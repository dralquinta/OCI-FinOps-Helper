{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73e7ee24",
   "metadata": {},
   "source": [
    "# OCI Services Growth Trends & Sales Planning Analysis\n",
    "\n",
    "**Objective:** Discover growth trends in OCI service consumption, identify expansion opportunities, and develop data-driven sales strategies for increased service adoption across the tenancy.\n",
    "\n",
    "**Analysis Date:** December 2025\n",
    "**Dataset:** output_merged.csv (merged billing and usage data)\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Table of Contents\n",
    "1. Import Required Libraries\n",
    "2. Load and Explore the Merged Dataset\n",
    "3. Data Cleaning and Preprocessing\n",
    "4. Time Series Analysis of Service Consumption\n",
    "5. Growth Rate Calculations and Trends\n",
    "6. Service-Level Consumption Patterns\n",
    "7. Cost Analysis and Revenue Projections\n",
    "8. Identify High-Growth Services\n",
    "9. Regional and Compartment Analysis\n",
    "10. Forecast Future Consumption\n",
    "11. Generate Sales Recommendations and Insights\n",
    "12. Key Metrics and Trends Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229f3d12",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03db7a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.dates import DateFormatter\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Statistical and ML libraries\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "# Configuration\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "# Plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully\")\n",
    "print(f\"üìÖ Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd04bfa",
   "metadata": {},
   "source": [
    "## 2. Load and Explore the Merged Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8167e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the merged dataset\n",
    "file = '../output/output_merged.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(file, low_memory=False)\n",
    "    print(f\"‚úÖ Dataset loaded successfully from {file}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading dataset: {e}\")\n",
    "    df = None\n",
    "\n",
    "if df is not None:\n",
    "    print(f\"\\nüìä Dataset Overview:\")\n",
    "    print(f\"   Shape: {df.shape[0]:,} rows √ó {df.shape[1]} columns\")\n",
    "    print(f\"   Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    \n",
    "    print(f\"\\nüìÖ Time Coverage:\")\n",
    "    print(f\"   Date Range: {df['timeUsageStarted'].min()} to {df['timeUsageEnded'].max()}\")\n",
    "    \n",
    "    print(f\"\\nüí∞ Financial Summary:\")\n",
    "    print(f\"   Total Cost: ${df['computedAmount'].sum():,.2f}\")\n",
    "    print(f\"   Average Cost per Row: ${df['computedAmount'].mean():,.2f}\")\n",
    "    \n",
    "    print(f\"\\nüìã Key Dimensions:\")\n",
    "    print(f\"   Unique Services: {df['service'].nunique()}\")\n",
    "    print(f\"   Unique Regions: {df['region'].nunique()}\")\n",
    "    print(f\"   Unique Compartments: {df['compartmentName'].nunique()}\")\n",
    "    print(f\"   Unique SKUs: {df['skuName'].nunique()}\")\n",
    "    \n",
    "    print(f\"\\nüìä Column Data Types:\")\n",
    "    print(df.dtypes)\n",
    "    \n",
    "    print(f\"\\nüìä First Few Rows:\")\n",
    "    df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be874a3",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd5a336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns to datetime\n",
    "df['timeUsageStarted'] = pd.to_datetime(df['timeUsageStarted'])\n",
    "df['timeUsageEnded'] = pd.to_datetime(df['timeUsageEnded'])\n",
    "\n",
    "# Create date-based features\n",
    "df['date'] = df['timeUsageStarted'].dt.date\n",
    "df['year'] = df['timeUsageStarted'].dt.year\n",
    "df['month'] = df['timeUsageStarted'].dt.month\n",
    "df['year_month'] = df['timeUsageStarted'].dt.strftime('%Y-%m')\n",
    "df['week'] = df['timeUsageStarted'].dt.isocalendar().week\n",
    "df['day_of_week'] = df['timeUsageStarted'].dt.day_name()\n",
    "df['day_of_month'] = df['timeUsageStarted'].dt.day\n",
    "df['quarter'] = df['timeUsageStarted'].dt.quarter\n",
    "\n",
    "# Fill missing values\n",
    "df['service'] = df['service'].fillna('Unknown')\n",
    "df['region'] = df['region'].fillna(df['region_from_call2']).fillna('Unknown')\n",
    "df['compartmentName'] = df['compartmentName'].fillna(df['compartmentPath'].str.split('/').str[-1]).fillna('Unknown')\n",
    "df['skuName'] = df['skuName'].fillna('Unknown SKU')\n",
    "df['computedAmount'] = pd.to_numeric(df['computedAmount'], errors='coerce').fillna(0)\n",
    "df['computedQuantity'] = pd.to_numeric(df['computedQuantity'], errors='coerce').fillna(0)\n",
    "\n",
    "# Handle tags - parse JSON if available\n",
    "def extract_tags(tag_str):\n",
    "    try:\n",
    "        if pd.isna(tag_str) or tag_str == '':\n",
    "            return {}\n",
    "        tags_list = json.loads(tag_str)\n",
    "        return {tag['key']: tag['value'] for tag in tags_list if 'key' in tag and 'value' in tag}\n",
    "    except:\n",
    "        return {}\n",
    "\n",
    "df['tags_dict'] = df['tags'].apply(extract_tags)\n",
    "df['cost_center'] = df['tags_dict'].apply(lambda x: x.get('CostCenter', 'Untagged'))\n",
    "df['environment'] = df['tags_dict'].apply(lambda x: x.get('Environment', 'Untagged'))\n",
    "df['team'] = df['tags_dict'].apply(lambda x: x.get('Team', 'Untagged'))\n",
    "\n",
    "# Remove duplicates if any\n",
    "initial_rows = len(df)\n",
    "df = df.drop_duplicates(subset=['timeUsageStarted', 'service', 'region', 'compartmentName', 'skuName', 'resourceId'])\n",
    "print(f\"‚úÖ Removed {initial_rows - len(df):,} duplicate rows\")\n",
    "\n",
    "print(f\"‚úÖ Data cleaning completed\")\n",
    "print(f\"üìä Final dataset: {len(df):,} rows √ó {df.shape[1]} columns\")\n",
    "print(f\"üìä Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "print(f\"üí∞ Total Cost: ${df['computedAmount'].sum():,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdbe987",
   "metadata": {},
   "source": [
    "## 4. Time Series Analysis of Service Consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e962d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily cost aggregation\n",
    "daily_costs = df.groupby('date').agg({\n",
    "    'computedAmount': 'sum',\n",
    "    'computedQuantity': 'sum',\n",
    "    'service': 'nunique',\n",
    "    'region': 'nunique',\n",
    "    'resourceId': 'count'\n",
    "}).rename(columns={'resourceId': 'transaction_count'}).reset_index()\n",
    "\n",
    "daily_costs['date'] = pd.to_datetime(daily_costs['date'])\n",
    "daily_costs = daily_costs.sort_values('date')\n",
    "\n",
    "# Weekly cost aggregation\n",
    "weekly_costs = df.groupby('year_month').agg({\n",
    "    'computedAmount': 'sum',\n",
    "    'computedQuantity': 'sum',\n",
    "    'service': 'nunique'\n",
    "}).reset_index()\n",
    "\n",
    "# Monthly cost aggregation\n",
    "monthly_costs = df.groupby('year_month').agg({\n",
    "    'computedAmount': 'sum',\n",
    "    'computedQuantity': 'sum',\n",
    "    'service': 'nunique',\n",
    "    'region': 'nunique',\n",
    "    'compartmentName': 'nunique'\n",
    "}).reset_index()\n",
    "monthly_costs.columns = ['year_month', 'total_cost', 'total_quantity', 'num_services', 'num_regions', 'num_compartments']\n",
    "\n",
    "print(f\"‚úÖ Time Series Analysis Completed\")\n",
    "print(f\"\\nüìä Daily Statistics:\")\n",
    "print(f\"   Min Daily Cost: ${daily_costs['computedAmount'].min():,.2f}\")\n",
    "print(f\"   Max Daily Cost: ${daily_costs['computedAmount'].max():,.2f}\")\n",
    "print(f\"   Avg Daily Cost: ${daily_costs['computedAmount'].mean():,.2f}\")\n",
    "print(f\"   Std Dev: ${daily_costs['computedAmount'].std():,.2f}\")\n",
    "\n",
    "print(f\"\\nüìä Monthly Statistics:\")\n",
    "print(f\"   Min Monthly Cost: ${monthly_costs['total_cost'].min():,.2f}\")\n",
    "print(f\"   Max Monthly Cost: ${monthly_costs['total_cost'].max():,.2f}\")\n",
    "print(f\"   Avg Monthly Cost: ${monthly_costs['total_cost'].mean():,.2f}\")\n",
    "\n",
    "print(f\"\\nüìä Monthly Breakdown:\")\n",
    "print(monthly_costs.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140dcfda",
   "metadata": {},
   "source": [
    "## 5. Growth Rate Calculations and Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09d5d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Month-over-Month (MoM) growth\n",
    "monthly_costs['mom_growth'] = monthly_costs['total_cost'].pct_change() * 100\n",
    "\n",
    "# Calculate Year-over-Year (YoY) growth (if available)\n",
    "yoy_data = df.groupby(['year', 'month']).agg({'computedAmount': 'sum'}).reset_index()\n",
    "yoy_pivot = yoy_data.pivot_table(index='month', columns='year', values='computedAmount')\n",
    "if yoy_pivot.shape[1] >= 2:\n",
    "    latest_year = yoy_pivot.columns[-1]\n",
    "    prev_year = yoy_pivot.columns[-2]\n",
    "    yoy_growth = ((yoy_pivot[latest_year] - yoy_pivot[prev_year]) / yoy_pivot[prev_year] * 100).fillna(0)\n",
    "    print(f\"‚úÖ Year-over-Year Growth Available: {latest_year} vs {prev_year}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Insufficient data for Year-over-Year comparison\")\n",
    "    yoy_growth = None\n",
    "\n",
    "# Linear regression trend analysis\n",
    "X = np.arange(len(daily_costs)).reshape(-1, 1)\n",
    "y = daily_costs['computedAmount'].values\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "daily_costs['trend'] = model.predict(X)\n",
    "\n",
    "slope = model.coef_[0]\n",
    "daily_growth_rate = (slope / daily_costs['computedAmount'].mean()) * 100\n",
    "\n",
    "print(f\"‚úÖ Growth Rate Calculations Completed\")\n",
    "print(f\"\\nüìà Daily Trend Analysis:\")\n",
    "print(f\"   Slope (daily change): ${slope:,.4f}\")\n",
    "print(f\"   Daily Growth Rate: {daily_growth_rate:.3f}% per day\")\n",
    "print(f\"   Annualized Growth Rate: {daily_growth_rate * 365:.2f}%\")\n",
    "\n",
    "print(f\"\\nüìä Month-over-Month Growth:\")\n",
    "print(monthly_costs[['year_month', 'total_cost', 'mom_growth']].tail(12))\n",
    "\n",
    "# Identify acceleration/deceleration\n",
    "recent_mom = monthly_costs['mom_growth'].tail(3).mean()\n",
    "earlier_mom = monthly_costs['mom_growth'].iloc[-12:-3].mean() if len(monthly_costs) > 12 else monthly_costs['mom_growth'].head(3).mean()\n",
    "acceleration = recent_mom - earlier_mom\n",
    "\n",
    "print(f\"\\n‚ö° Growth Momentum:\")\n",
    "print(f\"   Recent MoM (last 3 months): {recent_mom:.2f}%\")\n",
    "print(f\"   Previous MoM (3 months prior): {earlier_mom:.2f}%\")\n",
    "print(f\"   Acceleration: {acceleration:+.2f} percentage points\")\n",
    "if acceleration > 0:\n",
    "    print(f\"   Status: üöÄ ACCELERATING\")\n",
    "elif acceleration < 0:\n",
    "    print(f\"   Status: ‚¨áÔ∏è  DECELERATING\")\n",
    "else:\n",
    "    print(f\"   Status: ‚û°Ô∏è  STABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0d5da4",
   "metadata": {},
   "source": [
    "## 6. Service-Level Consumption Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3732ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Service-level cost breakdown\n",
    "service_summary = df.groupby('service').agg({\n",
    "    'computedAmount': ['sum', 'mean', 'count'],\n",
    "    'computedQuantity': 'sum',\n",
    "    'resourceId': 'nunique'\n",
    "}).reset_index()\n",
    "service_summary.columns = ['service', 'total_cost', 'avg_cost_per_row', 'num_records', 'total_quantity', 'num_resources']\n",
    "service_summary = service_summary.sort_values('total_cost', ascending=False)\n",
    "service_summary['market_share'] = (service_summary['total_cost'] / service_summary['total_cost'].sum() * 100).round(2)\n",
    "service_summary['rank'] = range(1, len(service_summary) + 1)\n",
    "\n",
    "# Top services\n",
    "top_services = service_summary.head(10)\n",
    "print(f\"‚úÖ Service-Level Analysis Completed\")\n",
    "print(f\"\\nüìä Top 10 Services by Cost:\")\n",
    "print(top_services[['rank', 'service', 'total_cost', 'market_share', 'num_resources']])\n",
    "\n",
    "# Service growth trends\n",
    "service_trends = df.groupby(['year_month', 'service']).agg({\n",
    "    'computedAmount': 'sum'\n",
    "}).reset_index()\n",
    "service_trends = service_trends.sort_values(['service', 'year_month'])\n",
    "service_trends['cost_change'] = service_trends.groupby('service')['computedAmount'].pct_change() * 100\n",
    "\n",
    "# Calculate CAGR for each service (if enough data)\n",
    "print(f\"\\nüìà Service Growth Analysis:\")\n",
    "service_cagr = []\n",
    "for service in df['service'].unique()[:10]:  # Top services\n",
    "    service_data = service_trends[service_trends['service'] == service].sort_values('year_month')\n",
    "    if len(service_data) > 1:\n",
    "        first_cost = service_data.iloc[0]['computedAmount']\n",
    "        last_cost = service_data.iloc[-1]['computedAmount']\n",
    "        periods = len(service_data) - 1\n",
    "        if first_cost > 0 and periods > 0:\n",
    "            cagr = ((last_cost / first_cost) ** (1 / periods) - 1) * 100\n",
    "            service_cagr.append({'service': service, 'cagr': cagr, 'current_cost': last_cost})\n",
    "\n",
    "if service_cagr:\n",
    "    service_cagr_df = pd.DataFrame(service_cagr).sort_values('cagr', ascending=False)\n",
    "    print(service_cagr_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96a1ed5",
   "metadata": {},
   "source": [
    "## 7. Cost Analysis and Revenue Projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19cf3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost analysis by service category\n",
    "service_cost_analysis = df.groupby('service').agg({\n",
    "    'computedAmount': ['sum', 'min', 'max', 'mean', 'std'],\n",
    "    'computedQuantity': 'sum',\n",
    "    'resourceId': 'count'\n",
    "}).round(2)\n",
    "service_cost_analysis.columns = ['total_cost', 'min_cost', 'max_cost', 'avg_cost', 'std_dev', 'total_quantity', 'transactions']\n",
    "service_cost_analysis = service_cost_analysis.sort_values('total_cost', ascending=False)\n",
    "\n",
    "# Calculate cost per resource\n",
    "service_cost_analysis['cost_per_resource'] = service_cost_analysis['total_cost'] / service_cost_analysis['transactions']\n",
    "\n",
    "print(f\"‚úÖ Cost Analysis Completed\")\n",
    "print(f\"\\nüí∞ Overall Financial Summary:\")\n",
    "print(f\"   Total Spend: ${df['computedAmount'].sum():,.2f}\")\n",
    "print(f\"   Average Transaction Size: ${df['computedAmount'].mean():,.2f}\")\n",
    "print(f\"   Median Transaction Size: ${df['computedAmount'].median():,.2f}\")\n",
    "print(f\"   Max Single Transaction: ${df['computedAmount'].max():,.2f}\")\n",
    "print(f\"   Transactions: {len(df):,}\")\n",
    "\n",
    "print(f\"\\nüí∞ Service Cost Structure:\")\n",
    "print(service_cost_analysis.head(10))\n",
    "\n",
    "# Revenue projections based on growth rates\n",
    "current_monthly_cost = monthly_costs.iloc[-1]['total_cost']\n",
    "print(f\"\\nüìä Revenue Projections (next 12 months):\")\n",
    "print(f\"   Current Monthly Cost: ${current_monthly_cost:,.2f}\")\n",
    "\n",
    "# Conservative, moderate, and aggressive projections\n",
    "growth_scenarios = [\n",
    "    ('Conservative (5% MoM)', 0.05),\n",
    "    ('Moderate (10% MoM)', 0.10),\n",
    "    ('Aggressive (15% MoM)', 0.15)\n",
    "]\n",
    "\n",
    "for scenario_name, growth_rate in growth_scenarios:\n",
    "    projection = current_monthly_cost\n",
    "    total_12m = 0\n",
    "    for month in range(12):\n",
    "        projection = projection * (1 + growth_rate)\n",
    "        total_12m += projection\n",
    "    print(f\"\\n   {scenario_name}:\")\n",
    "    print(f\"      Month 12 Cost: ${projection:,.2f}\")\n",
    "    print(f\"      Total 12-Month: ${total_12m:,.2f}\")\n",
    "    print(f\"      YoY Cost: ${current_monthly_cost * 12:,.2f}\")\n",
    "\n",
    "# Cost optimization opportunities\n",
    "print(f\"\\nüéØ Cost Optimization Opportunities:\")\n",
    "print(f\"   Services with high variance (potential optimization): \")\n",
    "high_variance = service_cost_analysis[service_cost_analysis['std_dev'] > service_cost_analysis['std_dev'].quantile(0.75)].head()\n",
    "for idx, (service, row) in enumerate(high_variance.iterrows(), 1):\n",
    "    print(f\"      {idx}. {service}: Std Dev ${row['std_dev']:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfaaebc",
   "metadata": {},
   "source": [
    "## 8. Identify High-Growth Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef38c71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify high-growth services\n",
    "growth_analysis = []\n",
    "for service in df['service'].unique():\n",
    "    service_data = df[df['service'] == service].copy()\n",
    "    service_data = service_data.sort_values('timeUsageStarted')\n",
    "    \n",
    "    # Calculate growth metrics\n",
    "    if len(service_data) > 1:\n",
    "        first_date = service_data['date'].min()\n",
    "        last_date = service_data['date'].max()\n",
    "        days_active = (last_date - first_date).days + 1\n",
    "        \n",
    "        # Get first and last month costs\n",
    "        first_month_idx = service_data.groupby('year_month')['computedAmount'].sum().index[0]\n",
    "        last_month_idx = service_data.groupby('year_month')['computedAmount'].sum().index[-1]\n",
    "        \n",
    "        first_month_cost = service_data[service_data['year_month'] == first_month_idx]['computedAmount'].sum()\n",
    "        last_month_cost = service_data[service_data['year_month'] == last_month_idx]['computedAmount'].sum()\n",
    "        \n",
    "        total_cost = service_data['computedAmount'].sum()\n",
    "        num_resources = service_data['resourceId'].nunique()\n",
    "        \n",
    "        # Calculate growth rate\n",
    "        if first_month_cost > 0:\n",
    "            # Simple growth rate calculation\n",
    "            months_active = len(service_data.groupby('year_month'))\n",
    "            if months_active > 1:\n",
    "                growth_rate = ((last_month_cost / first_month_cost) ** (1 / (months_active - 1)) - 1) * 100\n",
    "            else:\n",
    "                growth_rate = 0\n",
    "        else:\n",
    "            growth_rate = 0\n",
    "        \n",
    "        growth_analysis.append({\n",
    "            'service': service,\n",
    "            'total_cost': total_cost,\n",
    "            'current_monthly': last_month_cost,\n",
    "            'first_monthly': first_month_cost,\n",
    "            'growth_rate': growth_rate,\n",
    "            'num_resources': num_resources,\n",
    "            'days_active': days_active,\n",
    "            'market_share': (total_cost / df['computedAmount'].sum()) * 100\n",
    "        })\n",
    "\n",
    "growth_df = pd.DataFrame(growth_analysis).sort_values('growth_rate', ascending=False)\n",
    "\n",
    "print(f\"‚úÖ High-Growth Services Analysis Completed\")\n",
    "print(f\"\\nüöÄ Top 10 Highest-Growth Services:\")\n",
    "print(growth_df[['service', 'growth_rate', 'current_monthly', 'num_resources', 'market_share']].head(10))\n",
    "\n",
    "# Categorize services\n",
    "print(f\"\\nüìä Service Growth Categories:\")\n",
    "high_growth = growth_df[growth_df['growth_rate'] > growth_df['growth_rate'].quantile(0.75)]\n",
    "moderate_growth = growth_df[(growth_df['growth_rate'] > growth_df['growth_rate'].quantile(0.25)) & \n",
    "                             (growth_df['growth_rate'] <= growth_df['growth_rate'].quantile(0.75))]\n",
    "low_growth = growth_df[growth_df['growth_rate'] <= growth_df['growth_rate'].quantile(0.25)]\n",
    "\n",
    "print(f\"\\nüî• High-Growth Services ({len(high_growth)}):\")\n",
    "if len(high_growth) > 0:\n",
    "    print(high_growth[['service', 'growth_rate', 'current_monthly']].head(5))\n",
    "\n",
    "print(f\"\\n‚ö° Emerging Services (First 2 months of activity):\")\n",
    "emerging = growth_df[growth_df['days_active'] < 60].sort_values('current_monthly', ascending=False)\n",
    "if len(emerging) > 0:\n",
    "    print(emerging[['service', 'current_monthly', 'num_resources']].head(5))\n",
    "\n",
    "print(f\"\\nüìâ Services Approaching Saturation (Low growth, High cost):\")\n",
    "mature = growth_df[(growth_df['growth_rate'] < 5) & (growth_df['total_cost'] > growth_df['total_cost'].quantile(0.5))]\n",
    "if len(mature) > 0:\n",
    "    print(mature[['service', 'growth_rate', 'current_monthly', 'market_share']].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e55457f",
   "metadata": {},
   "source": [
    "## 9. Regional and Compartment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f034b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regional analysis\n",
    "regional_analysis = df.groupby('region').agg({\n",
    "    'computedAmount': ['sum', 'mean'],\n",
    "    'resourceId': 'nunique',\n",
    "    'compartmentName': 'nunique',\n",
    "    'service': 'nunique'\n",
    "}).reset_index()\n",
    "regional_analysis.columns = ['region', 'total_cost', 'avg_cost', 'num_resources', 'num_compartments', 'num_services']\n",
    "regional_analysis = regional_analysis.sort_values('total_cost', ascending=False)\n",
    "regional_analysis['market_share'] = (regional_analysis['total_cost'] / regional_analysis['total_cost'].sum() * 100).round(2)\n",
    "\n",
    "# Regional growth trends\n",
    "regional_trends = df.groupby(['year_month', 'region'])['computedAmount'].sum().reset_index()\n",
    "regional_trends = regional_trends.sort_values(['region', 'year_month'])\n",
    "\n",
    "# Compartment analysis\n",
    "compartment_analysis = df.groupby('compartmentName').agg({\n",
    "    'computedAmount': ['sum', 'mean', 'count'],\n",
    "    'service': 'nunique',\n",
    "    'region': 'nunique',\n",
    "    'resourceId': 'nunique'\n",
    "}).reset_index()\n",
    "compartment_analysis.columns = ['compartment', 'total_cost', 'avg_cost', 'num_records', 'num_services', 'num_regions', 'num_resources']\n",
    "compartment_analysis = compartment_analysis.sort_values('total_cost', ascending=False)\n",
    "compartment_analysis['market_share'] = (compartment_analysis['total_cost'] / compartment_analysis['total_cost'].sum() * 100).round(2)\n",
    "\n",
    "print(f\"‚úÖ Regional and Compartment Analysis Completed\")\n",
    "print(f\"\\nüåç Regional Cost Distribution:\")\n",
    "print(regional_analysis[['region', 'total_cost', 'market_share', 'num_services', 'num_resources']].head(10))\n",
    "\n",
    "print(f\"\\nüìä Regional Growth Hotspots:\")\n",
    "regional_growth = []\n",
    "for region in df['region'].unique():\n",
    "    region_data = regional_trends[regional_trends['region'] == region].sort_values('year_month')\n",
    "    if len(region_data) > 1:\n",
    "        first = region_data.iloc[0]['computedAmount']\n",
    "        last = region_data.iloc[-1]['computedAmount']\n",
    "        if first > 0:\n",
    "            growth = ((last / first) - 1) * 100\n",
    "            regional_growth.append({'region': region, 'growth_rate': growth, 'current_cost': last, 'num_months': len(region_data)})\n",
    "\n",
    "if regional_growth:\n",
    "    regional_growth_df = pd.DataFrame(regional_growth).sort_values('growth_rate', ascending=False)\n",
    "    print(regional_growth_df.head(10))\n",
    "else:\n",
    "    print(\"   No multi-month data available for regional growth analysis\")\n",
    "\n",
    "print(f\"\\nüè¢ Top Compartments by Cost:\")\n",
    "print(compartment_analysis[['compartment', 'total_cost', 'market_share', 'num_services']].head(10))\n",
    "\n",
    "print(f\"\\nüéØ Untapped Markets (Regions with low service adoption):\")\n",
    "low_adoption = regional_analysis[regional_analysis['num_services'] < regional_analysis['num_services'].median()].sort_values('total_cost')\n",
    "if len(low_adoption) > 0:\n",
    "    print(low_adoption[['region', 'total_cost', 'num_services', 'num_resources']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98aed1dd",
   "metadata": {},
   "source": [
    "## 10. Forecast Future Consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad85529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series forecasting\n",
    "print(f\"‚úÖ Starting Time Series Forecast Analysis\")\n",
    "\n",
    "# Prepare data for forecasting\n",
    "monthly_costs_ts = monthly_costs.set_index('year_month')['total_cost']\n",
    "\n",
    "# Try ARIMA if we have enough data\n",
    "forecast_results = {}\n",
    "if len(monthly_costs_ts) > 12:\n",
    "    try:\n",
    "        # Auto ARIMA-like approach (simple exponential smoothing)\n",
    "        model_exp = ExponentialSmoothing(monthly_costs_ts, trend='add', seasonal=None)\n",
    "        fitted_exp = model_exp.fit()\n",
    "        forecast_exp = fitted_exp.forecast(steps=6)\n",
    "        forecast_results['Exponential Smoothing (6M)'] = forecast_exp\n",
    "        print(\"‚úÖ Exponential Smoothing model trained successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Exponential Smoothing failed: {e}\")\n",
    "    \n",
    "    try:\n",
    "        # Linear regression forecast\n",
    "        X_forecast = np.arange(len(monthly_costs_ts), len(monthly_costs_ts) + 6).reshape(-1, 1)\n",
    "        X_train = np.arange(len(monthly_costs_ts)).reshape(-1, 1)\n",
    "        lr_model = LinearRegression()\n",
    "        lr_model.fit(X_train, monthly_costs_ts.values)\n",
    "        forecast_lr = lr_model.predict(X_forecast)\n",
    "        forecast_results['Linear Regression (6M)'] = forecast_lr\n",
    "        print(\"‚úÖ Linear Regression model trained successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Linear Regression failed: {e}\")\n",
    "\n",
    "# Display forecasts\n",
    "print(f\"\\nüìà 6-Month Cost Forecast:\")\n",
    "for model_name, forecast_values in forecast_results.items():\n",
    "    print(f\"\\n   {model_name}:\")\n",
    "    total_6m = forecast_values.sum() if isinstance(forecast_values, np.ndarray) else forecast_values.sum()\n",
    "    avg_forecast = forecast_values.mean() if isinstance(forecast_values, np.ndarray) else forecast_values.mean()\n",
    "    print(f\"      Average Monthly: ${avg_forecast:,.2f}\")\n",
    "    print(f\"      Total 6-Month: ${total_6m:,.2f}\")\n",
    "    if isinstance(forecast_values, np.ndarray):\n",
    "        print(f\"      Month 1: ${forecast_values[0]:,.2f}\")\n",
    "        print(f\"      Month 6: ${forecast_values[-1]:,.2f}\")\n",
    "\n",
    "# Service-level forecast\n",
    "print(f\"\\nüìä Top 5 Services - 6-Month Forecast:\")\n",
    "top_services_for_forecast = service_summary.head(5)['service'].tolist()\n",
    "for service in top_services_for_forecast:\n",
    "    service_ts = df[df['service'] == service].groupby('year_month')['computedAmount'].sum()\n",
    "    if len(service_ts) > 2:\n",
    "        try:\n",
    "            model_exp = ExponentialSmoothing(service_ts, trend='add', seasonal=None)\n",
    "            fitted = model_exp.fit()\n",
    "            forecast = fitted.forecast(steps=6)\n",
    "            print(f\"\\n   {service}:\")\n",
    "            print(f\"      Current Monthly: ${service_ts.iloc[-1]:,.2f}\")\n",
    "            print(f\"      6M Avg Forecast: ${forecast.mean():,.2f}\")\n",
    "            print(f\"      Growth: {((forecast.mean() / service_ts.iloc[-1]) - 1) * 100:+.1f}%\")\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ffdd80",
   "metadata": {},
   "source": [
    "## 11. Generate Sales Recommendations and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38acfa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive sales recommendations\n",
    "print(\"=\" * 80)\n",
    "print(\"STRATEGIC SALES RECOMMENDATIONS & ACTION ITEMS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. Upsell Opportunities\n",
    "print(\"\\nüîº UPSELL OPPORTUNITIES\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(\"\\n1. Services Ready for Expansion:\")\n",
    "high_growth_services = growth_df[growth_df['growth_rate'] > 20].sort_values('current_monthly', ascending=False)\n",
    "if len(high_growth_services) > 0:\n",
    "    for idx, (_, service) in enumerate(high_growth_services.head(5).iterrows(), 1):\n",
    "        print(f\"\\n   {idx}. {service['service']}\")\n",
    "        print(f\"      Current Monthly: ${service['current_monthly']:,.2f}\")\n",
    "        print(f\"      Growth Rate: {service['growth_rate']:.1f}%\")\n",
    "        print(f\"      Resources: {int(service['num_resources'])}\")\n",
    "        print(f\"      Action: Offer advanced features, consulting, or managed services\")\n",
    "\n",
    "# 2. Cross-sell Opportunities\n",
    "print(\"\\n\\n‚ùå CROSS-SELL OPPORTUNITIES\")\n",
    "print(\"-\" * 80)\n",
    "print(\"\\n1. Services Adoption Gaps by Region:\")\n",
    "\n",
    "for region in regional_analysis['region'].head(5).values:\n",
    "    region_services = df[df['region'] == region]['service'].nunique()\n",
    "    max_services = df['service'].nunique()\n",
    "    adoption_rate = (region_services / max_services) * 100\n",
    "    \n",
    "    if adoption_rate < 70:\n",
    "        print(f\"\\n   {region}:\")\n",
    "        print(f\"      Service Adoption: {adoption_rate:.1f}% ({region_services}/{max_services})\")\n",
    "        \n",
    "        # Find services in other regions not in this region\n",
    "        all_services = set(df['service'].unique())\n",
    "        region_services_set = set(df[df['region'] == region]['service'].unique())\n",
    "        missing_services = all_services - region_services_set\n",
    "        \n",
    "        if missing_services:\n",
    "            print(f\"      Missing Services: {', '.join(list(missing_services)[:3])}\")\n",
    "            print(f\"      Action: Target with service bundle offers\")\n",
    "\n",
    "# 3. Account Expansion\n",
    "print(\"\\n\\nüìà ACCOUNT EXPANSION (Compartment-level Analysis)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Find compartments with growth potential\n",
    "compartment_growth = []\n",
    "for comp in compartment_analysis['compartment'].head(20).values:\n",
    "    comp_data = df[df['compartmentName'] == comp]\n",
    "    comp_services = comp_data['service'].nunique()\n",
    "    comp_cost = comp_data['computedAmount'].sum()\n",
    "    services_potential = df['service'].nunique() - comp_services\n",
    "    \n",
    "    if services_potential > 3:\n",
    "        compartment_growth.append({\n",
    "            'compartment': comp,\n",
    "            'current_cost': comp_cost,\n",
    "            'service_count': comp_services,\n",
    "            'expansion_potential': services_potential\n",
    "        })\n",
    "\n",
    "if compartment_growth:\n",
    "    comp_growth_df = pd.DataFrame(compartment_growth).sort_values('current_cost', ascending=False)\n",
    "    print(\"\\nCompartments with High Expansion Potential:\")\n",
    "    for idx, (_, comp) in enumerate(comp_growth_df.head(5).iterrows(), 1):\n",
    "        print(f\"\\n   {idx}. {comp['compartment']}\")\n",
    "        print(f\"      Current Cost: ${comp['current_cost']:,.2f}\")\n",
    "        print(f\"      Services Used: {int(comp['service_count'])}\")\n",
    "        print(f\"      Services to Upsell: {int(comp['expansion_potential'])}\")\n",
    "\n",
    "# 4. New Market Opportunities\n",
    "print(\"\\n\\nüåç NEW MARKET OPPORTUNITIES (Geographic Expansion)\")\n",
    "print(\"-\" * 80)\n",
    "print(\"\\nRegions with Growth Potential:\")\n",
    "\n",
    "for idx, (_, region) in enumerate(low_adoption.head(5).iterrows(), 1):\n",
    "    print(f\"\\n   {idx}. {region['region']}\")\n",
    "    print(f\"      Current Spend: ${region['total_cost']:,.2f}\")\n",
    "    print(f\"      Services Available: {int(region['num_services'])}\")\n",
    "    print(f\"      Growth Potential: High (currently underutilized)\")\n",
    "    print(f\"      Action: Targeted sales campaign for region-specific requirements\")\n",
    "\n",
    "# 5. Product Bundle Recommendations\n",
    "print(\"\\n\\nüì¶ RECOMMENDED SERVICE BUNDLES\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Find services often used together\n",
    "service_pairs = {}\n",
    "for comp in df['compartmentName'].unique():\n",
    "    comp_services = df[df['compartmentName'] == comp]['service'].unique()\n",
    "    for i, svc1 in enumerate(comp_services):\n",
    "        for svc2 in comp_services[i+1:]:\n",
    "            pair = tuple(sorted([svc1, svc2]))\n",
    "            service_pairs[pair] = service_pairs.get(pair, 0) + 1\n",
    "\n",
    "if service_pairs:\n",
    "    common_pairs = sorted(service_pairs.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "    print(\"\\nMost Common Service Combinations:\")\n",
    "    for idx, (pair, count) in enumerate(common_pairs, 1):\n",
    "        print(f\"   {idx}. {pair[0]} + {pair[1]} (used together in {count} compartments)\")\n",
    "\n",
    "# 6. Retention Focus\n",
    "print(\"\\n\\n‚ö†Ô∏è  RETENTION FOCUS - Services at Risk\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "declining_services = growth_df[growth_df['growth_rate'] < -10].sort_values('current_monthly', ascending=False)\n",
    "if len(declining_services) > 0:\n",
    "    print(\"\\nServices with Declining Usage (Potential Churn Risk):\")\n",
    "    for idx, (_, service) in enumerate(declining_services.head(5).iterrows(), 1):\n",
    "        print(f\"\\n   {idx}. {service['service']}\")\n",
    "        print(f\"      Current Monthly Cost: ${service['current_monthly']:,.2f}\")\n",
    "        print(f\"      Decline Rate: {service['growth_rate']:.1f}%\")\n",
    "        print(f\"      Action: Proactive support, optimization, feature showcases\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ All tracked services showing stable or positive growth - low churn risk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880ba95f",
   "metadata": {},
   "source": [
    "## 12. Key Metrics and Trends Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3bcd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualizations\n",
    "fig = plt.figure(figsize=(18, 12))\n",
    "\n",
    "# 1. Daily cost trend with moving average\n",
    "ax1 = plt.subplot(3, 3, 1)\n",
    "ax1.plot(daily_costs['date'], daily_costs['computedAmount'], label='Daily Cost', alpha=0.5, linewidth=0.5)\n",
    "ax1.plot(daily_costs['date'], daily_costs['trend'], label='Trend', color='red', linewidth=2)\n",
    "# Add 7-day moving average\n",
    "ma_7 = daily_costs['computedAmount'].rolling(window=7).mean()\n",
    "ax1.plot(daily_costs['date'], ma_7, label='7-day MA', color='green', linewidth=2, alpha=0.7)\n",
    "ax1.set_title('Daily Cost Trend Analysis', fontsize=12, fontweight='bold')\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Cost ($)')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Monthly cost bar chart with growth rate\n",
    "ax2 = plt.subplot(3, 3, 2)\n",
    "months_display = monthly_costs['year_month'].tail(12).values\n",
    "costs_display = monthly_costs['total_cost'].tail(12).values\n",
    "colors = ['green' if x > 0 else 'red' for x in monthly_costs['mom_growth'].tail(12).values]\n",
    "ax2.bar(range(len(months_display)), costs_display, color=colors, alpha=0.7)\n",
    "ax2.set_title('Monthly Cost with Growth Direction', fontsize=12, fontweight='bold')\n",
    "ax2.set_xlabel('Month')\n",
    "ax2.set_ylabel('Cost ($)')\n",
    "ax2.set_xticks(range(len(months_display)))\n",
    "ax2.set_xticklabels(months_display, rotation=45, ha='right')\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 3. Top 10 services pie chart\n",
    "ax3 = plt.subplot(3, 3, 3)\n",
    "top_10_services = service_summary.head(10)\n",
    "other_cost = service_summary.iloc[10:]['total_cost'].sum()\n",
    "pie_data = list(top_10_services['total_cost'].values)\n",
    "pie_labels = list(top_10_services['service'].values)\n",
    "if other_cost > 0:\n",
    "    pie_data.append(other_cost)\n",
    "    pie_labels.append('Others')\n",
    "colors_pie = plt.cm.Set3(np.linspace(0, 1, len(pie_data)))\n",
    "ax3.pie(pie_data, labels=pie_labels, autopct='%1.1f%%', colors=colors_pie, startangle=90)\n",
    "ax3.set_title('Service Market Share (Top 10)', fontsize=12, fontweight='bold')\n",
    "\n",
    "# 4. Service growth rates\n",
    "ax4 = plt.subplot(3, 3, 4)\n",
    "top_growth = growth_df.head(10).sort_values('growth_rate')\n",
    "colors_growth = ['green' if x > 0 else 'red' for x in top_growth['growth_rate'].values]\n",
    "ax4.barh(range(len(top_growth)), top_growth['growth_rate'].values, color=colors_growth, alpha=0.7)\n",
    "ax4.set_yticks(range(len(top_growth)))\n",
    "ax4.set_yticklabels(top_growth['service'].values)\n",
    "ax4.set_xlabel('Growth Rate (%)')\n",
    "ax4.set_title('Top 10 Services by Growth Rate', fontsize=12, fontweight='bold')\n",
    "ax4.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "ax4.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# 5. Regional cost distribution\n",
    "ax5 = plt.subplot(3, 3, 5)\n",
    "top_regions = regional_analysis.head(8)\n",
    "ax5.bar(range(len(top_regions)), top_regions['total_cost'].values, color=plt.cm.Set2(np.linspace(0, 1, len(top_regions))))\n",
    "ax5.set_xticks(range(len(top_regions)))\n",
    "ax5.set_xticklabels(top_regions['region'].values, rotation=45, ha='right')\n",
    "ax5.set_ylabel('Cost ($)')\n",
    "ax5.set_title('Top Regions by Cost', fontsize=12, fontweight='bold')\n",
    "ax5.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 6. Compartment cost distribution\n",
    "ax6 = plt.subplot(3, 3, 6)\n",
    "top_comps = compartment_analysis.head(8)\n",
    "ax6.barh(range(len(top_comps)), top_comps['total_cost'].values, color=plt.cm.Spectral(np.linspace(0, 1, len(top_comps))))\n",
    "ax6.set_yticks(range(len(top_comps)))\n",
    "ax6.set_yticklabels([c[:30] + '...' if len(c) > 30 else c for c in top_comps['compartment'].values])\n",
    "ax6.set_xlabel('Cost ($)')\n",
    "ax6.set_title('Top Compartments by Cost', fontsize=12, fontweight='bold')\n",
    "ax6.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# 7. Service adoption by region (heatmap style)\n",
    "ax7 = plt.subplot(3, 3, 7)\n",
    "service_region_matrix = df.groupby(['region', 'service']).size().unstack(fill_value=0)\n",
    "top_regions_for_hm = regional_analysis.head(6)['region'].values\n",
    "top_services_for_hm = service_summary.head(10)['service'].values\n",
    "hm_data = service_region_matrix.loc[\n",
    "    service_region_matrix.index.isin(top_regions_for_hm),\n",
    "    service_region_matrix.columns.isin(top_services_for_hm)\n",
    "]\n",
    "im = ax7.imshow(hm_data.T, cmap='YlOrRd', aspect='auto')\n",
    "ax7.set_xticks(range(len(hm_data)))\n",
    "ax7.set_yticks(range(len(hm_data.columns)))\n",
    "ax7.set_xticklabels(hm_data.index, rotation=45, ha='right', fontsize=8)\n",
    "ax7.set_yticklabels([s[:15] + '...' if len(s) > 15 else s for s in hm_data.columns], fontsize=8)\n",
    "ax7.set_title('Service Adoption by Region', fontsize=12, fontweight='bold')\n",
    "plt.colorbar(im, ax=ax7)\n",
    "\n",
    "# 8. Cost distribution by day of week\n",
    "ax8 = plt.subplot(3, 3, 8)\n",
    "day_costs = df.groupby('day_of_week')['computedAmount'].mean().reindex(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])\n",
    "ax8.plot(day_costs.index, day_costs.values, marker='o', linewidth=2, markersize=8, color='purple')\n",
    "ax8.fill_between(range(len(day_costs)), day_costs.values, alpha=0.3, color='purple')\n",
    "ax8.set_ylabel('Average Cost ($)')\n",
    "ax8.set_title('Average Cost by Day of Week', fontsize=12, fontweight='bold')\n",
    "ax8.grid(True, alpha=0.3)\n",
    "ax8.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 9. Cost concentration (Pareto principle)\n",
    "ax9 = plt.subplot(3, 3, 9)\n",
    "service_costs_sorted = service_summary['total_cost'].sort_values(ascending=False).reset_index(drop=True)\n",
    "cumsum = service_costs_sorted.cumsum() / service_costs_sorted.sum() * 100\n",
    "ax9.plot(range(len(cumsum)), cumsum.values, marker='o', linewidth=2, color='darkgreen', markersize=4)\n",
    "ax9.axhline(y=80, color='red', linestyle='--', linewidth=2, label='80% (Pareto)')\n",
    "ax9.fill_between(range(len(cumsum)), cumsum.values, alpha=0.2, color='darkgreen')\n",
    "ax9.set_xlabel('Number of Services')\n",
    "ax9.set_ylabel('Cumulative Cost (%)')\n",
    "ax9.set_title('Cost Concentration (Pareto Analysis)', fontsize=12, fontweight='bold')\n",
    "ax9.legend()\n",
    "ax9.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "print(\"‚úÖ Main Dashboard visualization complete\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ec5f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional detailed visualizations for specific insights\n",
    "\n",
    "# Visualization 2: Service-level trends for top services\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "fig.suptitle('Top 4 Services - Detailed Trend Analysis', fontsize=14, fontweight='bold')\n",
    "\n",
    "top_4_services = service_summary.head(4)['service'].values\n",
    "\n",
    "for idx, (ax, service) in enumerate(zip(axes.flat, top_4_services)):\n",
    "    service_monthly = df[df['service'] == service].groupby('year_month').agg({\n",
    "        'computedAmount': 'sum',\n",
    "        'resourceId': 'nunique',\n",
    "        'computedQuantity': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    ax2 = ax.twinx()\n",
    "    \n",
    "    # Bar chart for cost\n",
    "    ax.bar(range(len(service_monthly)), service_monthly['computedAmount'].values, \n",
    "           color='skyblue', alpha=0.7, label='Cost')\n",
    "    \n",
    "    # Line chart for resource count\n",
    "    ax2.plot(range(len(service_monthly)), service_monthly['resourceId'].values, \n",
    "            marker='o', color='red', linewidth=2, markersize=6, label='Resources')\n",
    "    \n",
    "    ax.set_xlabel('Month')\n",
    "    ax.set_ylabel('Cost ($)', color='skyblue')\n",
    "    ax2.set_ylabel('Number of Resources', color='red')\n",
    "    ax.set_title(f'{service}', fontweight='bold')\n",
    "    ax.set_xticks(range(len(service_monthly)))\n",
    "    ax.set_xticklabels(service_monthly['year_month'].values, rotation=45, ha='right', fontsize=9)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add legends\n",
    "    ax.legend(loc='upper left')\n",
    "    ax2.legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "print(\"‚úÖ Top Services Trends visualization complete\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b404557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regional growth analysis visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "fig.suptitle('Regional Analysis & Growth Opportunities', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Regional cost and service adoption\n",
    "ax1 = axes[0]\n",
    "top_regions_detail = regional_analysis.head(10)\n",
    "x_pos = np.arange(len(top_regions_detail))\n",
    "width = 0.35\n",
    "\n",
    "ax1_bar = ax1.bar(x_pos - width/2, top_regions_detail['total_cost'].values, width, \n",
    "                   label='Total Cost', color='steelblue', alpha=0.8)\n",
    "ax1_twin = ax1.twinx()\n",
    "ax1_twin.bar(x_pos + width/2, top_regions_detail['num_services'].values, width,\n",
    "             label='Number of Services', color='coral', alpha=0.8)\n",
    "\n",
    "ax1.set_xlabel('Region')\n",
    "ax1.set_ylabel('Total Cost ($)', color='steelblue')\n",
    "ax1_twin.set_ylabel('Services Count', color='coral')\n",
    "ax1.set_title('Regional Cost Distribution & Service Diversity')\n",
    "ax1.set_xticks(x_pos)\n",
    "ax1.set_xticklabels(top_regions_detail['region'].values, rotation=45, ha='right')\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Regional growth rates\n",
    "ax2 = axes[1]\n",
    "# Check if regional_growth_df exists and has data\n",
    "if 'regional_growth_df' in locals() and len(regional_growth_df) > 0:\n",
    "    regional_growth_display = regional_growth_df.head(10).sort_values('growth_rate')\n",
    "    colors_reg = ['green' if x > 0 else 'red' for x in regional_growth_display['growth_rate'].values]\n",
    "    ax2.barh(range(len(regional_growth_display)), regional_growth_display['growth_rate'].values, \n",
    "             color=colors_reg, alpha=0.7)\n",
    "    ax2.set_yticks(range(len(regional_growth_display)))\n",
    "    ax2.set_yticklabels(regional_growth_display['region'].values)\n",
    "    ax2.set_xlabel('Growth Rate (%)')\n",
    "    ax2.set_title('Regional Growth Rates (Period-over-Period)')\n",
    "    ax2.axvline(x=0, color='black', linestyle='-', linewidth=1)\n",
    "    ax2.grid(True, alpha=0.3, axis='x')\n",
    "else:\n",
    "    ax2.text(0.5, 0.5, 'Insufficient multi-month data\\nfor regional growth analysis', \n",
    "             ha='center', va='center', fontsize=12, transform=ax2.transAxes)\n",
    "    ax2.set_title('Regional Growth Rates (Period-over-Period)')\n",
    "    ax2.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "print(\"‚úÖ Regional Analysis visualization complete\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a64645c",
   "metadata": {},
   "source": [
    "## 13. Cross-Selling Opportunity Analysis\n",
    "\n",
    "Identify services that are frequently used together, service adoption gaps, and cross-selling opportunities across compartments and regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdea96f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze service co-occurrence patterns for cross-selling opportunities\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"CROSS-SELLING OPPORTUNITY ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Service Co-occurrence Analysis\n",
    "print(\"\\nüìä Analyzing service usage patterns across compartments...\")\n",
    "\n",
    "# Build service co-occurrence matrix\n",
    "from itertools import combinations\n",
    "\n",
    "service_cooccurrence = {}\n",
    "compartments_with_service = {}\n",
    "\n",
    "# Track which compartments use which services\n",
    "for service in df['service'].unique():\n",
    "    compartments_with_service[service] = set(df[df['service'] == service]['compartmentName'].unique())\n",
    "\n",
    "# Calculate co-occurrence scores\n",
    "for service1, service2 in combinations(df['service'].unique(), 2):\n",
    "    comp1 = compartments_with_service[service1]\n",
    "    comp2 = compartments_with_service[service2]\n",
    "    \n",
    "    # Jaccard similarity (intersection / union)\n",
    "    intersection = len(comp1 & comp2)\n",
    "    union = len(comp1 | comp2)\n",
    "    \n",
    "    if union > 0 and intersection > 0:\n",
    "        jaccard = intersection / union\n",
    "        support = intersection  # How many compartments use both\n",
    "        \n",
    "        service_cooccurrence[(service1, service2)] = {\n",
    "            'jaccard': jaccard,\n",
    "            'support': support,\n",
    "            'comp1_only': len(comp1 - comp2),\n",
    "            'comp2_only': len(comp2 - comp1),\n",
    "            'both': intersection\n",
    "        }\n",
    "\n",
    "# Convert to DataFrame for analysis\n",
    "cooccurrence_list = []\n",
    "for (s1, s2), metrics in service_cooccurrence.items():\n",
    "    cooccurrence_list.append({\n",
    "        'service1': s1,\n",
    "        'service2': s2,\n",
    "        'jaccard_similarity': metrics['jaccard'],\n",
    "        'compartments_both': metrics['both'],\n",
    "        'compartments_s1_only': metrics['comp1_only'],\n",
    "        'compartments_s2_only': metrics['comp2_only'],\n",
    "        'cross_sell_potential': metrics['comp1_only'] + metrics['comp2_only']\n",
    "    })\n",
    "\n",
    "cooccurrence_df = pd.DataFrame(cooccurrence_list)\n",
    "cooccurrence_df = cooccurrence_df.sort_values('compartments_both', ascending=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Analyzed {len(cooccurrence_df)} service pairs\")\n",
    "print(f\"üìä Found {len(cooccurrence_df[cooccurrence_df['compartments_both'] > 5])} strong service associations (5+ compartments)\")\n",
    "\n",
    "# Top service pairs (frequently used together)\n",
    "print(\"\\nüîó TOP 10 SERVICE PAIRS - Frequently Used Together:\")\n",
    "print(\"-\"*80)\n",
    "top_pairs = cooccurrence_df.head(10)\n",
    "for idx, row in top_pairs.iterrows():\n",
    "    print(f\"\\n{row['service1'][:40]} + {row['service2'][:40]}\")\n",
    "    print(f\"   Used together in: {row['compartments_both']} compartments\")\n",
    "    print(f\"   Jaccard Similarity: {row['jaccard_similarity']:.3f}\")\n",
    "    print(f\"   Cross-sell potential: {row['cross_sell_potential']} compartments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a1920e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize service co-occurrence network\n",
    "\n",
    "# Create network visualization of top service relationships\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 14))\n",
    "fig.suptitle('Cross-Selling Opportunity Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Top Service Pairs Heatmap\n",
    "ax1 = axes[0, 0]\n",
    "top_15_services = service_summary.head(15)['service'].values\n",
    "\n",
    "# Build adjacency matrix for top services\n",
    "adjacency = np.zeros((len(top_15_services), len(top_15_services)))\n",
    "for i, s1 in enumerate(top_15_services):\n",
    "    for j, s2 in enumerate(top_15_services):\n",
    "        if i != j:\n",
    "            pair_data = cooccurrence_df[\n",
    "                ((cooccurrence_df['service1'] == s1) & (cooccurrence_df['service2'] == s2)) |\n",
    "                ((cooccurrence_df['service1'] == s2) & (cooccurrence_df['service2'] == s1))\n",
    "            ]\n",
    "            if not pair_data.empty:\n",
    "                adjacency[i, j] = pair_data.iloc[0]['compartments_both']\n",
    "\n",
    "im1 = ax1.imshow(adjacency, cmap='YlOrRd', aspect='auto')\n",
    "ax1.set_xticks(range(len(top_15_services)))\n",
    "ax1.set_yticks(range(len(top_15_services)))\n",
    "ax1.set_xticklabels([s[:20] + '...' if len(s) > 20 else s for s in top_15_services], rotation=45, ha='right', fontsize=8)\n",
    "ax1.set_yticklabels([s[:20] + '...' if len(s) > 20 else s for s in top_15_services], fontsize=8)\n",
    "ax1.set_title('Service Co-occurrence Matrix\\n(Number of shared compartments)', fontweight='bold')\n",
    "plt.colorbar(im1, ax=ax1, label='Compartments')\n",
    "\n",
    "# 2. Cross-sell potential by service\n",
    "ax2 = axes[0, 1]\n",
    "# Calculate cross-sell score for each service\n",
    "cross_sell_scores = {}\n",
    "for service in top_15_services:\n",
    "    # Find all pairs where this service appears\n",
    "    service_pairs = cooccurrence_df[\n",
    "        (cooccurrence_df['service1'] == service) | (cooccurrence_df['service2'] == service)\n",
    "    ]\n",
    "    \n",
    "    # Sum up cross-sell potential\n",
    "    total_potential = 0\n",
    "    for _, row in service_pairs.iterrows():\n",
    "        if row['service1'] == service:\n",
    "            total_potential += row['compartments_s2_only']\n",
    "        else:\n",
    "            total_potential += row['compartments_s1_only']\n",
    "    \n",
    "    cross_sell_scores[service] = total_potential\n",
    "\n",
    "# Sort and plot\n",
    "cross_sell_df = pd.DataFrame(list(cross_sell_scores.items()), columns=['service', 'cross_sell_potential'])\n",
    "cross_sell_df = cross_sell_df.sort_values('cross_sell_potential', ascending=True)\n",
    "\n",
    "ax2.barh(range(len(cross_sell_df)), cross_sell_df['cross_sell_potential'].values, \n",
    "         color=plt.cm.viridis(np.linspace(0, 1, len(cross_sell_df))))\n",
    "ax2.set_yticks(range(len(cross_sell_df)))\n",
    "ax2.set_yticklabels([s[:30] + '...' if len(s) > 30 else s for s in cross_sell_df['service'].values], fontsize=9)\n",
    "ax2.set_xlabel('Cross-Sell Opportunities (Compartments)')\n",
    "ax2.set_title('Service Cross-Sell Potential', fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# 3. Service Adoption Gap Analysis by Region\n",
    "ax3 = axes[1, 0]\n",
    "top_8_services = service_summary.head(8)['service'].values\n",
    "top_8_regions = regional_analysis.head(8)['region'].values\n",
    "\n",
    "# Build adoption matrix (1 if service used in region, 0 otherwise)\n",
    "adoption_matrix = np.zeros((len(top_8_services), len(top_8_regions)))\n",
    "for i, service in enumerate(top_8_services):\n",
    "    for j, region in enumerate(top_8_regions):\n",
    "        count = len(df[(df['service'] == service) & (df['region'] == region)])\n",
    "        adoption_matrix[i, j] = 1 if count > 0 else 0\n",
    "\n",
    "im3 = ax3.imshow(adoption_matrix, cmap='RdYlGn', aspect='auto', vmin=0, vmax=1)\n",
    "ax3.set_xticks(range(len(top_8_regions)))\n",
    "ax3.set_yticks(range(len(top_8_services)))\n",
    "ax3.set_xticklabels(top_8_regions, rotation=45, ha='right', fontsize=9)\n",
    "ax3.set_yticklabels([s[:25] + '...' if len(s) > 25 else s for s in top_8_services], fontsize=9)\n",
    "ax3.set_title('Service Adoption by Region\\n(Red = Gap Opportunity, Green = Adopted)', fontweight='bold')\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(len(top_8_services)):\n",
    "    for j in range(len(top_8_regions)):\n",
    "        text = ax3.text(j, i, '‚úì' if adoption_matrix[i, j] == 1 else '‚úó',\n",
    "                       ha=\"center\", va=\"center\", color=\"white\" if adoption_matrix[i, j] == 1 else \"black\",\n",
    "                       fontsize=10, fontweight='bold')\n",
    "\n",
    "# 4. Top Cross-Sell Opportunities (specific recommendations)\n",
    "ax4 = axes[1, 1]\n",
    "ax4.axis('off')\n",
    "\n",
    "# Find top specific cross-sell opportunities\n",
    "recommendations = []\n",
    "for _, row in cooccurrence_df.head(20).iterrows():\n",
    "    if row['cross_sell_potential'] > 10:  # Significant opportunity\n",
    "        recommendations.append({\n",
    "            'primary': row['service1'][:35],\n",
    "            'cross_sell': row['service2'][:35],\n",
    "            'potential': row['cross_sell_potential'],\n",
    "            'together': row['compartments_both']\n",
    "        })\n",
    "\n",
    "# Display as table\n",
    "table_data = []\n",
    "table_data.append(['Primary Service', 'Cross-Sell To', 'Potential', 'Current'])\n",
    "table_data.append(['-'*35, '-'*35, '-'*10, '-'*10])\n",
    "\n",
    "for rec in recommendations[:10]:\n",
    "    table_data.append([\n",
    "        rec['primary'][:35],\n",
    "        rec['cross_sell'][:35],\n",
    "        f\"{rec['potential']} comps\",\n",
    "        f\"{rec['together']} comps\"\n",
    "    ])\n",
    "\n",
    "ax4.text(0.5, 0.95, 'TOP CROSS-SELL RECOMMENDATIONS', \n",
    "         ha='center', va='top', fontsize=14, fontweight='bold', transform=ax4.transAxes)\n",
    "\n",
    "y_position = 0.88\n",
    "for row in table_data:\n",
    "    if row[0].startswith('-'):\n",
    "        ax4.text(0.05, y_position, row[0], fontsize=8, family='monospace', transform=ax4.transAxes)\n",
    "        ax4.text(0.42, y_position, row[1], fontsize=8, family='monospace', transform=ax4.transAxes)\n",
    "        ax4.text(0.78, y_position, row[2], fontsize=8, family='monospace', transform=ax4.transAxes)\n",
    "        ax4.text(0.90, y_position, row[3], fontsize=8, family='monospace', transform=ax4.transAxes)\n",
    "    else:\n",
    "        ax4.text(0.05, y_position, row[0], fontsize=8, family='monospace', transform=ax4.transAxes)\n",
    "        ax4.text(0.42, y_position, row[1], fontsize=8, family='monospace', transform=ax4.transAxes)\n",
    "        ax4.text(0.78, y_position, row[2], fontsize=8, family='monospace', transform=ax4.transAxes, \n",
    "                color='darkgreen' if 'comps' in row[2] else 'black')\n",
    "        ax4.text(0.90, y_position, row[3], fontsize=8, family='monospace', transform=ax4.transAxes)\n",
    "    y_position -= 0.08\n",
    "\n",
    "plt.tight_layout()\n",
    "print(\"‚úÖ Cross-Selling Analysis visualization complete\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2f6c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Service Bundle Analysis - Identify common service combinations\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SERVICE BUNDLE RECOMMENDATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Find most common 3-service bundles\n",
    "from collections import Counter\n",
    "\n",
    "service_bundles = []\n",
    "for comp in df['compartmentName'].unique():\n",
    "    comp_services = sorted(df[df['compartmentName'] == comp]['service'].unique())\n",
    "    if len(comp_services) >= 3:\n",
    "        # Generate all 3-service combinations\n",
    "        for combo in combinations(comp_services, 3):\n",
    "            service_bundles.append(tuple(sorted(combo)))\n",
    "\n",
    "bundle_counts = Counter(service_bundles)\n",
    "top_bundles = bundle_counts.most_common(15)\n",
    "\n",
    "print(f\"\\nüì¶ TOP 15 THREE-SERVICE BUNDLES:\")\n",
    "print(\"-\"*80)\n",
    "for idx, (bundle, count) in enumerate(top_bundles, 1):\n",
    "    print(f\"\\n{idx}. Bundle used by {count} compartments:\")\n",
    "    for service in bundle:\n",
    "        print(f\"   ‚Ä¢ {service[:70]}\")\n",
    "\n",
    "# Visualize bundle popularity\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "fig.suptitle('Service Bundle Analysis', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Bundle frequency chart\n",
    "ax1 = axes[0]\n",
    "bundle_names = [f\"Bundle {i+1}\" for i in range(min(10, len(top_bundles)))]\n",
    "bundle_freqs = [count for _, count in top_bundles[:10]]\n",
    "\n",
    "bars = ax1.barh(range(len(bundle_names)), bundle_freqs, color=plt.cm.Paired(np.linspace(0, 1, len(bundle_names))))\n",
    "ax1.set_yticks(range(len(bundle_names)))\n",
    "ax1.set_yticklabels(bundle_names)\n",
    "ax1.set_xlabel('Number of Compartments Using Bundle')\n",
    "ax1.set_title('Most Popular 3-Service Bundles', fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Add value labels\n",
    "for i, (bar, freq) in enumerate(zip(bars, bundle_freqs)):\n",
    "    ax1.text(freq + 0.5, i, str(freq), va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Service diversity per compartment\n",
    "ax2 = axes[1]\n",
    "comp_service_counts = df.groupby('compartmentName')['service'].nunique().reset_index()\n",
    "comp_service_counts.columns = ['compartment', 'num_services']\n",
    "\n",
    "# Create histogram\n",
    "bins = [1, 2, 3, 5, 10, 20, 50, 100]\n",
    "hist, bin_edges = np.histogram(comp_service_counts['num_services'], bins=bins)\n",
    "\n",
    "ax2.bar(range(len(hist)), hist, color='teal', alpha=0.7, edgecolor='black')\n",
    "ax2.set_xticks(range(len(hist)))\n",
    "ax2.set_xticklabels([f\"{bins[i]}-{bins[i+1]}\" for i in range(len(bins)-1)], rotation=45)\n",
    "ax2.set_xlabel('Number of Services per Compartment')\n",
    "ax2.set_ylabel('Number of Compartments')\n",
    "ax2.set_title('Service Diversity Distribution', fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add percentage labels\n",
    "total_comps = len(comp_service_counts)\n",
    "for i, count in enumerate(hist):\n",
    "    percentage = (count / total_comps) * 100\n",
    "    ax2.text(i, count + max(hist)*0.02, f'{count}\\n({percentage:.1f}%)', \n",
    "            ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "print(\"\\n‚úÖ Service Bundle visualization complete\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate bundle uplift potential\n",
    "print(f\"\\nüí° BUNDLE UPLIFT ANALYSIS:\")\n",
    "print(\"-\"*80)\n",
    "print(f\"Total Compartments: {len(df['compartmentName'].unique())}\")\n",
    "print(f\"Avg Services per Compartment: {comp_service_counts['num_services'].mean():.1f}\")\n",
    "print(f\"Median Services per Compartment: {comp_service_counts['num_services'].median():.0f}\")\n",
    "print(f\"\\nCompartments with 1-2 services: {len(comp_service_counts[comp_service_counts['num_services'] <= 2])} \"\n",
    "      f\"({len(comp_service_counts[comp_service_counts['num_services'] <= 2])/total_comps*100:.1f}%)\")\n",
    "print(f\"   ‚Üí High potential for bundle upsell\")\n",
    "print(f\"\\nCompartments with 10+ services: {len(comp_service_counts[comp_service_counts['num_services'] >= 10])} \"\n",
    "      f\"({len(comp_service_counts[comp_service_counts['num_services'] >= 10])/total_comps*100:.1f}%)\")\n",
    "print(f\"   ‚Üí Premium customers, focus on optimization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fd35cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compartment Segmentation for Targeted Cross-Selling\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARTMENT SEGMENTATION FOR CROSS-SELLING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Segment compartments by service adoption and spending\n",
    "compartment_profiles = df.groupby('compartmentName').agg({\n",
    "    'computedAmount': 'sum',\n",
    "    'service': 'nunique',\n",
    "    'resourceId': 'nunique',\n",
    "    'region': 'nunique'\n",
    "}).reset_index()\n",
    "compartment_profiles.columns = ['compartment', 'total_spend', 'num_services', 'num_resources', 'num_regions']\n",
    "\n",
    "# Calculate percentiles for segmentation\n",
    "spend_q33 = compartment_profiles['total_spend'].quantile(0.33)\n",
    "spend_q66 = compartment_profiles['total_spend'].quantile(0.66)\n",
    "service_q33 = compartment_profiles['num_services'].quantile(0.33)\n",
    "service_q66 = compartment_profiles['num_services'].quantile(0.66)\n",
    "\n",
    "# Create segments\n",
    "def segment_compartment(row):\n",
    "    if row['total_spend'] >= spend_q66 and row['num_services'] >= service_q66:\n",
    "        return 'Enterprise (High Spend, High Diversity)'\n",
    "    elif row['total_spend'] >= spend_q66 and row['num_services'] < service_q66:\n",
    "        return 'High Value (High Spend, Low Diversity)'\n",
    "    elif row['total_spend'] < spend_q33 and row['num_services'] < service_q33:\n",
    "        return 'Starter (Low Spend, Low Diversity)'\n",
    "    elif row['total_spend'] < spend_q33 and row['num_services'] >= service_q66:\n",
    "        return 'Diverse Small (Low Spend, High Diversity)'\n",
    "    elif row['num_services'] >= service_q66:\n",
    "        return 'Growing (Mid Spend, High Diversity)'\n",
    "    elif row['total_spend'] >= spend_q66:\n",
    "        return 'Focused High Value (High Spend, Mid Diversity)'\n",
    "    else:\n",
    "        return 'Standard (Mid Spend, Mid Diversity)'\n",
    "\n",
    "compartment_profiles['segment'] = compartment_profiles.apply(segment_compartment, axis=1)\n",
    "\n",
    "# Visualize segmentation\n",
    "fig = plt.figure(figsize=(18, 10))\n",
    "\n",
    "# 1. Scatter plot with segments\n",
    "ax1 = plt.subplot(2, 2, 1)\n",
    "segments = compartment_profiles['segment'].unique()\n",
    "colors_seg = plt.cm.Set3(np.linspace(0, 1, len(segments)))\n",
    "color_map = dict(zip(segments, colors_seg))\n",
    "\n",
    "for segment in segments:\n",
    "    seg_data = compartment_profiles[compartment_profiles['segment'] == segment]\n",
    "    ax1.scatter(seg_data['num_services'], seg_data['total_spend'], \n",
    "               label=segment, alpha=0.6, s=100, color=color_map[segment], edgecolors='black', linewidth=0.5)\n",
    "\n",
    "ax1.set_xlabel('Number of Services', fontsize=11, fontweight='bold')\n",
    "ax1.set_ylabel('Total Spend ($)', fontsize=11, fontweight='bold')\n",
    "ax1.set_title('Compartment Segmentation', fontsize=12, fontweight='bold')\n",
    "ax1.legend(loc='best', fontsize=8)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.axhline(y=spend_q66, color='red', linestyle='--', alpha=0.5, linewidth=1)\n",
    "ax1.axhline(y=spend_q33, color='orange', linestyle='--', alpha=0.5, linewidth=1)\n",
    "ax1.axvline(x=service_q66, color='red', linestyle='--', alpha=0.5, linewidth=1)\n",
    "ax1.axvline(x=service_q33, color='orange', linestyle='--', alpha=0.5, linewidth=1)\n",
    "\n",
    "# 2. Segment distribution\n",
    "ax2 = plt.subplot(2, 2, 2)\n",
    "segment_counts = compartment_profiles['segment'].value_counts()\n",
    "colors_pie2 = [color_map[seg] for seg in segment_counts.index]\n",
    "wedges, texts, autotexts = ax2.pie(segment_counts.values, labels=segment_counts.index, \n",
    "                                     autopct='%1.1f%%', colors=colors_pie2, startangle=90)\n",
    "for autotext in autotexts:\n",
    "    autotext.set_color('black')\n",
    "    autotext.set_fontweight('bold')\n",
    "    autotext.set_fontsize(9)\n",
    "ax2.set_title('Compartment Distribution by Segment', fontsize=12, fontweight='bold')\n",
    "\n",
    "# 3. Cross-sell opportunity by segment\n",
    "ax3 = plt.subplot(2, 2, 3)\n",
    "segment_opportunities = []\n",
    "for segment in segments:\n",
    "    seg_comps = compartment_profiles[compartment_profiles['segment'] == segment]['compartment'].values\n",
    "    avg_services = compartment_profiles[compartment_profiles['segment'] == segment]['num_services'].mean()\n",
    "    max_services_available = df['service'].nunique()\n",
    "    opportunity = max_services_available - avg_services\n",
    "    segment_opportunities.append({\n",
    "        'segment': segment,\n",
    "        'avg_services': avg_services,\n",
    "        'opportunity': opportunity,\n",
    "        'count': len(seg_comps)\n",
    "    })\n",
    "\n",
    "seg_opp_df = pd.DataFrame(segment_opportunities).sort_values('opportunity', ascending=True)\n",
    "bars3 = ax3.barh(range(len(seg_opp_df)), seg_opp_df['opportunity'].values,\n",
    "                color=[color_map[s] for s in seg_opp_df['segment'].values], alpha=0.7, edgecolor='black')\n",
    "ax3.set_yticks(range(len(seg_opp_df)))\n",
    "ax3.set_yticklabels([s[:30] for s in seg_opp_df['segment'].values], fontsize=9)\n",
    "ax3.set_xlabel('Avg Services Gap (Cross-sell Potential)', fontsize=10, fontweight='bold')\n",
    "ax3.set_title('Cross-Sell Opportunity by Segment', fontsize=12, fontweight='bold')\n",
    "ax3.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Add value labels\n",
    "for i, (opp, count) in enumerate(zip(seg_opp_df['opportunity'].values, seg_opp_df['count'].values)):\n",
    "    ax3.text(opp + 1, i, f'{opp:.1f} ({count} comps)', va='center', fontsize=8)\n",
    "\n",
    "# 4. Segment recommendations\n",
    "ax4 = plt.subplot(2, 2, 4)\n",
    "ax4.axis('off')\n",
    "\n",
    "recommendations_text = \"\"\"\n",
    "SEGMENT-SPECIFIC RECOMMENDATIONS:\n",
    "\n",
    "üè¢ Enterprise (High Spend, High Diversity)\n",
    "   ‚Ä¢ Focus: Optimization & Advanced Features\n",
    "   ‚Ä¢ Action: Premium support, custom solutions\n",
    "   ‚Ä¢ Cross-sell: Emerging services, add-ons\n",
    "\n",
    "üíé High Value (High Spend, Low Diversity)\n",
    "   ‚Ä¢ Focus: Service Expansion & Diversification\n",
    "   ‚Ä¢ Action: Introduce complementary services\n",
    "   ‚Ä¢ Cross-sell: HIGH PRIORITY - Bundles\n",
    "\n",
    "üå± Starter (Low Spend, Low Diversity)\n",
    "   ‚Ä¢ Focus: Education & Onboarding\n",
    "   ‚Ä¢ Action: Starter bundles, free trials\n",
    "   ‚Ä¢ Cross-sell: Foundational services\n",
    "\n",
    "üìä Diverse Small (Low Spend, High Diversity)\n",
    "   ‚Ä¢ Focus: Usage Optimization\n",
    "   ‚Ä¢ Action: Identify unused services\n",
    "   ‚Ä¢ Cross-sell: Consolidation opportunities\n",
    "\n",
    "üöÄ Growing (Mid Spend, High Diversity)\n",
    "   ‚Ä¢ Focus: Scale & Performance\n",
    "   ‚Ä¢ Action: Growth packages, volume discounts\n",
    "   ‚Ä¢ Cross-sell: Premium tiers\n",
    "\n",
    "‚≠ê Focused High Value (High Spend, Mid Diversity)\n",
    "   ‚Ä¢ Focus: Adjacent Service Adoption\n",
    "   ‚Ä¢ Action: Targeted campaigns\n",
    "   ‚Ä¢ Cross-sell: MEDIUM-HIGH PRIORITY\n",
    "\n",
    "üìà Standard (Mid Spend, Mid Diversity)\n",
    "   ‚Ä¢ Focus: Gradual Expansion\n",
    "   ‚Ä¢ Action: Success stories, use cases\n",
    "   ‚Ä¢ Cross-sell: Popular bundles\n",
    "\"\"\"\n",
    "\n",
    "ax4.text(0.05, 0.95, recommendations_text, transform=ax4.transAxes, \n",
    "        fontsize=9, verticalalignment='top', family='monospace',\n",
    "        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))\n",
    "\n",
    "plt.tight_layout()\n",
    "print(f\"\\n‚úÖ Compartment Segmentation complete\")\n",
    "print(f\"\\nüìä Segment Summary:\")\n",
    "for _, row in seg_opp_df.iterrows():\n",
    "    print(f\"   {row['segment']}: {row['count']} compartments, avg {row['avg_services']:.1f} services, \"\n",
    "          f\"cross-sell gap: {row['opportunity']:.1f} services\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a414e852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-Selling Action Plan Dashboard\n",
    "\n",
    "fig = plt.figure(figsize=(18, 10))\n",
    "fig.suptitle('Cross-Selling Action Plan Dashboard', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Top Priority Cross-Sell Targets (Compartments)\n",
    "ax1 = plt.subplot(2, 3, 1)\n",
    "# Find compartments with high spend but low service diversity\n",
    "high_value_low_div = compartment_profiles[\n",
    "    (compartment_profiles['total_spend'] > compartment_profiles['total_spend'].quantile(0.75)) &\n",
    "    (compartment_profiles['num_services'] < compartment_profiles['num_services'].quantile(0.5))\n",
    "].sort_values('total_spend', ascending=False).head(10)\n",
    "\n",
    "ax1.barh(range(len(high_value_low_div)), high_value_low_div['total_spend'].values,\n",
    "        color='coral', alpha=0.7, edgecolor='black')\n",
    "ax1.set_yticks(range(len(high_value_low_div)))\n",
    "ax1.set_yticklabels([c[:25] + '...' if len(c) > 25 else c for c in high_value_low_div['compartment'].values], fontsize=8)\n",
    "ax1.set_xlabel('Total Spend ($)')\n",
    "ax1.set_title('üéØ Priority Accounts\\n(High Spend, Low Diversity)', fontweight='bold', fontsize=11)\n",
    "ax1.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Add service count annotations\n",
    "for i, (spend, num_svc) in enumerate(zip(high_value_low_div['total_spend'].values, high_value_low_div['num_services'].values)):\n",
    "    ax1.text(spend * 0.5, i, f'{int(num_svc)} svcs', va='center', ha='center', \n",
    "            fontsize=8, fontweight='bold', color='white')\n",
    "\n",
    "# 2. Service Penetration Rate\n",
    "ax2 = plt.subplot(2, 3, 2)\n",
    "# Calculate penetration rate for each service\n",
    "service_penetration = []\n",
    "total_compartments = len(df['compartmentName'].unique())\n",
    "for service in service_summary.head(15)['service'].values:\n",
    "    comps_with_service = len(df[df['service'] == service]['compartmentName'].unique())\n",
    "    penetration = (comps_with_service / total_compartments) * 100\n",
    "    service_penetration.append({\n",
    "        'service': service,\n",
    "        'penetration': penetration,\n",
    "        'comps_count': comps_with_service\n",
    "    })\n",
    "\n",
    "pen_df = pd.DataFrame(service_penetration).sort_values('penetration')\n",
    "colors_pen = ['green' if p > 50 else 'orange' if p > 25 else 'red' for p in pen_df['penetration'].values]\n",
    "\n",
    "ax2.barh(range(len(pen_df)), pen_df['penetration'].values, color=colors_pen, alpha=0.7, edgecolor='black')\n",
    "ax2.set_yticks(range(len(pen_df)))\n",
    "ax2.set_yticklabels([s[:25] + '...' if len(s) > 25 else s for s in pen_df['service'].values], fontsize=8)\n",
    "ax2.set_xlabel('Penetration Rate (%)')\n",
    "ax2.set_title('üìä Service Penetration Rates\\n(Red=Low, Orange=Medium, Green=High)', fontweight='bold', fontsize=11)\n",
    "ax2.axvline(x=50, color='darkgreen', linestyle='--', alpha=0.5, linewidth=2)\n",
    "ax2.axvline(x=25, color='orange', linestyle='--', alpha=0.5, linewidth=2)\n",
    "ax2.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# 3. Regional Service Gap Matrix\n",
    "ax3 = plt.subplot(2, 3, 3)\n",
    "top_5_services = service_summary.head(5)['service'].values\n",
    "top_6_regions = regional_analysis.head(6)['region'].values\n",
    "\n",
    "gap_matrix = np.zeros((len(top_5_services), len(top_6_regions)))\n",
    "for i, service in enumerate(top_5_services):\n",
    "    for j, region in enumerate(top_6_regions):\n",
    "        comps_in_region = len(df[df['region'] == region]['compartmentName'].unique())\n",
    "        comps_with_service = len(df[(df['service'] == service) & (df['region'] == region)]['compartmentName'].unique())\n",
    "        gap_matrix[i, j] = ((comps_in_region - comps_with_service) / comps_in_region * 100) if comps_in_region > 0 else 0\n",
    "\n",
    "im3 = ax3.imshow(gap_matrix, cmap='Reds', aspect='auto')\n",
    "ax3.set_xticks(range(len(top_6_regions)))\n",
    "ax3.set_yticks(range(len(top_5_services)))\n",
    "ax3.set_xticklabels(top_6_regions, rotation=45, ha='right', fontsize=8)\n",
    "ax3.set_yticklabels([s[:20] + '...' if len(s) > 20 else s for s in top_5_services], fontsize=8)\n",
    "ax3.set_title('üó∫Ô∏è Regional Service Gaps (%)\\n(Darker = More Opportunity)', fontweight='bold', fontsize=11)\n",
    "plt.colorbar(im3, ax=ax3, label='Gap %')\n",
    "\n",
    "# 4. Cross-Sell Revenue Potential\n",
    "ax4 = plt.subplot(2, 3, 4)\n",
    "# Estimate revenue potential from cross-selling\n",
    "revenue_potential = []\n",
    "for service in service_summary.head(10)['service'].values:\n",
    "    avg_cost_per_comp = df[df['service'] == service].groupby('compartmentName')['computedAmount'].sum().mean()\n",
    "    comps_with_service = len(df[df['service'] == service]['compartmentName'].unique())\n",
    "    comps_without = total_compartments - comps_with_service\n",
    "    potential_revenue = avg_cost_per_comp * comps_without\n",
    "    \n",
    "    revenue_potential.append({\n",
    "        'service': service,\n",
    "        'potential': potential_revenue,\n",
    "        'targets': comps_without\n",
    "    })\n",
    "\n",
    "rev_df = pd.DataFrame(revenue_potential).sort_values('potential', ascending=False)\n",
    "\n",
    "ax4.bar(range(len(rev_df)), rev_df['potential'].values, \n",
    "       color=plt.cm.plasma(np.linspace(0, 1, len(rev_df))), alpha=0.7, edgecolor='black')\n",
    "ax4.set_xticks(range(len(rev_df)))\n",
    "ax4.set_xticklabels([s[:15] + '...' if len(s) > 15 else s for s in rev_df['service'].values], \n",
    "                    rotation=45, ha='right', fontsize=8)\n",
    "ax4.set_ylabel('Potential Revenue ($)')\n",
    "ax4.set_title('üí∞ Cross-Sell Revenue Potential\\n(If adopted by all compartments)', fontweight='bold', fontsize=11)\n",
    "ax4.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add total potential\n",
    "total_potential = rev_df['potential'].sum()\n",
    "ax4.text(0.5, 0.95, f'Total Potential: ${total_potential:,.0f}', \n",
    "        transform=ax4.transAxes, ha='center', fontsize=10, fontweight='bold',\n",
    "        bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))\n",
    "\n",
    "# 5. Recommended Action Priority Matrix\n",
    "ax5 = plt.subplot(2, 3, 5)\n",
    "# Create action items based on segments\n",
    "action_priorities = []\n",
    "\n",
    "for _, row in seg_opp_df.iterrows():\n",
    "    segment = row['segment']\n",
    "    count = row['count']\n",
    "    opportunity = row['opportunity']\n",
    "    \n",
    "    # Calculate priority score (opportunity * count)\n",
    "    priority_score = opportunity * count\n",
    "    \n",
    "    action_priorities.append({\n",
    "        'segment': segment,\n",
    "        'priority_score': priority_score,\n",
    "        'compartments': count,\n",
    "        'avg_gap': opportunity\n",
    "    })\n",
    "\n",
    "action_df = pd.DataFrame(action_priorities).sort_values('priority_score', ascending=False)\n",
    "\n",
    "# Create bubble chart\n",
    "colors_action = plt.cm.Set2(np.linspace(0, 1, len(action_df)))\n",
    "for i, row in action_df.iterrows():\n",
    "    ax5.scatter(row['avg_gap'], row['compartments'], s=row['priority_score']*20, \n",
    "               alpha=0.6, color=colors_action[i], edgecolors='black', linewidth=1.5)\n",
    "    ax5.text(row['avg_gap'], row['compartments'], action_df.iloc[i].name + 1, \n",
    "            ha='center', va='center', fontweight='bold', fontsize=9)\n",
    "\n",
    "ax5.set_xlabel('Avg Service Gap (Opportunity)', fontweight='bold')\n",
    "ax5.set_ylabel('Number of Compartments', fontweight='bold')\n",
    "ax5.set_title('üéØ Action Priority Matrix\\n(Bubble size = Total Opportunity)', fontweight='bold', fontsize=11)\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Key Metrics Summary\n",
    "ax6 = plt.subplot(2, 3, 6)\n",
    "ax6.axis('off')\n",
    "\n",
    "# Calculate key metrics\n",
    "total_cross_sell_opps = cooccurrence_df['cross_sell_potential'].sum()\n",
    "avg_services_per_comp = compartment_profiles['num_services'].mean()\n",
    "high_priority_comps = len(high_value_low_div)\n",
    "total_rev_potential = rev_df['potential'].sum()\n",
    "\n",
    "metrics_text = f\"\"\"\n",
    "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "‚ïë   CROSS-SELLING KEY METRICS      ‚ïë\n",
    "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "\n",
    "üìä Overall Metrics:\n",
    "   ‚Ä¢ Total Compartments: {total_compartments:,}\n",
    "   ‚Ä¢ Avg Services/Comp: {avg_services_per_comp:.1f}\n",
    "   ‚Ä¢ Total Services: {df['service'].nunique()}\n",
    "\n",
    "üéØ Opportunity Metrics:\n",
    "   ‚Ä¢ Cross-sell Opportunities: {total_cross_sell_opps:,.0f}\n",
    "   ‚Ä¢ High-Priority Accounts: {high_priority_comps}\n",
    "   ‚Ä¢ Revenue Potential: ${total_rev_potential:,.0f}\n",
    "\n",
    "üìà Top Actions:\n",
    "   1. Target High Value/Low Div segment\n",
    "   2. Push top service bundles\n",
    "   3. Fill regional service gaps\n",
    "   4. Upsell to Starter segment\n",
    "\n",
    "üèÜ Focus Areas:\n",
    "   ‚Ä¢ {rev_df.iloc[0]['service'][:35]}\n",
    "     Potential: ${rev_df.iloc[0]['potential']:,.0f}\n",
    "   \n",
    "   ‚Ä¢ {rev_df.iloc[1]['service'][:35]}\n",
    "     Potential: ${rev_df.iloc[1]['potential']:,.0f}\n",
    "   \n",
    "   ‚Ä¢ {rev_df.iloc[2]['service'][:35]}\n",
    "     Potential: ${rev_df.iloc[2]['potential']:,.0f}\n",
    "\n",
    "üí° Next Steps:\n",
    "   ‚Üí Create targeted campaigns\n",
    "   ‚Üí Develop bundle offers\n",
    "   ‚Üí Train sales on co-sell patterns\n",
    "\"\"\"\n",
    "\n",
    "ax6.text(0.05, 0.95, metrics_text, transform=ax6.transAxes, \n",
    "        fontsize=9, verticalalignment='top', family='monospace',\n",
    "        bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.3))\n",
    "\n",
    "plt.tight_layout()\n",
    "print(\"‚úÖ Cross-Selling Action Plan Dashboard complete\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CROSS-SELLING ANALYSIS COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n‚úÖ Total potential cross-sell opportunities identified: {total_cross_sell_opps:,.0f}\")\n",
    "print(f\"üí∞ Estimated revenue potential: ${total_rev_potential:,.0f}\")\n",
    "print(f\"üéØ High-priority accounts for immediate action: {high_priority_comps}\")\n",
    "print(f\"\\nüìä All visualizations embedded in notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb090cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary report as dataframe export\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXECUTIVE SUMMARY - KEY METRICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "summary_metrics = {\n",
    "    'Metric': [\n",
    "        'Total Historical Cost',\n",
    "        'Total Transactions',\n",
    "        'Average Transaction Size',\n",
    "        'Daily Average Cost',\n",
    "        'Monthly Average Cost',\n",
    "        'Current Daily Cost',\n",
    "        'Current Month Cost (partial)',\n",
    "        '',\n",
    "        'Unique Services',\n",
    "        'Unique Regions',\n",
    "        'Unique Compartments',\n",
    "        'Unique Resources',\n",
    "        '',\n",
    "        'Overall Growth Rate (daily)',\n",
    "        'Overall Growth Rate (annualized)',\n",
    "        'Recent MoM Growth',\n",
    "        'Growth Momentum',\n",
    "        '',\n",
    "        'Top Service Market Share',\n",
    "        'Top 3 Services Market Share',\n",
    "        'Top 5 Services Market Share',\n",
    "        '',\n",
    "        'Services with Positive Growth',\n",
    "        'Services with Negative Growth',\n",
    "        'High-Growth Services (>20%)',\n",
    "        'Emerging Services (<60 days)',\n",
    "    ],\n",
    "    'Value': [\n",
    "        f\"${df['computedAmount'].sum():,.2f}\",\n",
    "        f\"{len(df):,}\",\n",
    "        f\"${df['computedAmount'].mean():,.2f}\",\n",
    "        f\"${daily_costs['computedAmount'].mean():,.2f}\",\n",
    "        f\"${monthly_costs['total_cost'].mean():,.2f}\",\n",
    "        f\"${daily_costs['computedAmount'].iloc[-1]:,.2f}\",\n",
    "        f\"${monthly_costs['total_cost'].iloc[-1]:,.2f}\",\n",
    "        '',\n",
    "        f\"{df['service'].nunique()}\",\n",
    "        f\"{df['region'].nunique()}\",\n",
    "        f\"{df['compartmentName'].nunique()}\",\n",
    "        f\"{df['resourceId'].nunique()}\",\n",
    "        '',\n",
    "        f\"{daily_growth_rate:.3f}%\",\n",
    "        f\"{daily_growth_rate * 365:.2f}%\",\n",
    "        f\"{recent_mom:.2f}%\",\n",
    "        f\"{'üöÄ Accelerating' if acceleration > 0 else '‚¨áÔ∏è Decelerating' if acceleration < 0 else '‚û°Ô∏è Stable'}\",\n",
    "        '',\n",
    "        f\"{service_summary.iloc[0]['market_share']:.1f}%\",\n",
    "        f\"{service_summary.head(3)['market_share'].sum():.1f}%\",\n",
    "        f\"{service_summary.head(5)['market_share'].sum():.1f}%\",\n",
    "        '',\n",
    "        f\"{len(growth_df[growth_df['growth_rate'] > 0])}\",\n",
    "        f\"{len(growth_df[growth_df['growth_rate'] < 0])}\",\n",
    "        f\"{len(high_growth)}\",\n",
    "        f\"{len(emerging) if 'emerging' in locals() else 0}\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_metrics)\n",
    "print(\"\\n\" + summary_df.to_string(index=False))\n",
    "\n",
    "# Export key datasets to CSV for further analysis\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXPORTING ANALYSIS RESULTS TO CSV\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Export monthly trends\n",
    "monthly_export = monthly_costs[['year_month', 'total_cost', 'num_services', 'num_regions', 'mom_growth']]\n",
    "monthly_export.to_csv('../output/growth_analysis_monthly_trends.csv', index=False)\n",
    "print(\"‚úÖ Monthly trends exported: growth_analysis_monthly_trends.csv\")\n",
    "\n",
    "# Export service analysis\n",
    "service_export = service_summary[['rank', 'service', 'total_cost', 'market_share', 'num_resources', 'avg_cost_per_row']]\n",
    "service_export.to_csv('../output/growth_analysis_service_breakdown.csv', index=False)\n",
    "print(\"‚úÖ Service breakdown exported: growth_analysis_service_breakdown.csv\")\n",
    "\n",
    "# Export growth analysis\n",
    "growth_export = growth_df[['service', 'total_cost', 'current_monthly', 'growth_rate', 'num_resources', 'market_share']]\n",
    "growth_export.to_csv('../output/growth_analysis_service_growth_rates.csv', index=False)\n",
    "print(\"‚úÖ Service growth rates exported: growth_analysis_service_growth_rates.csv\")\n",
    "\n",
    "# Export regional analysis\n",
    "regional_export = regional_analysis[['region', 'total_cost', 'market_share', 'num_services', 'num_resources']]\n",
    "regional_export.to_csv('../output/growth_analysis_regional_breakdown.csv', index=False)\n",
    "print(\"‚úÖ Regional analysis exported: growth_analysis_regional_breakdown.csv\")\n",
    "\n",
    "# Export compartment analysis\n",
    "compartment_export = compartment_analysis[['compartment', 'total_cost', 'market_share', 'num_services', 'num_resources']]\n",
    "compartment_export.to_csv('../output/growth_analysis_compartment_breakdown.csv', index=False)\n",
    "print(\"‚úÖ Compartment analysis exported: growth_analysis_compartment_breakdown.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n‚úÖ All visualizations and exports have been saved to ../output/\")\n",
    "print(f\"üìä Open the generated CSV files for detailed reporting and further analysis\")\n",
    "print(f\"üìà Share the PNG visualizations with stakeholders for decision-making\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fde926",
   "metadata": {},
   "source": [
    "## 14. Upselling Analysis - Premium Tier Upgrades\n",
    "\n",
    "Identify opportunities to upgrade customers to premium/higher-tier services within existing service categories. Focus on customers already using base-tier services who could benefit from enterprise features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534b4dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upselling Analysis: Identify service tier upgrade opportunities\n",
    "print(\"=== UPSELLING ANALYSIS: PREMIUM TIER UPGRADES ===\\n\")\n",
    "\n",
    "# Define upselling pathways (base service -> premium service mappings)\n",
    "upselling_pathways = {\n",
    "    # Compute upgrades\n",
    "    'Compute': {\n",
    "        'premium': 'Container Engine Service',\n",
    "        'description': 'Upgrade to Container Engine (OKE) for cloud-native workloads',\n",
    "        'value_proposition': 'Enable microservices architecture, improve deployment speed'\n",
    "    },\n",
    "    'Block Storage': {\n",
    "        'premium': 'File Storage',\n",
    "        'description': 'Add File Storage for shared file systems',\n",
    "        'value_proposition': 'Enable multi-instance access, NFS protocol support'\n",
    "    },\n",
    "    \n",
    "    # Database upgrades\n",
    "    'Database': {\n",
    "        'premium': 'Autonomous Data Warehouse',\n",
    "        'description': 'Upgrade to Autonomous Database for self-driving capabilities',\n",
    "        'value_proposition': 'Eliminate manual tuning, 99.995% availability SLA'\n",
    "    },\n",
    "    'MySQL': {\n",
    "        'premium': 'Database Management',\n",
    "        'description': 'Add Database Management for comprehensive database monitoring',\n",
    "        'value_proposition': 'Automated performance insights, diagnostics and fleet management'\n",
    "    },\n",
    "    \n",
    "    # Networking upgrades\n",
    "    'Virtual Cloud Network': {\n",
    "        'premium': 'Load Balancer',\n",
    "        'description': 'Add Load Balancer for high availability',\n",
    "        'value_proposition': 'Ensure application uptime, distribute traffic efficiently'\n",
    "    },\n",
    "    'Load Balancer': {\n",
    "        'premium': 'Web Application Firewall',\n",
    "        'description': 'Upgrade to Web Application Firewall for security',\n",
    "        'value_proposition': 'Protect against OWASP Top 10, DDoS protection'\n",
    "    },\n",
    "    \n",
    "    # Storage upgrades\n",
    "    'Object Storage': {\n",
    "        'premium': 'Archive Storage',\n",
    "        'description': 'Add Archive Storage for long-term data retention',\n",
    "        'value_proposition': 'Reduce storage costs by 90% for infrequently accessed data'\n",
    "    },\n",
    "    \n",
    "    # Observability upgrades\n",
    "    'Telemetry': {\n",
    "        'premium': 'Logging Analytics',\n",
    "        'description': 'Upgrade to Logging Analytics for advanced insights',\n",
    "        'value_proposition': 'ML-powered log analysis, faster troubleshooting'\n",
    "    },\n",
    "    'Logging': {\n",
    "        'premium': 'Application Performance Monitoring',\n",
    "        'description': 'Add APM for application-level monitoring',\n",
    "        'value_proposition': 'End-to-end transaction tracing, performance optimization'\n",
    "    },\n",
    "    \n",
    "    # Security upgrades\n",
    "    'Oracle Cloud Guard Service': {\n",
    "        'premium': 'Vulnerability Scanning Service',\n",
    "        'description': 'Add Vulnerability Scanning for comprehensive security assessment',\n",
    "        'value_proposition': 'Automated vulnerability detection, compliance monitoring'\n",
    "    },\n",
    "    \n",
    "    # Data & AI upgrades\n",
    "    'Data Flow': {\n",
    "        'premium': 'Data Integration',\n",
    "        'description': 'Upgrade to Data Integration for enterprise ETL/ELT',\n",
    "        'value_proposition': 'No-code data pipelines, advanced transformations'\n",
    "    },\n",
    "    'Data Integration': {\n",
    "        'premium': 'Data Science',\n",
    "        'description': 'Add Data Science platform for ML capabilities',\n",
    "        'value_proposition': 'Build and deploy ML models, predictive analytics'\n",
    "    },\n",
    "    'Analytics': {\n",
    "        'premium': 'Oracle AI Data Platform',\n",
    "        'description': 'Upgrade to AI Data Platform for unified data and AI',\n",
    "        'value_proposition': 'Integrated data lakehouse, AI-powered analytics'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Calculate upselling opportunities\n",
    "upselling_opportunities = []\n",
    "\n",
    "for base_service, upgrade_info in upselling_pathways.items():\n",
    "    premium_service = upgrade_info['premium']\n",
    "    \n",
    "    # Find compartments using base service but not premium service\n",
    "    comps_with_base = set(df[df['service'] == base_service]['compartmentName'].unique())\n",
    "    comps_with_premium = set(df[df['service'] == premium_service]['compartmentName'].unique())\n",
    "    \n",
    "    upsell_targets = comps_with_base - comps_with_premium\n",
    "    \n",
    "    if len(upsell_targets) > 0:\n",
    "        # Calculate potential revenue (assume 30% of base service cost)\n",
    "        base_spend = df[df['service'] == base_service]['computedAmount'].sum()\n",
    "        avg_spend_per_comp = base_spend / len(comps_with_base) if len(comps_with_base) > 0 else 0\n",
    "        potential_revenue = len(upsell_targets) * avg_spend_per_comp * 0.30\n",
    "        \n",
    "        upselling_opportunities.append({\n",
    "            'base_service': base_service,\n",
    "            'premium_service': premium_service,\n",
    "            'compartments_with_base': len(comps_with_base),\n",
    "            'compartments_with_premium': len(comps_with_premium),\n",
    "            'upsell_targets': len(upsell_targets),\n",
    "            'conversion_rate': len(comps_with_premium) / len(comps_with_base) if len(comps_with_base) > 0 else 0,\n",
    "            'base_service_revenue': base_spend,\n",
    "            'potential_upsell_revenue': potential_revenue,\n",
    "            'description': upgrade_info['description'],\n",
    "            'value_proposition': upgrade_info['value_proposition']\n",
    "        })\n",
    "\n",
    "upsell_df = pd.DataFrame(upselling_opportunities)\n",
    "upsell_df = upsell_df.sort_values('potential_upsell_revenue', ascending=False)\n",
    "\n",
    "print(f\"Total Upselling Opportunities Found: {len(upsell_df)}\")\n",
    "print(f\"Total Potential Upsell Revenue: ${upsell_df['potential_upsell_revenue'].sum():,.2f}\")\n",
    "print(f\"Total Compartments with Upsell Potential: {upsell_df['upsell_targets'].sum()}\")\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Display top opportunities\n",
    "print(\"TOP 10 UPSELLING OPPORTUNITIES:\\n\")\n",
    "for idx, row in upsell_df.head(10).iterrows():\n",
    "    print(f\"{row['base_service']} ‚Üí {row['premium_service']}\")\n",
    "    print(f\"  Current Users: {row['compartments_with_base']} | Already Upgraded: {row['compartments_with_premium']}\")\n",
    "    print(f\"  Upsell Targets: {row['upsell_targets']} compartments\")\n",
    "    print(f\"  Conversion Rate: {row['conversion_rate']:.1%}\")\n",
    "    print(f\"  Potential Revenue: ${row['potential_upsell_revenue']:,.2f}\")\n",
    "    print(f\"  üìä {row['description']}\")\n",
    "    print(f\"  üí° Value: {row['value_proposition']}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef0a7ba",
   "metadata": {},
   "source": [
    "## 15. Regional Focus Analysis - Top 3 Regions\n",
    "\n",
    "Most customers operate in 2-3 regions. Focus sales efforts on the most active regions where growth potential is highest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8747840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regional Focus: Analyze top 3 regions for concentrated sales efforts\n",
    "print(\"=== REGIONAL FOCUS: TOP 3 REGIONS FOR SALES EXPANSION ===\\n\")\n",
    "\n",
    "# Identify top 3 regions by cost\n",
    "top_3_regions = df.groupby('region').agg({\n",
    "    'computedAmount': 'sum',\n",
    "    'compartmentName': 'nunique',\n",
    "    'service': 'nunique'\n",
    "}).rename(columns={\n",
    "    'computedAmount': 'total_cost',\n",
    "    'compartmentName': 'compartments',\n",
    "    'service': 'services_used'\n",
    "}).sort_values('total_cost', ascending=False).head(3)\n",
    "\n",
    "print(\"TOP 3 REGIONS BY REVENUE:\\n\")\n",
    "for region, data in top_3_regions.iterrows():\n",
    "    pct_of_total = (data['total_cost'] / df['computedAmount'].sum()) * 100\n",
    "    print(f\"üìç {region}\")\n",
    "    print(f\"   Revenue: ${data['total_cost']:,.2f} ({pct_of_total:.1f}% of total)\")\n",
    "    print(f\"   Compartments: {data['compartments']}\")\n",
    "    print(f\"   Services Used: {data['services_used']}\")\n",
    "    print()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Detailed analysis for each top region\n",
    "top_3_region_names = top_3_regions.index.tolist()\n",
    "regional_insights = []\n",
    "\n",
    "for region in top_3_region_names:\n",
    "    region_df = df[df['region'] == region]\n",
    "    \n",
    "    # Service diversity\n",
    "    services_in_region = region_df['service'].nunique()\n",
    "    total_services = df['service'].nunique()\n",
    "    service_coverage = services_in_region / total_services\n",
    "    \n",
    "    # Top services\n",
    "    top_services_region = region_df.groupby('service')['computedAmount'].sum().sort_values(ascending=False).head(5)\n",
    "    \n",
    "    # Compartment analysis\n",
    "    comps_in_region = region_df['compartmentName'].nunique()\n",
    "    avg_cost_per_comp = region_df['computedAmount'].sum() / comps_in_region\n",
    "    \n",
    "    # Cross-sell opportunities (services used in other top regions but not here)\n",
    "    services_in_region_set = set(region_df['service'].unique())\n",
    "    other_regions = [r for r in top_3_region_names if r != region]\n",
    "    services_in_other_top_regions = set()\n",
    "    for other_region in other_regions:\n",
    "        services_in_other_top_regions.update(df[df['region'] == other_region]['service'].unique())\n",
    "    \n",
    "    cross_sell_opps = services_in_other_top_regions - services_in_region_set\n",
    "    cross_sell_count = len(cross_sell_opps)\n",
    "    \n",
    "    # Upselling opportunities in this region\n",
    "    region_upsell_opps = []\n",
    "    for base_service, upgrade_info in upselling_pathways.items():\n",
    "        premium_service = upgrade_info['premium']\n",
    "        comps_with_base = set(region_df[region_df['service'] == base_service]['compartmentName'].unique())\n",
    "        comps_with_premium = set(region_df[region_df['service'] == premium_service]['compartmentName'].unique())\n",
    "        upsell_targets = comps_with_base - comps_with_premium\n",
    "        \n",
    "        if len(upsell_targets) > 0:\n",
    "            region_upsell_opps.append({\n",
    "                'pathway': f\"{base_service} ‚Üí {premium_service}\",\n",
    "                'targets': len(upsell_targets)\n",
    "            })\n",
    "    \n",
    "    regional_insights.append({\n",
    "        'region': region,\n",
    "        'revenue': region_df['computedAmount'].sum(),\n",
    "        'compartments': comps_in_region,\n",
    "        'services_used': services_in_region,\n",
    "        'service_coverage': service_coverage,\n",
    "        'avg_cost_per_comp': avg_cost_per_comp,\n",
    "        'cross_sell_opportunities': cross_sell_count,\n",
    "        'upsell_opportunities': len(region_upsell_opps),\n",
    "        'top_services': top_services_region.to_dict(),\n",
    "        'top_upsell_pathways': sorted(region_upsell_opps, key=lambda x: x['targets'], reverse=True)[:3]\n",
    "    })\n",
    "\n",
    "# Display detailed insights\n",
    "for insight in regional_insights:\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"REGION: {insight['region']}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    print(f\"üí∞ REVENUE METRICS:\")\n",
    "    print(f\"   Total Revenue: ${insight['revenue']:,.2f}\")\n",
    "    print(f\"   Average per Compartment: ${insight['avg_cost_per_comp']:,.2f}\")\n",
    "    print(f\"   Compartments: {insight['compartments']}\")\n",
    "    print()\n",
    "    \n",
    "    print(f\"üìä SERVICE ADOPTION:\")\n",
    "    print(f\"   Services in Use: {insight['services_used']}/{total_services} ({insight['service_coverage']:.1%} coverage)\")\n",
    "    print(f\"   Cross-Sell Opportunities: {insight['cross_sell_opportunities']} services not yet adopted\")\n",
    "    print(f\"   Upsell Opportunities: {insight['upsell_opportunities']} upgrade pathways available\")\n",
    "    print()\n",
    "    \n",
    "    print(f\"üîù TOP 5 SERVICES BY REVENUE:\")\n",
    "    for idx, (service, cost) in enumerate(insight['top_services'].items(), 1):\n",
    "        print(f\"   {idx}. {service}: ${cost:,.2f}\")\n",
    "    print()\n",
    "    \n",
    "    if insight['top_upsell_pathways']:\n",
    "        print(f\"üéØ TOP UPSELLING OPPORTUNITIES:\")\n",
    "        for idx, pathway in enumerate(insight['top_upsell_pathways'], 1):\n",
    "            print(f\"   {idx}. {pathway['pathway']}\")\n",
    "            print(f\"      ‚Üí {pathway['targets']} compartments ready to upgrade\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"\\n‚úÖ FOCUS STRATEGY: Concentrate sales efforts on these 3 regions which represent\")\n",
    "print(f\"   {(top_3_regions['total_cost'].sum() / df['computedAmount'].sum() * 100):.1f}% of total revenue.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2109d178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizations: Upselling and Regional Focus Dashboard\n",
    "print(\"Creating comprehensive upselling and regional focus visualizations...\\n\")\n",
    "\n",
    "fig = plt.figure(figsize=(20, 16))\n",
    "gs = fig.add_gridspec(4, 3, hspace=0.35, wspace=0.3)\n",
    "\n",
    "# 1. Top Upselling Opportunities\n",
    "ax1 = fig.add_subplot(gs[0, :])\n",
    "top_10_upsell = upsell_df.head(10)\n",
    "pathways = [f\"{row['base_service']}\\n‚Üí {row['premium_service']}\" for _, row in top_10_upsell.iterrows()]\n",
    "revenues = top_10_upsell['potential_upsell_revenue'].values\n",
    "targets = top_10_upsell['upsell_targets'].values\n",
    "\n",
    "x = np.arange(len(pathways))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax1.bar(x - width/2, revenues, width, label='Potential Revenue ($)', color='#2E7D32', alpha=0.8)\n",
    "ax1_twin = ax1.twinx()\n",
    "bars2 = ax1_twin.bar(x + width/2, targets, width, label='Target Compartments', color='#1976D2', alpha=0.8)\n",
    "\n",
    "ax1.set_xlabel('Upselling Pathway', fontsize=11, fontweight='bold')\n",
    "ax1.set_ylabel('Potential Revenue ($)', fontsize=10, fontweight='bold', color='#2E7D32')\n",
    "ax1_twin.set_ylabel('Target Compartments', fontsize=10, fontweight='bold', color='#1976D2')\n",
    "ax1.set_title('Top 10 Upselling Opportunities - Premium Tier Upgrades', fontsize=13, fontweight='bold', pad=15)\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(pathways, rotation=45, ha='right', fontsize=9)\n",
    "ax1.tick_params(axis='y', labelcolor='#2E7D32')\n",
    "ax1_twin.tick_params(axis='y', labelcolor='#1976D2')\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, val in zip(bars1, revenues):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'${val:,.0f}', ha='center', va='bottom', fontsize=8, fontweight='bold', color='#2E7D32')\n",
    "\n",
    "# 2. Upselling Conversion Funnel\n",
    "ax2 = fig.add_subplot(gs[1, 0])\n",
    "top_5_funnel = upsell_df.head(5)\n",
    "funnel_data = []\n",
    "for _, row in top_5_funnel.iterrows():\n",
    "    funnel_data.append({\n",
    "        'stage': f\"{row['base_service'][:15]}...\",\n",
    "        'base_users': row['compartments_with_base'],\n",
    "        'converted': row['compartments_with_premium'],\n",
    "        'targets': row['upsell_targets']\n",
    "    })\n",
    "\n",
    "stages = [d['stage'] for d in funnel_data]\n",
    "base = [d['base_users'] for d in funnel_data]\n",
    "converted = [d['converted'] for d in funnel_data]\n",
    "targets_data = [d['targets'] for d in funnel_data]\n",
    "\n",
    "y_pos = np.arange(len(stages))\n",
    "ax2.barh(y_pos, base, color='#E0E0E0', label='Base Users', alpha=0.7)\n",
    "ax2.barh(y_pos, converted, color='#4CAF50', label='Already Upgraded', alpha=0.9)\n",
    "\n",
    "ax2.set_yticks(y_pos)\n",
    "ax2.set_yticklabels(stages, fontsize=9)\n",
    "ax2.set_xlabel('Number of Compartments', fontsize=10, fontweight='bold')\n",
    "ax2.set_title('Upselling Conversion Funnel\\nTop 5 Pathways', fontsize=11, fontweight='bold')\n",
    "ax2.legend(loc='lower right', fontsize=8)\n",
    "ax2.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Add target labels\n",
    "for i, (target, total) in enumerate(zip(targets_data, base)):\n",
    "    conversion = (total - target) / total * 100 if total > 0 else 0\n",
    "    ax2.text(total + 1, i, f'{target} targets\\n({conversion:.0f}% conv.)', \n",
    "             va='center', fontsize=8, fontweight='bold', color='#D32F2F')\n",
    "\n",
    "# 3. Regional Revenue Distribution (Top 3)\n",
    "ax3 = fig.add_subplot(gs[1, 1])\n",
    "region_revenues = top_3_regions['total_cost'].values\n",
    "region_names = [name[:20] for name in top_3_regions.index]\n",
    "colors_region = ['#1976D2', '#388E3C', '#F57C00']\n",
    "\n",
    "wedges, texts, autotexts = ax3.pie(region_revenues, labels=region_names, autopct='%1.1f%%',\n",
    "                                     colors=colors_region, startangle=90, textprops={'fontsize': 9})\n",
    "for autotext in autotexts:\n",
    "    autotext.set_color('white')\n",
    "    autotext.set_fontweight('bold')\n",
    "    autotext.set_fontsize(10)\n",
    "\n",
    "ax3.set_title(f'Top 3 Regions Revenue Distribution\\nTotal: ${top_3_regions[\"total_cost\"].sum():,.0f}',\n",
    "              fontsize=11, fontweight='bold')\n",
    "\n",
    "# 4. Service Coverage by Top 3 Regions\n",
    "ax4 = fig.add_subplot(gs[1, 2])\n",
    "region_names_short = [insight['region'][:15] + '...' if len(insight['region']) > 15 else insight['region'] \n",
    "                       for insight in regional_insights]\n",
    "services_used = [insight['services_used'] for insight in regional_insights]\n",
    "services_available = [total_services] * len(regional_insights)\n",
    "\n",
    "x_pos = np.arange(len(region_names_short))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax4.bar(x_pos - width/2, services_available, width, label='Total Available', \n",
    "                color='#E0E0E0', alpha=0.7)\n",
    "bars2 = ax4.bar(x_pos + width/2, services_used, width, label='Currently Used', \n",
    "                color='#1976D2', alpha=0.9)\n",
    "\n",
    "ax4.set_ylabel('Number of Services', fontsize=10, fontweight='bold')\n",
    "ax4.set_title('Service Adoption Coverage\\nTop 3 Regions', fontsize=11, fontweight='bold')\n",
    "ax4.set_xticks(x_pos)\n",
    "ax4.set_xticklabels(region_names_short, rotation=30, ha='right', fontsize=9)\n",
    "ax4.legend(fontsize=8)\n",
    "ax4.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add coverage percentage\n",
    "for i, (used, available) in enumerate(zip(services_used, services_available)):\n",
    "    coverage = (used / available) * 100\n",
    "    ax4.text(i, used + 2, f'{coverage:.0f}%', ha='center', fontsize=9, fontweight='bold', color='#1976D2')\n",
    "\n",
    "# 5. Cross-Sell vs Upsell Opportunities by Region\n",
    "ax5 = fig.add_subplot(gs[2, 0])\n",
    "regions_short = [insight['region'][:15] for insight in regional_insights]\n",
    "cross_sell = [insight['cross_sell_opportunities'] for insight in regional_insights]\n",
    "upsell = [insight['upsell_opportunities'] for insight in regional_insights]\n",
    "\n",
    "x = np.arange(len(regions_short))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax5.bar(x - width/2, cross_sell, width, label='Cross-Sell Opps', color='#FF9800', alpha=0.8)\n",
    "bars2 = ax5.bar(x + width/2, upsell, width, label='Upsell Opps', color='#9C27B0', alpha=0.8)\n",
    "\n",
    "ax5.set_ylabel('Number of Opportunities', fontsize=10, fontweight='bold')\n",
    "ax5.set_title('Growth Opportunities by Region\\n(Cross-Sell vs Upsell)', fontsize=11, fontweight='bold')\n",
    "ax5.set_xticks(x)\n",
    "ax5.set_xticklabels(regions_short, rotation=30, ha='right', fontsize=9)\n",
    "ax5.legend(fontsize=8)\n",
    "ax5.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax5.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                 f'{int(height)}', ha='center', va='bottom', fontsize=8, fontweight='bold')\n",
    "\n",
    "# 6. Revenue per Compartment (Top 3 Regions)\n",
    "ax6 = fig.add_subplot(gs[2, 1])\n",
    "avg_costs = [insight['avg_cost_per_comp'] for insight in regional_insights]\n",
    "compartments = [insight['compartments'] for insight in regional_insights]\n",
    "\n",
    "colors_bars = ['#1976D2', '#388E3C', '#F57C00']\n",
    "bars = ax6.bar(regions_short, avg_costs, color=colors_bars, alpha=0.8)\n",
    "\n",
    "ax6.set_ylabel('Average Cost per Compartment ($)', fontsize=10, fontweight='bold')\n",
    "ax6.set_title('Revenue Efficiency by Region\\nAvg. Cost per Compartment', fontsize=11, fontweight='bold')\n",
    "ax6.set_xticklabels(regions_short, rotation=30, ha='right', fontsize=9)\n",
    "ax6.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels with compartment count\n",
    "for bar, cost, comp_count in zip(bars, avg_costs, compartments):\n",
    "    height = bar.get_height()\n",
    "    ax6.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'${cost:,.2f}\\n({comp_count} comps)', ha='center', va='bottom', fontsize=8, fontweight='bold')\n",
    "\n",
    "# 7. Upselling Revenue Potential by Category\n",
    "ax7 = fig.add_subplot(gs[2, 2])\n",
    "# Categorize upselling pathways\n",
    "categories = {\n",
    "    'Compute': ['COMPUTE', 'COMPUTE_MANAGEMENT', 'CONTAINER_ENGINE'],\n",
    "    'Database': ['DATABASE', 'DATABASE_TOOLS', 'AUTONOMOUS_DATABASE', 'DATA_SAFE'],\n",
    "    'Networking': ['VIRTUAL_CLOUD_NETWORK', 'LOAD_BALANCER', 'VPN_CONNECT', 'FASTCONNECT', 'WAF'],\n",
    "    'Storage': ['BLOCK_STORAGE', 'FILE_STORAGE', 'OBJECT_STORAGE', 'ARCHIVE_STORAGE'],\n",
    "    'Observability': ['MONITORING', 'LOGGING', 'LOGGING_ANALYTICS', 'APPLICATION_PERFORMANCE_MONITORING'],\n",
    "    'Security': ['IDENTITY', 'CLOUD_GUARD'],\n",
    "    'Data & AI': ['DATA_CATALOG', 'DATA_INTEGRATION', 'DATA_SCIENCE']\n",
    "}\n",
    "\n",
    "category_revenue = {}\n",
    "for category, services in categories.items():\n",
    "    revenue = upsell_df[upsell_df['base_service'].isin(services)]['potential_upsell_revenue'].sum()\n",
    "    if revenue > 0:\n",
    "        category_revenue[category] = revenue\n",
    "\n",
    "sorted_categories = sorted(category_revenue.items(), key=lambda x: x[1], reverse=True)\n",
    "cat_names = [c[0] for c in sorted_categories]\n",
    "cat_revenues = [c[1] for c in sorted_categories]\n",
    "\n",
    "colors_cat = plt.cm.Set3(np.linspace(0, 1, len(cat_names)))\n",
    "bars = ax7.barh(cat_names, cat_revenues, color=colors_cat, alpha=0.8)\n",
    "\n",
    "ax7.set_xlabel('Potential Revenue ($)', fontsize=10, fontweight='bold')\n",
    "ax7.set_title('Upselling Revenue Potential\\nby Service Category', fontsize=11, fontweight='bold')\n",
    "ax7.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Add value labels\n",
    "for bar, revenue in zip(bars, cat_revenues):\n",
    "    width = bar.get_width()\n",
    "    ax7.text(width, bar.get_y() + bar.get_height()/2.,\n",
    "             f' ${revenue:,.0f}', ha='left', va='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "# 8. Regional Service Heatmap (Top 3 Regions, Top Services)\n",
    "ax8 = fig.add_subplot(gs[3, :2])\n",
    "\n",
    "# Create service-region matrix for top services\n",
    "top_services_global = df.groupby('service')['computedAmount'].sum().sort_values(ascending=False).head(12).index\n",
    "region_service_spend = pd.DataFrame(index=top_3_region_names, columns=top_services_global)\n",
    "\n",
    "for region in top_3_region_names:\n",
    "    for service in top_services_global:\n",
    "        spend = df[(df['region'] == region) & (df['service'] == service)]['computedAmount'].sum()\n",
    "        region_service_spend.loc[region, service] = spend\n",
    "\n",
    "region_service_spend = region_service_spend.fillna(0).astype(float)\n",
    "\n",
    "im = ax8.imshow(region_service_spend.values, cmap='YlOrRd', aspect='auto')\n",
    "ax8.set_xticks(np.arange(len(top_services_global)))\n",
    "ax8.set_yticks(np.arange(len(top_3_region_names)))\n",
    "ax8.set_xticklabels(top_services_global, rotation=45, ha='right', fontsize=9)\n",
    "ax8.set_yticklabels([name[:25] for name in top_3_region_names], fontsize=9)\n",
    "ax8.set_title('Service Spending Heatmap: Top 3 Regions √ó Top 12 Services', fontsize=12, fontweight='bold', pad=15)\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(im, ax=ax8)\n",
    "cbar.set_label('Spending ($)', rotation=270, labelpad=20, fontsize=10, fontweight='bold')\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(len(top_3_region_names)):\n",
    "    for j in range(len(top_services_global)):\n",
    "        value = region_service_spend.values[i, j]\n",
    "        if value > 0:\n",
    "            text = ax8.text(j, i, f'${value:.0f}',\n",
    "                           ha=\"center\", va=\"center\", color=\"black\" if value < region_service_spend.values.max()/2 else \"white\",\n",
    "                           fontsize=7, fontweight='bold')\n",
    "\n",
    "# 9. Sales Priority Matrix\n",
    "ax9 = fig.add_subplot(gs[3, 2])\n",
    "\n",
    "# Create priority matrix data\n",
    "priority_data = []\n",
    "for insight in regional_insights:\n",
    "    total_opps = insight['cross_sell_opportunities'] + insight['upsell_opportunities']\n",
    "    revenue_potential = insight['avg_cost_per_comp'] * total_opps * 0.25  # Estimated 25% conversion\n",
    "    priority_data.append({\n",
    "        'region': insight['region'][:15],\n",
    "        'opportunities': total_opps,\n",
    "        'revenue_potential': revenue_potential,\n",
    "        'compartments': insight['compartments']\n",
    "    })\n",
    "\n",
    "regions_plot = [d['region'] for d in priority_data]\n",
    "opps = [d['opportunities'] for d in priority_data]\n",
    "revenues_plot = [d['revenue_potential'] for d in priority_data]\n",
    "sizes = [d['compartments'] * 3 for d in priority_data]\n",
    "\n",
    "scatter = ax9.scatter(opps, revenues_plot, s=sizes, c=colors_region, alpha=0.6, edgecolors='black', linewidth=2)\n",
    "\n",
    "for i, region in enumerate(regions_plot):\n",
    "    ax9.annotate(region, (opps[i], revenues_plot[i]), fontsize=9, fontweight='bold', \n",
    "                 xytext=(5, 5), textcoords='offset points')\n",
    "\n",
    "ax9.set_xlabel('Total Opportunities (Cross-Sell + Upsell)', fontsize=10, fontweight='bold')\n",
    "ax9.set_ylabel('Estimated Revenue Potential ($)', fontsize=10, fontweight='bold')\n",
    "ax9.set_title('Sales Priority Matrix\\nTop 3 Regions\\n(Bubble size = # Compartments)', \n",
    "              fontsize=11, fontweight='bold')\n",
    "ax9.grid(True, alpha=0.3)\n",
    "\n",
    "# Add quadrant lines\n",
    "ax9.axhline(y=np.median(revenues_plot), color='gray', linestyle='--', alpha=0.5, linewidth=1)\n",
    "ax9.axvline(x=np.median(opps), color='gray', linestyle='--', alpha=0.5, linewidth=1)\n",
    "\n",
    "# Add quadrant labels\n",
    "ax9.text(0.95, 0.95, 'HIGH PRIORITY', transform=ax9.transAxes, fontsize=9, \n",
    "         fontweight='bold', color='#D32F2F', ha='right', va='top',\n",
    "         bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.3))\n",
    "\n",
    "plt.suptitle('üéØ UPSELLING & REGIONAL FOCUS DASHBOARD', fontsize=16, fontweight='bold', y=0.995)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Upselling and Regional Focus Dashboard created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc241c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Upselling and Regional Analysis Data\n",
    "print(\"Exporting upselling and regional focus analysis data...\\n\")\n",
    "\n",
    "# Export upselling opportunities\n",
    "upsell_export = upsell_df.copy()\n",
    "upsell_export.to_csv('../output/upselling_opportunities.csv', index=False)\n",
    "print(f\"‚úÖ Exported: upselling_opportunities.csv ({len(upsell_export)} opportunities)\")\n",
    "\n",
    "# Export regional insights\n",
    "regional_export = pd.DataFrame([{\n",
    "    'region': insight['region'],\n",
    "    'revenue': insight['revenue'],\n",
    "    'compartments': insight['compartments'],\n",
    "    'services_used': insight['services_used'],\n",
    "    'service_coverage_pct': insight['service_coverage'] * 100,\n",
    "    'avg_cost_per_compartment': insight['avg_cost_per_comp'],\n",
    "    'cross_sell_opportunities': insight['cross_sell_opportunities'],\n",
    "    'upsell_opportunities': insight['upsell_opportunities'],\n",
    "    'top_service_1': list(insight['top_services'].keys())[0] if insight['top_services'] else '',\n",
    "    'top_service_1_revenue': list(insight['top_services'].values())[0] if insight['top_services'] else 0,\n",
    "    'top_service_2': list(insight['top_services'].keys())[1] if len(insight['top_services']) > 1 else '',\n",
    "    'top_service_2_revenue': list(insight['top_services'].values())[1] if len(insight['top_services']) > 1 else 0,\n",
    "    'top_service_3': list(insight['top_services'].keys())[2] if len(insight['top_services']) > 2 else '',\n",
    "    'top_service_3_revenue': list(insight['top_services'].values())[2] if len(insight['top_services']) > 2 else 0\n",
    "} for insight in regional_insights])\n",
    "\n",
    "regional_export.to_csv('../output/regional_focus_top3.csv', index=False)\n",
    "print(f\"‚úÖ Exported: regional_focus_top3.csv ({len(regional_export)} regions)\")\n",
    "\n",
    "# Create executive summary\n",
    "exec_summary = {\n",
    "    'total_upsell_opportunities': len(upsell_df),\n",
    "    'total_upsell_revenue_potential': upsell_df['potential_upsell_revenue'].sum(),\n",
    "    'total_compartments_with_upsell_potential': upsell_df['upsell_targets'].sum(),\n",
    "    'top_3_regions': top_3_region_names,\n",
    "    'top_3_regions_revenue': top_3_regions['total_cost'].sum(),\n",
    "    'top_3_regions_pct_of_total': (top_3_regions['total_cost'].sum() / df['computedAmount'].sum()) * 100,\n",
    "    'total_cross_sell_opps_in_top_3': sum([i['cross_sell_opportunities'] for i in regional_insights]),\n",
    "    'total_upsell_opps_in_top_3': sum([i['upsell_opportunities'] for i in regional_insights]),\n",
    "    'avg_service_coverage_top_3': np.mean([i['service_coverage'] for i in regional_insights]) * 100\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXECUTIVE SUMMARY - UPSELLING & REGIONAL FOCUS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüí∞ UPSELLING POTENTIAL:\")\n",
    "print(f\"   Total Opportunities: {exec_summary['total_upsell_opportunities']} upgrade pathways\")\n",
    "print(f\"   Revenue Potential: ${exec_summary['total_upsell_revenue_potential']:,.2f}\")\n",
    "print(f\"   Target Compartments: {exec_summary['total_compartments_with_upsell_potential']}\")\n",
    "\n",
    "print(f\"\\nüìç TOP 3 REGIONS:\")\n",
    "print(f\"   Regions: {', '.join(exec_summary['top_3_regions'])}\")\n",
    "print(f\"   Combined Revenue: ${exec_summary['top_3_regions_revenue']:,.2f}\")\n",
    "print(f\"   % of Total: {exec_summary['top_3_regions_pct_of_total']:.1f}%\")\n",
    "print(f\"   Avg Service Coverage: {exec_summary['avg_service_coverage_top_3']:.1f}%\")\n",
    "\n",
    "print(f\"\\nüéØ GROWTH OPPORTUNITIES IN TOP 3 REGIONS:\")\n",
    "print(f\"   Cross-Sell Opportunities: {exec_summary['total_cross_sell_opps_in_top_3']} services\")\n",
    "print(f\"   Upsell Opportunities: {exec_summary['total_upsell_opps_in_top_3']} pathways\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\n‚úÖ All upselling and regional focus analysis completed!\")\n",
    "print(\"üìä Review the dashboard above for visual insights.\")\n",
    "print(\"üìÅ Check output folder for exported CSV files.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e3eb35",
   "metadata": {},
   "source": [
    "## 16. Cost Tracking & Tagging Analysis for Upsell/Cross-Sell\n",
    "\n",
    "Analyze resource tagging patterns to identify opportunities for improved cost governance and targeted sales campaigns. Untagged or poorly tagged resources represent opportunities to sell tagging/governance solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4313ac97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tagging Analysis: Identify cost governance and compliance opportunities\n",
    "print(\"=== COST TRACKING & TAGGING ANALYSIS ===\\n\")\n",
    "\n",
    "# Analyze tagging compliance\n",
    "df['has_cost_center'] = df['cost_center'] != 'Untagged'\n",
    "df['has_environment'] = df['environment'] != 'Untagged'\n",
    "df['has_team'] = df['team'] != 'Untagged'\n",
    "df['has_any_tag'] = df['has_cost_center'] | df['has_environment'] | df['has_team']\n",
    "\n",
    "# Overall tagging statistics\n",
    "total_cost = df['computedAmount'].sum()\n",
    "tagged_cost = df[df['has_any_tag']]['computedAmount'].sum()\n",
    "untagged_cost = df[~df['has_any_tag']]['computedAmount'].sum()\n",
    "tagging_coverage_pct = (tagged_cost / total_cost) * 100\n",
    "\n",
    "print(f\"üìä OVERALL TAGGING COMPLIANCE:\")\n",
    "print(f\"   Total Cost: ${total_cost:,.2f}\")\n",
    "print(f\"   Tagged Resources: ${tagged_cost:,.2f} ({tagging_coverage_pct:.1f}%)\")\n",
    "print(f\"   Untagged Resources: ${untagged_cost:,.2f} ({100-tagging_coverage_pct:.1f}%)\")\n",
    "print()\n",
    "\n",
    "# Tagging by standard keys\n",
    "cost_center_tagged = df[df['has_cost_center']]['computedAmount'].sum()\n",
    "environment_tagged = df[df['has_environment']]['computedAmount'].sum()\n",
    "team_tagged = df[df['has_team']]['computedAmount'].sum()\n",
    "\n",
    "print(f\"üìã TAG KEY COVERAGE:\")\n",
    "print(f\"   CostCenter Tag: ${cost_center_tagged:,.2f} ({cost_center_tagged/total_cost*100:.1f}%)\")\n",
    "print(f\"   Environment Tag: ${environment_tagged:,.2f} ({environment_tagged/total_cost*100:.1f}%)\")\n",
    "print(f\"   Team Tag: ${team_tagged:,.2f} ({team_tagged/total_cost*100:.1f}%)\")\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Tagging compliance by compartment (identify governance opportunities)\n",
    "compartment_tagging = df.groupby('compartmentName').agg({\n",
    "    'computedAmount': 'sum',\n",
    "    'has_any_tag': 'mean',\n",
    "    'has_cost_center': 'mean',\n",
    "    'has_environment': 'mean',\n",
    "    'has_team': 'mean',\n",
    "    'service': 'nunique'\n",
    "}).rename(columns={\n",
    "    'computedAmount': 'total_cost',\n",
    "    'has_any_tag': 'overall_compliance',\n",
    "    'has_cost_center': 'cost_center_compliance',\n",
    "    'has_environment': 'environment_compliance',\n",
    "    'has_team': 'team_compliance',\n",
    "    'service': 'num_services'\n",
    "}).reset_index()\n",
    "\n",
    "compartment_tagging = compartment_tagging.sort_values('total_cost', ascending=False)\n",
    "\n",
    "# Identify governance upsell targets (high spend, low compliance)\n",
    "governance_targets = compartment_tagging[\n",
    "    (compartment_tagging['total_cost'] > compartment_tagging['total_cost'].quantile(0.50)) &\n",
    "    (compartment_tagging['overall_compliance'] < 0.30)\n",
    "].copy()\n",
    "\n",
    "print(f\"üéØ GOVERNANCE UPSELL OPPORTUNITIES:\")\n",
    "print(f\"   High-spend, Low-compliance Compartments: {len(governance_targets)}\")\n",
    "print(f\"   Combined Cost: ${governance_targets['total_cost'].sum():,.2f}\")\n",
    "print(f\"   Average Compliance: {governance_targets['overall_compliance'].mean()*100:.1f}%\")\n",
    "print()\n",
    "\n",
    "if len(governance_targets) > 0:\n",
    "    print(f\"TOP 10 GOVERNANCE TARGETS:\\n\")\n",
    "    for idx, row in governance_targets.head(10).iterrows():\n",
    "        print(f\"üìÅ {row['compartmentName'][:50]}\")\n",
    "        print(f\"   Cost: ${row['total_cost']:,.2f} | Services: {row['num_services']}\")\n",
    "        print(f\"   Compliance: {row['overall_compliance']*100:.0f}% | CostCenter: {row['cost_center_compliance']*100:.0f}% | Environment: {row['environment_compliance']*100:.0f}%\")\n",
    "        print(f\"   üí° Opportunity: Implement tagging policies, cost allocation, showback/chargeback\")\n",
    "        print()\n",
    "\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Tagging patterns by region (identify regional compliance gaps)\n",
    "regional_tagging = df.groupby('region').agg({\n",
    "    'computedAmount': 'sum',\n",
    "    'has_any_tag': 'mean',\n",
    "    'compartmentName': 'nunique'\n",
    "}).rename(columns={\n",
    "    'computedAmount': 'total_cost',\n",
    "    'has_any_tag': 'compliance_rate',\n",
    "    'compartmentName': 'num_compartments'\n",
    "}).sort_values('total_cost', ascending=False).head(10)\n",
    "\n",
    "print(f\"üåç REGIONAL TAGGING COMPLIANCE (Top 10 Regions):\\n\")\n",
    "for region, data in regional_tagging.iterrows():\n",
    "    compliance_status = \"‚úÖ Good\" if data['compliance_rate'] > 0.70 else \"‚ö†Ô∏è Poor\" if data['compliance_rate'] < 0.30 else \"üìä Medium\"\n",
    "    print(f\"{region[:35]:35} | Cost: ${data['total_cost']:>10,.2f} | Compliance: {data['compliance_rate']*100:>5.1f}% {compliance_status}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Service-level tagging analysis (which services are poorly tagged?)\n",
    "service_tagging = df.groupby('service').agg({\n",
    "    'computedAmount': 'sum',\n",
    "    'has_any_tag': 'mean',\n",
    "    'compartmentName': 'nunique'\n",
    "}).rename(columns={\n",
    "    'computedAmount': 'total_cost',\n",
    "    'has_any_tag': 'compliance_rate',\n",
    "    'compartmentName': 'num_compartments'\n",
    "}).sort_values('total_cost', ascending=False)\n",
    "\n",
    "poorly_tagged_services = service_tagging[service_tagging['compliance_rate'] < 0.30].copy()\n",
    "poorly_tagged_services = poorly_tagged_services[poorly_tagged_services['total_cost'] > 10]  # Only significant services\n",
    "\n",
    "print(f\"‚ö†Ô∏è POORLY TAGGED SERVICES (High Cost, Low Compliance):\\n\")\n",
    "if len(poorly_tagged_services) > 0:\n",
    "    for service, data in poorly_tagged_services.head(10).iterrows():\n",
    "        print(f\"{service[:40]:40} | ${data['total_cost']:>10,.2f} | {data['compliance_rate']*100:>5.1f}% tagged\")\n",
    "else:\n",
    "    print(\"   ‚úÖ No major services with poor tagging compliance\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Tag value analysis - identify most common tag values\n",
    "print(f\"üìë TAG VALUE DISTRIBUTION:\\n\")\n",
    "\n",
    "# Cost Center distribution\n",
    "cost_centers = df[df['has_cost_center']].groupby('cost_center')['computedAmount'].sum().sort_values(ascending=False)\n",
    "print(f\"Top 10 Cost Centers:\")\n",
    "for cc, cost in cost_centers.head(10).items():\n",
    "    print(f\"   {cc[:30]:30} | ${cost:>10,.2f}\")\n",
    "print()\n",
    "\n",
    "# Environment distribution\n",
    "environments = df[df['has_environment']].groupby('environment')['computedAmount'].sum().sort_values(ascending=False)\n",
    "print(f\"Environment Breakdown:\")\n",
    "for env, cost in environments.head(10).items():\n",
    "    print(f\"   {env[:30]:30} | ${cost:>10,.2f}\")\n",
    "print()\n",
    "\n",
    "# Team distribution\n",
    "teams = df[df['has_team']].groupby('team')['computedAmount'].sum().sort_values(ascending=False)\n",
    "print(f\"Top 10 Teams:\")\n",
    "for team, cost in teams.head(10).items():\n",
    "    print(f\"   {team[:30]:30} | ${cost:>10,.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Calculate tagging solution revenue opportunity\n",
    "governance_opportunity = {\n",
    "    'untagged_cost': untagged_cost,\n",
    "    'poorly_tagged_compartments': len(governance_targets),\n",
    "    'poorly_tagged_compartment_cost': governance_targets['total_cost'].sum() if len(governance_targets) > 0 else 0,\n",
    "    'estimated_governance_solution_revenue': untagged_cost * 0.02,  # 2% of untagged cost as solution revenue\n",
    "    'showback_chargeback_opportunity': governance_targets['total_cost'].sum() * 0.015 if len(governance_targets) > 0 else 0  # 1.5% for implementation\n",
    "}\n",
    "\n",
    "print(f\"\\nüí∞ GOVERNANCE SOLUTION OPPORTUNITY:\")\n",
    "print(f\"   Untagged Resources: ${governance_opportunity['untagged_cost']:,.2f}\")\n",
    "print(f\"   Governance Solution Revenue Potential: ${governance_opportunity['estimated_governance_solution_revenue']:,.2f}\")\n",
    "print(f\"   Showback/Chargeback Implementation Revenue: ${governance_opportunity['showback_chargeback_opportunity']:,.2f}\")\n",
    "print(f\"   Total Governance Revenue Opportunity: ${governance_opportunity['estimated_governance_solution_revenue'] + governance_opportunity['showback_chargeback_opportunity']:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fa9e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tagging Analysis Visualizations\n",
    "print(\"Creating comprehensive tagging analysis dashboard...\\n\")\n",
    "\n",
    "fig = plt.figure(figsize=(20, 14))\n",
    "gs = fig.add_gridspec(3, 3, hspace=0.35, wspace=0.3)\n",
    "\n",
    "# 1. Overall Tagging Compliance (Pie Chart)\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "tagging_data = [tagged_cost, untagged_cost]\n",
    "tagging_labels = ['Tagged\\nResources', 'Untagged\\nResources']\n",
    "colors_tag = ['#4CAF50', '#F44336']\n",
    "explode = (0.05, 0.1)\n",
    "\n",
    "wedges, texts, autotexts = ax1.pie(tagging_data, labels=tagging_labels, autopct='%1.1f%%',\n",
    "                                     colors=colors_tag, explode=explode, startangle=90,\n",
    "                                     textprops={'fontsize': 10, 'fontweight': 'bold'})\n",
    "for autotext in autotexts:\n",
    "    autotext.set_color('white')\n",
    "    autotext.set_fontsize(11)\n",
    "\n",
    "ax1.set_title(f'Overall Tagging Compliance\\nTotal: ${total_cost:,.0f}', \n",
    "              fontsize=12, fontweight='bold', pad=15)\n",
    "\n",
    "# 2. Tag Key Coverage Breakdown\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "tag_keys = ['CostCenter', 'Environment', 'Team', 'Untagged']\n",
    "tag_costs = [cost_center_tagged, environment_tagged, team_tagged, untagged_cost]\n",
    "colors_keys = ['#2196F3', '#FF9800', '#9C27B0', '#E0E0E0']\n",
    "\n",
    "bars = ax2.barh(tag_keys, tag_costs, color=colors_keys, alpha=0.8)\n",
    "ax2.set_xlabel('Cost ($)', fontsize=10, fontweight='bold')\n",
    "ax2.set_title('Tag Key Coverage by Cost', fontsize=12, fontweight='bold', pad=15)\n",
    "ax2.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Add value labels\n",
    "for bar, cost in zip(bars, tag_costs):\n",
    "    width = bar.get_width()\n",
    "    pct = (cost / total_cost) * 100\n",
    "    ax2.text(width, bar.get_y() + bar.get_height()/2.,\n",
    "             f' ${cost:,.0f} ({pct:.1f}%)', ha='left', va='center', \n",
    "             fontsize=9, fontweight='bold')\n",
    "\n",
    "# 3. Top 10 Governance Targets\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "if len(governance_targets) > 0:\n",
    "    top_gov_targets = governance_targets.head(10).copy()\n",
    "    comp_names_short = [name[:20] + '...' if len(name) > 20 else name \n",
    "                        for name in top_gov_targets['compartmentName']]\n",
    "    costs = top_gov_targets['total_cost'].values\n",
    "    compliance = top_gov_targets['overall_compliance'].values\n",
    "    \n",
    "    y_pos = np.arange(len(comp_names_short))\n",
    "    \n",
    "    # Create horizontal bars colored by compliance\n",
    "    colors_comp = ['#F44336' if c < 0.2 else '#FF9800' if c < 0.3 else '#FFC107' \n",
    "                   for c in compliance]\n",
    "    bars = ax3.barh(y_pos, costs, color=colors_comp, alpha=0.8)\n",
    "    \n",
    "    ax3.set_yticks(y_pos)\n",
    "    ax3.set_yticklabels(comp_names_short, fontsize=8)\n",
    "    ax3.set_xlabel('Cost ($)', fontsize=10, fontweight='bold')\n",
    "    ax3.set_title('Top 10 Governance Targets\\n(High Cost, Low Compliance)', \n",
    "                  fontsize=11, fontweight='bold', pad=15)\n",
    "    ax3.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    # Add compliance percentage labels\n",
    "    for i, (cost, comp) in enumerate(zip(costs, compliance)):\n",
    "        ax3.text(cost + (costs.max() * 0.02), i, f'{comp*100:.0f}%', \n",
    "                va='center', fontsize=8, fontweight='bold', color='#D32F2F')\n",
    "else:\n",
    "    ax3.text(0.5, 0.5, 'No governance targets\\nidentified', \n",
    "             ha='center', va='center', fontsize=12, transform=ax3.transAxes)\n",
    "    ax3.set_xlim(0, 1)\n",
    "    ax3.set_ylim(0, 1)\n",
    "    ax3.axis('off')\n",
    "\n",
    "# 4. Regional Tagging Compliance\n",
    "ax4 = fig.add_subplot(gs[1, 0])\n",
    "top_regions_tag = regional_tagging.head(8)\n",
    "region_names_tag = [r[:20] for r in top_regions_tag.index]\n",
    "compliance_rates = top_regions_tag['compliance_rate'].values * 100\n",
    "region_costs_tag = top_regions_tag['total_cost'].values\n",
    "\n",
    "x_pos = np.arange(len(region_names_tag))\n",
    "width = 0.35\n",
    "\n",
    "# Color bars by compliance level\n",
    "colors_compliance = ['#4CAF50' if c > 70 else '#FFC107' if c > 30 else '#F44336' \n",
    "                     for c in compliance_rates]\n",
    "bars = ax4.bar(x_pos, compliance_rates, color=colors_compliance, alpha=0.8)\n",
    "\n",
    "ax4.set_ylabel('Compliance Rate (%)', fontsize=10, fontweight='bold')\n",
    "ax4.set_title('Regional Tagging Compliance\\nTop 8 Regions', fontsize=11, fontweight='bold')\n",
    "ax4.set_xticks(x_pos)\n",
    "ax4.set_xticklabels(region_names_tag, rotation=45, ha='right', fontsize=8)\n",
    "ax4.axhline(y=70, color='green', linestyle='--', alpha=0.5, linewidth=1, label='Target: 70%')\n",
    "ax4.axhline(y=30, color='red', linestyle='--', alpha=0.5, linewidth=1, label='Critical: 30%')\n",
    "ax4.legend(loc='upper right', fontsize=8)\n",
    "ax4.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels\n",
    "for bar, rate in zip(bars, compliance_rates):\n",
    "    height = bar.get_height()\n",
    "    ax4.text(bar.get_x() + bar.get_width()/2., height + 2,\n",
    "             f'{rate:.0f}%', ha='center', va='bottom', fontsize=8, fontweight='bold')\n",
    "\n",
    "# 5. Tagging Compliance by Service (Top 10 by cost)\n",
    "ax5 = fig.add_subplot(gs[1, 1])\n",
    "top_services_tag = service_tagging.head(10)\n",
    "service_names_short = [s[:25] + '...' if len(s) > 25 else s for s in top_services_tag.index]\n",
    "service_compliance = top_services_tag['compliance_rate'].values * 100\n",
    "service_costs_tag = top_services_tag['total_cost'].values\n",
    "\n",
    "y_pos = np.arange(len(service_names_short))\n",
    "\n",
    "# Base bars for total cost (grey)\n",
    "ax5.barh(y_pos, [100] * len(service_names_short), color='#E0E0E0', alpha=0.3, label='Untagged')\n",
    "\n",
    "# Overlay bars for compliance (colored)\n",
    "colors_svc = ['#4CAF50' if c > 70 else '#FFC107' if c > 30 else '#F44336' \n",
    "              for c in service_compliance]\n",
    "bars = ax5.barh(y_pos, service_compliance, color=colors_svc, alpha=0.8, label='Tagged')\n",
    "\n",
    "ax5.set_yticks(y_pos)\n",
    "ax5.set_yticklabels(service_names_short, fontsize=8)\n",
    "ax5.set_xlabel('Compliance Rate (%)', fontsize=10, fontweight='bold')\n",
    "ax5.set_title('Service Tagging Compliance\\nTop 10 Services by Cost', \n",
    "              fontsize=11, fontweight='bold', pad=15)\n",
    "ax5.set_xlim(0, 100)\n",
    "ax5.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Add compliance labels\n",
    "for i, rate in enumerate(service_compliance):\n",
    "    ax5.text(rate + 2, i, f'{rate:.0f}%', va='center', fontsize=8, fontweight='bold')\n",
    "\n",
    "# 6. Cost Center Distribution (Top 10)\n",
    "ax6 = fig.add_subplot(gs[1, 2])\n",
    "if len(cost_centers) > 0:\n",
    "    top_cc = cost_centers.head(10)\n",
    "    cc_names = [cc[:20] + '...' if len(cc) > 20 else cc for cc in top_cc.index]\n",
    "    cc_costs = top_cc.values\n",
    "    \n",
    "    colors_cc = plt.cm.Set3(np.linspace(0, 1, len(cc_names)))\n",
    "    bars = ax6.barh(cc_names, cc_costs, color=colors_cc, alpha=0.8)\n",
    "    \n",
    "    ax6.set_xlabel('Cost ($)', fontsize=10, fontweight='bold')\n",
    "    ax6.set_title('Top 10 Cost Centers', fontsize=11, fontweight='bold', pad=15)\n",
    "    ax6.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, cost in zip(bars, cc_costs):\n",
    "        width = bar.get_width()\n",
    "        ax6.text(width, bar.get_y() + bar.get_height()/2.,\n",
    "                 f' ${cost:,.0f}', ha='left', va='center', fontsize=8, fontweight='bold')\n",
    "else:\n",
    "    ax6.text(0.5, 0.5, 'No cost center\\ntags found', \n",
    "             ha='center', va='center', fontsize=12, transform=ax6.transAxes)\n",
    "    ax6.axis('off')\n",
    "\n",
    "# 7. Environment Distribution\n",
    "ax7 = fig.add_subplot(gs[2, 0])\n",
    "if len(environments) > 0:\n",
    "    env_data = environments.values\n",
    "    env_labels = environments.index.tolist()\n",
    "    colors_env = ['#1976D2', '#388E3C', '#F57C00', '#C2185B', '#7B1FA2'][:len(env_labels)]\n",
    "    \n",
    "    wedges, texts, autotexts = ax7.pie(env_data, labels=env_labels, autopct='%1.1f%%',\n",
    "                                        colors=colors_env, startangle=90,\n",
    "                                        textprops={'fontsize': 9})\n",
    "    for autotext in autotexts:\n",
    "        autotext.set_color('white')\n",
    "        autotext.set_fontweight('bold')\n",
    "        autotext.set_fontsize(10)\n",
    "    \n",
    "    ax7.set_title(f'Environment Distribution\\nTotal: ${env_data.sum():,.0f}', \n",
    "                  fontsize=11, fontweight='bold')\n",
    "else:\n",
    "    ax7.text(0.5, 0.5, 'No environment\\ntags found', \n",
    "             ha='center', va='center', fontsize=12, transform=ax7.transAxes)\n",
    "    ax7.axis('off')\n",
    "\n",
    "# 8. Governance Opportunity Summary\n",
    "ax8 = fig.add_subplot(gs[2, 1])\n",
    "ax8.axis('off')\n",
    "\n",
    "summary_text = f\"\"\"\n",
    "GOVERNANCE SOLUTION OPPORTUNITIES\n",
    "\n",
    "üìä Tagging Compliance\n",
    "   ‚Ä¢ Overall Coverage: {tagging_coverage_pct:.1f}%\n",
    "   ‚Ä¢ Tagged Cost: ${tagged_cost:,.0f}\n",
    "   ‚Ä¢ Untagged Cost: ${untagged_cost:,.0f}\n",
    "\n",
    "üéØ Target Opportunities\n",
    "   ‚Ä¢ High-Risk Compartments: {len(governance_targets)}\n",
    "   ‚Ä¢ Combined Cost: ${governance_targets['total_cost'].sum() if len(governance_targets) > 0 else 0:,.0f}\n",
    "   ‚Ä¢ Avg. Compliance: {governance_targets['overall_compliance'].mean()*100 if len(governance_targets) > 0 else 0:.1f}%\n",
    "\n",
    "üí∞ Revenue Potential\n",
    "   ‚Ä¢ Tagging Solution: ${governance_opportunity['estimated_governance_solution_revenue']:,.0f}\n",
    "   ‚Ä¢ Showback/Chargeback: ${governance_opportunity['showback_chargeback_opportunity']:,.0f}\n",
    "   ‚Ä¢ Total Opportunity: ${governance_opportunity['estimated_governance_solution_revenue'] + governance_opportunity['showback_chargeback_opportunity']:,.0f}\n",
    "\n",
    "‚úÖ Recommended Actions\n",
    "   1. Implement tag policies for untagged resources\n",
    "   2. Deploy cost allocation/showback for targets\n",
    "   3. Enable automated tagging workflows\n",
    "   4. Establish governance training programs\n",
    "\"\"\"\n",
    "\n",
    "ax8.text(0.05, 0.95, summary_text, transform=ax8.transAxes,\n",
    "         fontsize=10, verticalalignment='top', fontfamily='monospace',\n",
    "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))\n",
    "\n",
    "# 9. Compliance Heatmap: Top Regions vs Tag Keys\n",
    "ax9 = fig.add_subplot(gs[2, 2])\n",
    "\n",
    "# Create compliance matrix\n",
    "top_regions_for_heatmap = regional_tagging.head(6).index\n",
    "tag_key_compliance = pd.DataFrame(index=top_regions_for_heatmap, \n",
    "                                  columns=['CostCenter', 'Environment', 'Team'])\n",
    "\n",
    "for region in top_regions_for_heatmap:\n",
    "    region_data = df[df['region'] == region]\n",
    "    tag_key_compliance.loc[region, 'CostCenter'] = region_data['has_cost_center'].mean() * 100\n",
    "    tag_key_compliance.loc[region, 'Environment'] = region_data['has_environment'].mean() * 100\n",
    "    tag_key_compliance.loc[region, 'Team'] = region_data['has_team'].mean() * 100\n",
    "\n",
    "tag_key_compliance = tag_key_compliance.astype(float)\n",
    "\n",
    "im = ax9.imshow(tag_key_compliance.values, cmap='RdYlGn', aspect='auto', vmin=0, vmax=100)\n",
    "ax9.set_xticks(np.arange(len(tag_key_compliance.columns)))\n",
    "ax9.set_yticks(np.arange(len(tag_key_compliance.index)))\n",
    "ax9.set_xticklabels(tag_key_compliance.columns, fontsize=9, fontweight='bold')\n",
    "ax9.set_yticklabels([r[:20] for r in tag_key_compliance.index], fontsize=8)\n",
    "ax9.set_title('Tag Compliance Heatmap\\nTop 6 Regions √ó Tag Keys', fontsize=11, fontweight='bold', pad=15)\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(im, ax=ax9)\n",
    "cbar.set_label('Compliance %', rotation=270, labelpad=20, fontsize=9, fontweight='bold')\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(len(tag_key_compliance.index)):\n",
    "    for j in range(len(tag_key_compliance.columns)):\n",
    "        value = tag_key_compliance.values[i, j]\n",
    "        color = 'white' if value < 50 else 'black'\n",
    "        text = ax9.text(j, i, f'{value:.0f}%',\n",
    "                       ha=\"center\", va=\"center\", color=color,\n",
    "                       fontsize=9, fontweight='bold')\n",
    "\n",
    "plt.suptitle('üìã COST TRACKING & TAGGING ANALYSIS DASHBOARD', fontsize=16, fontweight='bold', y=0.995)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Tagging analysis dashboard created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4471b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Tagging Analysis Results\n",
    "print(\"Exporting tagging and governance analysis data...\\n\")\n",
    "\n",
    "# Export governance targets\n",
    "if len(governance_targets) > 0:\n",
    "    governance_export = governance_targets.copy()\n",
    "    governance_export['governance_solution_priority'] = governance_export.apply(\n",
    "        lambda x: 'HIGH' if x['total_cost'] > governance_targets['total_cost'].quantile(0.75) else \n",
    "                  'MEDIUM' if x['total_cost'] > governance_targets['total_cost'].quantile(0.50) else 'LOW',\n",
    "        axis=1\n",
    "    )\n",
    "    governance_export.to_csv('../output/tagging_governance_targets.csv', index=False)\n",
    "    print(f\"‚úÖ Exported: tagging_governance_targets.csv ({len(governance_export)} targets)\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No governance targets to export\")\n",
    "\n",
    "# Export regional tagging analysis\n",
    "regional_tag_export = regional_tagging.copy()\n",
    "regional_tag_export.to_csv('../output/regional_tagging_compliance.csv')\n",
    "print(f\"‚úÖ Exported: regional_tagging_compliance.csv ({len(regional_tag_export)} regions)\")\n",
    "\n",
    "# Export service tagging analysis\n",
    "service_tag_export = service_tagging.copy()\n",
    "service_tag_export['compliance_status'] = service_tag_export['compliance_rate'].apply(\n",
    "    lambda x: 'Good' if x > 0.70 else 'Medium' if x > 0.30 else 'Poor'\n",
    ")\n",
    "service_tag_export.to_csv('../output/service_tagging_compliance.csv')\n",
    "print(f\"‚úÖ Exported: service_tagging_compliance.csv ({len(service_tag_export)} services)\")\n",
    "\n",
    "# Export compartment-level tagging for governance teams\n",
    "compartment_tag_export = compartment_tagging.copy()\n",
    "compartment_tag_export['governance_priority'] = compartment_tag_export.apply(\n",
    "    lambda x: 'CRITICAL' if x['total_cost'] > 50 and x['overall_compliance'] < 0.20 else\n",
    "              'HIGH' if x['total_cost'] > 20 and x['overall_compliance'] < 0.40 else\n",
    "              'MEDIUM' if x['overall_compliance'] < 0.60 else 'LOW',\n",
    "    axis=1\n",
    ")\n",
    "compartment_tag_export.to_csv('../output/compartment_tagging_analysis.csv', index=False)\n",
    "print(f\"‚úÖ Exported: compartment_tagging_analysis.csv ({len(compartment_tag_export)} compartments)\")\n",
    "\n",
    "# Create comprehensive tagging summary\n",
    "tagging_summary = {\n",
    "    'overall_compliance': {\n",
    "        'total_cost': total_cost,\n",
    "        'tagged_cost': tagged_cost,\n",
    "        'untagged_cost': untagged_cost,\n",
    "        'tagging_coverage_pct': tagging_coverage_pct\n",
    "    },\n",
    "    'tag_key_coverage': {\n",
    "        'cost_center_tagged': cost_center_tagged,\n",
    "        'cost_center_pct': (cost_center_tagged / total_cost) * 100,\n",
    "        'environment_tagged': environment_tagged,\n",
    "        'environment_pct': (environment_tagged / total_cost) * 100,\n",
    "        'team_tagged': team_tagged,\n",
    "        'team_pct': (team_tagged / total_cost) * 100\n",
    "    },\n",
    "    'governance_targets': {\n",
    "        'num_targets': len(governance_targets),\n",
    "        'target_cost': governance_targets['total_cost'].sum() if len(governance_targets) > 0 else 0,\n",
    "        'avg_compliance': governance_targets['overall_compliance'].mean() if len(governance_targets) > 0 else 0\n",
    "    },\n",
    "    'revenue_opportunity': governance_opportunity\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TAGGING ANALYSIS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüìä OVERALL COMPLIANCE:\")\n",
    "print(f\"   Tagging Coverage: {tagging_coverage_pct:.1f}%\")\n",
    "print(f\"   Tagged Resources: ${tagged_cost:,.2f}\")\n",
    "print(f\"   Untagged Resources: ${untagged_cost:,.2f}\")\n",
    "\n",
    "print(f\"\\nüéØ GOVERNANCE OPPORTUNITIES:\")\n",
    "print(f\"   High-Risk Compartments: {len(governance_targets)}\")\n",
    "print(f\"   Total Cost at Risk: ${governance_targets['total_cost'].sum() if len(governance_targets) > 0 else 0:,.2f}\")\n",
    "\n",
    "print(f\"\\nüí∞ REVENUE POTENTIAL:\")\n",
    "print(f\"   Tagging Solution Revenue: ${governance_opportunity['estimated_governance_solution_revenue']:,.2f}\")\n",
    "print(f\"   Showback/Chargeback Revenue: ${governance_opportunity['showback_chargeback_opportunity']:,.2f}\")\n",
    "print(f\"   Total Governance Opportunity: ${governance_opportunity['estimated_governance_solution_revenue'] + governance_opportunity['showback_chargeback_opportunity']:,.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\n‚úÖ All tagging and governance analysis completed!\")\n",
    "print(\"üìä Review the dashboard above for visual insights.\")\n",
    "print(\"üìÅ Check output folder for exported CSV files.\")\n",
    "print(\"\\nüí° NEXT STEPS:\")\n",
    "print(\"   1. Share governance targets CSV with account teams\")\n",
    "print(\"   2. Develop tagging policy enforcement plan\")\n",
    "print(\"   3. Propose cost allocation/showback implementation\")\n",
    "print(\"   4. Schedule governance training for low-compliance teams\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.9.21)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
