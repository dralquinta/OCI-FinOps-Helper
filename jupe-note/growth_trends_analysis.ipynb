{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73e7ee24",
   "metadata": {},
   "source": [
    "# OCI Services Growth Trends & Sales Planning Analysis\n",
    "\n",
    "**Objective:** Discover growth trends in OCI service consumption, identify expansion opportunities, and develop data-driven sales strategies for increased service adoption across the tenancy.\n",
    "\n",
    "**Analysis Date:** December 2025\n",
    "**Dataset:** output_merged.csv (merged billing and usage data)\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Table of Contents\n",
    "1. Import Required Libraries\n",
    "2. Load and Explore the Merged Dataset\n",
    "3. Data Cleaning and Preprocessing\n",
    "4. Time Series Analysis of Service Consumption\n",
    "5. Growth Rate Calculations and Trends\n",
    "6. Service-Level Consumption Patterns\n",
    "7. Cost Analysis and Revenue Projections\n",
    "8. Identify High-Growth Services\n",
    "9. Regional and Compartment Analysis\n",
    "10. Forecast Future Consumption\n",
    "11. Generate Sales Recommendations and Insights\n",
    "12. Key Metrics and Trends Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229f3d12",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03db7a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.dates import DateFormatter\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Statistical and ML libraries\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "# Configuration\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "# Plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully\")\n",
    "print(f\"üìÖ Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd04bfa",
   "metadata": {},
   "source": [
    "## 2. Load and Explore the Merged Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8167e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the merged dataset\n",
    "file = '../output/output_merged.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(file, low_memory=False)\n",
    "    print(f\"‚úÖ Dataset loaded successfully from {file}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading dataset: {e}\")\n",
    "    df = None\n",
    "\n",
    "if df is not None:\n",
    "    print(f\"\\nüìä Dataset Overview:\")\n",
    "    print(f\"   Shape: {df.shape[0]:,} rows √ó {df.shape[1]} columns\")\n",
    "    print(f\"   Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    \n",
    "    print(f\"\\nüìÖ Time Coverage:\")\n",
    "    print(f\"   Date Range: {df['timeUsageStarted'].min()} to {df['timeUsageEnded'].max()}\")\n",
    "    \n",
    "    print(f\"\\nüí∞ Financial Summary:\")\n",
    "    print(f\"   Total Cost: ${df['computedAmount'].sum():,.2f}\")\n",
    "    print(f\"   Average Cost per Row: ${df['computedAmount'].mean():,.2f}\")\n",
    "    \n",
    "    print(f\"\\nüìã Key Dimensions:\")\n",
    "    print(f\"   Unique Services: {df['service'].nunique()}\")\n",
    "    print(f\"   Unique Regions: {df['region'].nunique()}\")\n",
    "    print(f\"   Unique Compartments: {df['compartmentName'].nunique()}\")\n",
    "    print(f\"   Unique SKUs: {df['skuName'].nunique()}\")\n",
    "    \n",
    "    print(f\"\\nüìä Column Data Types:\")\n",
    "    print(df.dtypes)\n",
    "    \n",
    "    print(f\"\\nüìä First Few Rows:\")\n",
    "    df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be874a3",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd5a336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns to datetime\n",
    "df['timeUsageStarted'] = pd.to_datetime(df['timeUsageStarted'])\n",
    "df['timeUsageEnded'] = pd.to_datetime(df['timeUsageEnded'])\n",
    "\n",
    "# Create date-based features\n",
    "df['date'] = df['timeUsageStarted'].dt.date\n",
    "df['year'] = df['timeUsageStarted'].dt.year\n",
    "df['month'] = df['timeUsageStarted'].dt.month\n",
    "df['year_month'] = df['timeUsageStarted'].dt.strftime('%Y-%m')\n",
    "df['week'] = df['timeUsageStarted'].dt.isocalendar().week\n",
    "df['day_of_week'] = df['timeUsageStarted'].dt.day_name()\n",
    "df['day_of_month'] = df['timeUsageStarted'].dt.day\n",
    "df['quarter'] = df['timeUsageStarted'].dt.quarter\n",
    "\n",
    "# Fill missing values\n",
    "df['service'] = df['service'].fillna('Unknown')\n",
    "df['region'] = df['region'].fillna(df['region_from_call2']).fillna('Unknown')\n",
    "df['compartmentName'] = df['compartmentName'].fillna(df['compartmentPath'].str.split('/').str[-1]).fillna('Unknown')\n",
    "df['skuName'] = df['skuName'].fillna('Unknown SKU')\n",
    "df['computedAmount'] = pd.to_numeric(df['computedAmount'], errors='coerce').fillna(0)\n",
    "df['computedQuantity'] = pd.to_numeric(df['computedQuantity'], errors='coerce').fillna(0)\n",
    "\n",
    "# Handle tags - parse JSON if available\n",
    "def extract_tags(tag_str):\n",
    "    try:\n",
    "        if pd.isna(tag_str) or tag_str == '':\n",
    "            return {}\n",
    "        tags_list = json.loads(tag_str)\n",
    "        return {tag['key']: tag['value'] for tag in tags_list if 'key' in tag and 'value' in tag}\n",
    "    except:\n",
    "        return {}\n",
    "\n",
    "df['tags_dict'] = df['tags'].apply(extract_tags)\n",
    "df['cost_center'] = df['tags_dict'].apply(lambda x: x.get('CostCenter', 'Untagged'))\n",
    "df['environment'] = df['tags_dict'].apply(lambda x: x.get('Environment', 'Untagged'))\n",
    "df['team'] = df['tags_dict'].apply(lambda x: x.get('Team', 'Untagged'))\n",
    "\n",
    "# Remove duplicates if any\n",
    "initial_rows = len(df)\n",
    "df = df.drop_duplicates(subset=['timeUsageStarted', 'service', 'region', 'compartmentName', 'skuName', 'resourceId'])\n",
    "print(f\"‚úÖ Removed {initial_rows - len(df):,} duplicate rows\")\n",
    "\n",
    "print(f\"‚úÖ Data cleaning completed\")\n",
    "print(f\"üìä Final dataset: {len(df):,} rows √ó {df.shape[1]} columns\")\n",
    "print(f\"üìä Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "print(f\"üí∞ Total Cost: ${df['computedAmount'].sum():,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdbe987",
   "metadata": {},
   "source": [
    "## 4. Time Series Analysis of Service Consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e962d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily cost aggregation\n",
    "daily_costs = df.groupby('date').agg({\n",
    "    'computedAmount': 'sum',\n",
    "    'computedQuantity': 'sum',\n",
    "    'service': 'nunique',\n",
    "    'region': 'nunique',\n",
    "    'resourceId': 'count'\n",
    "}).rename(columns={'resourceId': 'transaction_count'}).reset_index()\n",
    "\n",
    "daily_costs['date'] = pd.to_datetime(daily_costs['date'])\n",
    "daily_costs = daily_costs.sort_values('date')\n",
    "\n",
    "# Weekly cost aggregation\n",
    "weekly_costs = df.groupby('year_month').agg({\n",
    "    'computedAmount': 'sum',\n",
    "    'computedQuantity': 'sum',\n",
    "    'service': 'nunique'\n",
    "}).reset_index()\n",
    "\n",
    "# Monthly cost aggregation\n",
    "monthly_costs = df.groupby('year_month').agg({\n",
    "    'computedAmount': 'sum',\n",
    "    'computedQuantity': 'sum',\n",
    "    'service': 'nunique',\n",
    "    'region': 'nunique',\n",
    "    'compartmentName': 'nunique'\n",
    "}).reset_index()\n",
    "monthly_costs.columns = ['year_month', 'total_cost', 'total_quantity', 'num_services', 'num_regions', 'num_compartments']\n",
    "\n",
    "print(f\"‚úÖ Time Series Analysis Completed\")\n",
    "print(f\"\\nüìä Daily Statistics:\")\n",
    "print(f\"   Min Daily Cost: ${daily_costs['computedAmount'].min():,.2f}\")\n",
    "print(f\"   Max Daily Cost: ${daily_costs['computedAmount'].max():,.2f}\")\n",
    "print(f\"   Avg Daily Cost: ${daily_costs['computedAmount'].mean():,.2f}\")\n",
    "print(f\"   Std Dev: ${daily_costs['computedAmount'].std():,.2f}\")\n",
    "\n",
    "print(f\"\\nüìä Monthly Statistics:\")\n",
    "print(f\"   Min Monthly Cost: ${monthly_costs['total_cost'].min():,.2f}\")\n",
    "print(f\"   Max Monthly Cost: ${monthly_costs['total_cost'].max():,.2f}\")\n",
    "print(f\"   Avg Monthly Cost: ${monthly_costs['total_cost'].mean():,.2f}\")\n",
    "\n",
    "print(f\"\\nüìä Monthly Breakdown:\")\n",
    "print(monthly_costs.tail(10))\n",
    "\n",
    "# Create comprehensive time series visualization\n",
    "print(\"\\nCreating time series visualization...\")\n",
    "\n",
    "fig = plt.figure(figsize=(18, 10))\n",
    "gs = fig.add_gridspec(3, 2, hspace=0.3, wspace=0.25)\n",
    "\n",
    "# Main chart: Daily costs with 7-day moving average and trend\n",
    "ax_main = fig.add_subplot(gs[0:2, :])\n",
    "\n",
    "# Plot daily costs as area chart\n",
    "ax_main.fill_between(daily_costs['date'], daily_costs['computedAmount'], \n",
    "                      alpha=0.3, color='#2196F3', label='Daily Cost')\n",
    "ax_main.plot(daily_costs['date'], daily_costs['computedAmount'], \n",
    "             color='#1976D2', linewidth=1.5, alpha=0.7)\n",
    "\n",
    "# Calculate and plot 7-day moving average\n",
    "if len(daily_costs) >= 7:\n",
    "    daily_costs['ma_7'] = daily_costs['computedAmount'].rolling(window=7, min_periods=1).mean()\n",
    "    ax_main.plot(daily_costs['date'], daily_costs['ma_7'], \n",
    "                 color='#FF5722', linewidth=2.5, label='7-Day Moving Average', linestyle='-')\n",
    "\n",
    "# Add trend line\n",
    "if len(daily_costs) > 1:\n",
    "    x_numeric = (daily_costs['date'] - daily_costs['date'].min()).dt.days\n",
    "    z = np.polyfit(x_numeric, daily_costs['computedAmount'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    ax_main.plot(daily_costs['date'], p(x_numeric), \n",
    "                 color='#4CAF50', linewidth=2, linestyle='--', \n",
    "                 label=f'Trend Line ({\"‚Üó\" if z[0] > 0 else \"‚Üò\"} ${z[0]:.2f}/day)', alpha=0.8)\n",
    "\n",
    "# Highlight max and min days\n",
    "max_day = daily_costs.loc[daily_costs['computedAmount'].idxmax()]\n",
    "min_day = daily_costs.loc[daily_costs['computedAmount'].idxmin()]\n",
    "\n",
    "ax_main.scatter([max_day['date']], [max_day['computedAmount']], \n",
    "                color='red', s=150, zorder=5, marker='^', \n",
    "                label=f'Peak: ${max_day[\"computedAmount\"]:.2f}')\n",
    "ax_main.scatter([min_day['date']], [min_day['computedAmount']], \n",
    "                color='green', s=150, zorder=5, marker='v',\n",
    "                label=f'Low: ${min_day[\"computedAmount\"]:.2f}')\n",
    "\n",
    "ax_main.set_xlabel('Date', fontsize=12, fontweight='bold')\n",
    "ax_main.set_ylabel('Daily Cost ($)', fontsize=12, fontweight='bold')\n",
    "ax_main.set_title('Daily Cost Trend Analysis with Moving Average', \n",
    "                  fontsize=14, fontweight='bold', pad=15)\n",
    "ax_main.legend(loc='best', fontsize=10, framealpha=0.9)\n",
    "ax_main.grid(True, alpha=0.3, linestyle='--')\n",
    "ax_main.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Format y-axis as currency\n",
    "ax_main.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x:,.0f}'))\n",
    "\n",
    "# Bottom left: Transaction count over time\n",
    "ax_tx = fig.add_subplot(gs[2, 0])\n",
    "ax_tx.bar(daily_costs['date'], daily_costs['transaction_count'], \n",
    "          color='#9C27B0', alpha=0.7, width=0.8)\n",
    "ax_tx.set_xlabel('Date', fontsize=10, fontweight='bold')\n",
    "ax_tx.set_ylabel('Transactions', fontsize=10, fontweight='bold')\n",
    "ax_tx.set_title('Daily Transaction Volume', fontsize=11, fontweight='bold')\n",
    "ax_tx.grid(True, alpha=0.3, axis='y')\n",
    "ax_tx.tick_params(axis='x', rotation=45, labelsize=8)\n",
    "\n",
    "# Bottom right: Service diversity over time\n",
    "ax_svc = fig.add_subplot(gs[2, 1])\n",
    "ax_svc.plot(daily_costs['date'], daily_costs['service'], \n",
    "            color='#FF9800', linewidth=2, marker='o', markersize=4, alpha=0.8)\n",
    "ax_svc.fill_between(daily_costs['date'], daily_costs['service'], \n",
    "                     alpha=0.2, color='#FF9800')\n",
    "ax_svc.set_xlabel('Date', fontsize=10, fontweight='bold')\n",
    "ax_svc.set_ylabel('Number of Services', fontsize=10, fontweight='bold')\n",
    "ax_svc.set_title('Service Diversity Over Time', fontsize=11, fontweight='bold')\n",
    "ax_svc.grid(True, alpha=0.3)\n",
    "ax_svc.tick_params(axis='x', rotation=45, labelsize=8)\n",
    "\n",
    "# Add summary statistics as text box\n",
    "stats_text = f\"\"\"Key Metrics:\n",
    "‚Ä¢ Total Days: {len(daily_costs)}\n",
    "‚Ä¢ Avg Daily: ${daily_costs['computedAmount'].mean():,.2f}\n",
    "‚Ä¢ Std Dev: ${daily_costs['computedAmount'].std():,.2f}\n",
    "‚Ä¢ Trend: {\"‚Üó Growing\" if z[0] > 0 else \"‚Üò Declining\"} (${z[0]:.2f}/day)\n",
    "‚Ä¢ Total: ${daily_costs['computedAmount'].sum():,.2f}\"\"\"\n",
    "\n",
    "ax_main.text(0.02, 0.98, stats_text, transform=ax_main.transAxes,\n",
    "            fontsize=9, verticalalignment='top', fontfamily='monospace',\n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "\n",
    "plt.suptitle('üìä TIME SERIES COST ANALYSIS', fontsize=16, fontweight='bold', y=0.995)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Time series visualization created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140dcfda",
   "metadata": {},
   "source": [
    "## 5. Growth Rate Calculations and Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09d5d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Month-over-Month (MoM) growth\n",
    "monthly_costs['mom_growth'] = monthly_costs['total_cost'].pct_change() * 100\n",
    "\n",
    "# Calculate Year-over-Year (YoY) growth (if available)\n",
    "yoy_data = df.groupby(['year', 'month']).agg({'computedAmount': 'sum'}).reset_index()\n",
    "yoy_pivot = yoy_data.pivot_table(index='month', columns='year', values='computedAmount')\n",
    "if yoy_pivot.shape[1] >= 2:\n",
    "    latest_year = yoy_pivot.columns[-1]\n",
    "    prev_year = yoy_pivot.columns[-2]\n",
    "    yoy_growth = ((yoy_pivot[latest_year] - yoy_pivot[prev_year]) / yoy_pivot[prev_year] * 100).fillna(0)\n",
    "    print(f\"‚úÖ Year-over-Year Growth Available: {latest_year} vs {prev_year}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Insufficient data for Year-over-Year comparison\")\n",
    "    yoy_growth = None\n",
    "\n",
    "# Linear regression trend analysis\n",
    "X = np.arange(len(daily_costs)).reshape(-1, 1)\n",
    "y = daily_costs['computedAmount'].values\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "daily_costs['trend'] = model.predict(X)\n",
    "\n",
    "slope = model.coef_[0]\n",
    "daily_growth_rate = (slope / daily_costs['computedAmount'].mean()) * 100\n",
    "\n",
    "print(f\"‚úÖ Growth Rate Calculations Completed\")\n",
    "print(f\"\\nüìà Daily Trend Analysis:\")\n",
    "print(f\"   Slope (daily change): ${slope:,.4f}\")\n",
    "print(f\"   Daily Growth Rate: {daily_growth_rate:.3f}% per day\")\n",
    "print(f\"   Annualized Growth Rate: {daily_growth_rate * 365:.2f}%\")\n",
    "\n",
    "print(f\"\\nüìä Month-over-Month Growth:\")\n",
    "print(monthly_costs[['year_month', 'total_cost', 'mom_growth']].tail(12))\n",
    "\n",
    "# Identify acceleration/deceleration\n",
    "recent_mom = monthly_costs['mom_growth'].tail(3).mean()\n",
    "earlier_mom = monthly_costs['mom_growth'].iloc[-12:-3].mean() if len(monthly_costs) > 12 else monthly_costs['mom_growth'].head(3).mean()\n",
    "acceleration = recent_mom - earlier_mom\n",
    "\n",
    "print(f\"\\n‚ö° Growth Momentum:\")\n",
    "print(f\"   Recent MoM (last 3 months): {recent_mom:.2f}%\")\n",
    "print(f\"   Previous MoM (3 months prior): {earlier_mom:.2f}%\")\n",
    "print(f\"   Acceleration: {acceleration:+.2f} percentage points\")\n",
    "if acceleration > 0:\n",
    "    print(f\"   Status: üöÄ ACCELERATING\")\n",
    "elif acceleration < 0:\n",
    "    print(f\"   Status: ‚¨áÔ∏è  DECELERATING\")\n",
    "else:\n",
    "    print(f\"   Status: ‚û°Ô∏è  STABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0d5da4",
   "metadata": {},
   "source": [
    "## 6. Service-Level Consumption Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3732ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Service-level cost breakdown\n",
    "service_summary = df.groupby('service').agg({\n",
    "    'computedAmount': ['sum', 'mean', 'count'],\n",
    "    'computedQuantity': 'sum',\n",
    "    'resourceId': 'nunique'\n",
    "}).reset_index()\n",
    "service_summary.columns = ['service', 'total_cost', 'avg_cost_per_row', 'num_records', 'total_quantity', 'num_resources']\n",
    "service_summary = service_summary.sort_values('total_cost', ascending=False)\n",
    "service_summary['market_share'] = (service_summary['total_cost'] / service_summary['total_cost'].sum() * 100).round(2)\n",
    "service_summary['rank'] = range(1, len(service_summary) + 1)\n",
    "\n",
    "# Top services\n",
    "top_services = service_summary.head(10)\n",
    "print(f\"‚úÖ Service-Level Analysis Completed\")\n",
    "print(f\"\\nüìä Top 10 Services by Cost:\")\n",
    "print(top_services[['rank', 'service', 'total_cost', 'market_share', 'num_resources']])\n",
    "\n",
    "# Service growth trends\n",
    "service_trends = df.groupby(['year_month', 'service']).agg({\n",
    "    'computedAmount': 'sum'\n",
    "}).reset_index()\n",
    "service_trends = service_trends.sort_values(['service', 'year_month'])\n",
    "service_trends['cost_change'] = service_trends.groupby('service')['computedAmount'].pct_change() * 100\n",
    "\n",
    "# Calculate CAGR for each service (if enough data)\n",
    "print(f\"\\nüìà Service Growth Analysis:\")\n",
    "service_cagr = []\n",
    "for service in df['service'].unique()[:10]:  # Top services\n",
    "    service_data = service_trends[service_trends['service'] == service].sort_values('year_month')\n",
    "    if len(service_data) > 1:\n",
    "        first_cost = service_data.iloc[0]['computedAmount']\n",
    "        last_cost = service_data.iloc[-1]['computedAmount']\n",
    "        periods = len(service_data) - 1\n",
    "        if first_cost > 0 and periods > 0:\n",
    "            cagr = ((last_cost / first_cost) ** (1 / periods) - 1) * 100\n",
    "            service_cagr.append({'service': service, 'cagr': cagr, 'current_cost': last_cost})\n",
    "\n",
    "if service_cagr:\n",
    "    service_cagr_df = pd.DataFrame(service_cagr).sort_values('cagr', ascending=False)\n",
    "    print(service_cagr_df.head(10))\n",
    "\n",
    "# Create simple service consumption visualization\n",
    "print(\"\\nCreating service consumption visualization...\")\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "# Left chart: Top 10 Services by Cost (Horizontal bar chart)\n",
    "top_10 = service_summary.head(10).copy()\n",
    "colors_gradient = plt.cm.Blues(np.linspace(0.4, 0.9, len(top_10)))\n",
    "\n",
    "ax1.barh(range(len(top_10)), top_10['total_cost'], color=colors_gradient)\n",
    "ax1.set_yticks(range(len(top_10)))\n",
    "ax1.set_yticklabels([s[:40] + '...' if len(s) > 40 else s for s in top_10['service']], fontsize=10)\n",
    "ax1.set_xlabel('Total Cost ($)', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Top 10 Services by Cost', fontsize=13, fontweight='bold', pad=15)\n",
    "ax1.grid(True, alpha=0.3, axis='x')\n",
    "ax1.invert_yaxis()\n",
    "\n",
    "# Add cost labels and market share\n",
    "for i, (cost, share) in enumerate(zip(top_10['total_cost'], top_10['market_share'])):\n",
    "    ax1.text(cost, i, f' ${cost:,.0f} ({share:.1f}%)', \n",
    "             va='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "# Right chart: Market Share Pie Chart (Top 7 + Others)\n",
    "top_7 = service_summary.head(7)\n",
    "other_cost = service_summary.iloc[7:]['total_cost'].sum()\n",
    "\n",
    "pie_data = list(top_7['total_cost']) + [other_cost]\n",
    "pie_labels = [s[:25] + '...' if len(s) > 25 else s for s in top_7['service']] + ['Others']\n",
    "colors_pie = plt.cm.Set3(np.linspace(0, 1, len(pie_data)))\n",
    "\n",
    "wedges, texts, autotexts = ax2.pie(pie_data, labels=pie_labels, autopct='%1.1f%%',\n",
    "                                     colors=colors_pie, startangle=90,\n",
    "                                     textprops={'fontsize': 9})\n",
    "\n",
    "for autotext in autotexts:\n",
    "    autotext.set_color('white')\n",
    "    autotext.set_fontweight('bold')\n",
    "    autotext.set_fontsize(10)\n",
    "\n",
    "ax2.set_title(f'Service Market Share Distribution\\nTotal: ${service_summary[\"total_cost\"].sum():,.0f}', \n",
    "              fontsize=13, fontweight='bold', pad=15)\n",
    "\n",
    "# Add summary stats box\n",
    "stats_text = f\"\"\"Summary:\n",
    "‚Ä¢ Total Services: {len(service_summary)}\n",
    "‚Ä¢ Top 10 Share: {top_10['market_share'].sum():.1f}%\n",
    "‚Ä¢ Avg Cost/Service: ${service_summary['total_cost'].mean():,.0f}\n",
    "‚Ä¢ Most Resources: {top_10.iloc[0]['service'][:25]}\n",
    "  ({int(top_10.iloc[0]['num_resources'])} resources)\"\"\"\n",
    "\n",
    "ax2.text(1.45, 0.5, stats_text, transform=ax2.transAxes,\n",
    "         fontsize=10, verticalalignment='center', fontfamily='monospace',\n",
    "         bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.3))\n",
    "\n",
    "plt.suptitle('üì¶ SERVICE-LEVEL CONSUMPTION PATTERNS', fontsize=15, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Service consumption visualization created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96a1ed5",
   "metadata": {},
   "source": [
    "## 7. Cost Analysis and Revenue Projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19cf3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost analysis by service category\n",
    "service_cost_analysis = df.groupby('service').agg({\n",
    "    'computedAmount': ['sum', 'min', 'max', 'mean', 'std'],\n",
    "    'computedQuantity': 'sum',\n",
    "    'resourceId': 'count'\n",
    "}).round(2)\n",
    "service_cost_analysis.columns = ['total_cost', 'min_cost', 'max_cost', 'avg_cost', 'std_dev', 'total_quantity', 'transactions']\n",
    "service_cost_analysis = service_cost_analysis.sort_values('total_cost', ascending=False)\n",
    "\n",
    "# Calculate cost per resource\n",
    "service_cost_analysis['cost_per_resource'] = service_cost_analysis['total_cost'] / service_cost_analysis['transactions']\n",
    "\n",
    "print(f\"‚úÖ Cost Analysis Completed\")\n",
    "print(f\"\\nüí∞ Overall Financial Summary:\")\n",
    "print(f\"   Total Spend: ${df['computedAmount'].sum():,.2f}\")\n",
    "print(f\"   Average Transaction Size: ${df['computedAmount'].mean():,.2f}\")\n",
    "print(f\"   Median Transaction Size: ${df['computedAmount'].median():,.2f}\")\n",
    "print(f\"   Max Single Transaction: ${df['computedAmount'].max():,.2f}\")\n",
    "print(f\"   Transactions: {len(df):,}\")\n",
    "\n",
    "print(f\"\\nüí∞ Service Cost Structure:\")\n",
    "print(service_cost_analysis.head(10))\n",
    "\n",
    "# Revenue projections based on growth rates\n",
    "current_monthly_cost = monthly_costs.iloc[-1]['total_cost']\n",
    "print(f\"\\nüìä Revenue Projections (next 12 months):\")\n",
    "print(f\"   Current Monthly Cost: ${current_monthly_cost:,.2f}\")\n",
    "\n",
    "# Conservative, moderate, and aggressive projections\n",
    "growth_scenarios = [\n",
    "    ('Conservative (5% MoM)', 0.05),\n",
    "    ('Moderate (10% MoM)', 0.10),\n",
    "    ('Aggressive (15% MoM)', 0.15)\n",
    "]\n",
    "\n",
    "for scenario_name, growth_rate in growth_scenarios:\n",
    "    projection = current_monthly_cost\n",
    "    total_12m = 0\n",
    "    for month in range(12):\n",
    "        projection = projection * (1 + growth_rate)\n",
    "        total_12m += projection\n",
    "    print(f\"\\n   {scenario_name}:\")\n",
    "    print(f\"      Month 12 Cost: ${projection:,.2f}\")\n",
    "    print(f\"      Total 12-Month: ${total_12m:,.2f}\")\n",
    "    print(f\"      YoY Cost: ${current_monthly_cost * 12:,.2f}\")\n",
    "\n",
    "# Cost optimization opportunities\n",
    "print(f\"\\nüéØ Cost Optimization Opportunities:\")\n",
    "print(f\"   Services with high variance (potential optimization): \")\n",
    "high_variance = service_cost_analysis[service_cost_analysis['std_dev'] > service_cost_analysis['std_dev'].quantile(0.75)].head()\n",
    "for idx, (service, row) in enumerate(high_variance.iterrows(), 1):\n",
    "    print(f\"      {idx}. {service}: Std Dev ${row['std_dev']:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfaaebc",
   "metadata": {},
   "source": [
    "## 8. Identify High-Growth Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef38c71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify high-growth services\n",
    "growth_analysis = []\n",
    "for service in df['service'].unique():\n",
    "    service_data = df[df['service'] == service].copy()\n",
    "    service_data = service_data.sort_values('timeUsageStarted')\n",
    "    \n",
    "    # Calculate growth metrics\n",
    "    if len(service_data) > 1:\n",
    "        first_date = service_data['date'].min()\n",
    "        last_date = service_data['date'].max()\n",
    "        days_active = (last_date - first_date).days + 1\n",
    "        \n",
    "        # Get first and last month costs\n",
    "        first_month_idx = service_data.groupby('year_month')['computedAmount'].sum().index[0]\n",
    "        last_month_idx = service_data.groupby('year_month')['computedAmount'].sum().index[-1]\n",
    "        \n",
    "        first_month_cost = service_data[service_data['year_month'] == first_month_idx]['computedAmount'].sum()\n",
    "        last_month_cost = service_data[service_data['year_month'] == last_month_idx]['computedAmount'].sum()\n",
    "        \n",
    "        total_cost = service_data['computedAmount'].sum()\n",
    "        num_resources = service_data['resourceId'].nunique()\n",
    "        \n",
    "        # Calculate growth rate\n",
    "        if first_month_cost > 0:\n",
    "            # Simple growth rate calculation\n",
    "            months_active = len(service_data.groupby('year_month'))\n",
    "            if months_active > 1:\n",
    "                growth_rate = ((last_month_cost / first_month_cost) ** (1 / (months_active - 1)) - 1) * 100\n",
    "            else:\n",
    "                growth_rate = 0\n",
    "        else:\n",
    "            growth_rate = 0\n",
    "        \n",
    "        growth_analysis.append({\n",
    "            'service': service,\n",
    "            'total_cost': total_cost,\n",
    "            'current_monthly': last_month_cost,\n",
    "            'first_monthly': first_month_cost,\n",
    "            'growth_rate': growth_rate,\n",
    "            'num_resources': num_resources,\n",
    "            'days_active': days_active,\n",
    "            'market_share': (total_cost / df['computedAmount'].sum()) * 100\n",
    "        })\n",
    "\n",
    "growth_df = pd.DataFrame(growth_analysis).sort_values('growth_rate', ascending=False)\n",
    "\n",
    "print(f\"‚úÖ High-Growth Services Analysis Completed\")\n",
    "print(f\"\\nüöÄ Top 10 Highest-Growth Services:\")\n",
    "print(growth_df[['service', 'growth_rate', 'current_monthly', 'num_resources', 'market_share']].head(10))\n",
    "\n",
    "# Categorize services\n",
    "print(f\"\\nüìä Service Growth Categories:\")\n",
    "high_growth = growth_df[growth_df['growth_rate'] > growth_df['growth_rate'].quantile(0.75)]\n",
    "moderate_growth = growth_df[(growth_df['growth_rate'] > growth_df['growth_rate'].quantile(0.25)) & \n",
    "                             (growth_df['growth_rate'] <= growth_df['growth_rate'].quantile(0.75))]\n",
    "low_growth = growth_df[growth_df['growth_rate'] <= growth_df['growth_rate'].quantile(0.25)]\n",
    "\n",
    "print(f\"\\nüî• High-Growth Services ({len(high_growth)}):\")\n",
    "if len(high_growth) > 0:\n",
    "    print(high_growth[['service', 'growth_rate', 'current_monthly']].head(5))\n",
    "\n",
    "print(f\"\\n‚ö° Emerging Services (First 2 months of activity):\")\n",
    "emerging = growth_df[growth_df['days_active'] < 60].sort_values('current_monthly', ascending=False)\n",
    "if len(emerging) > 0:\n",
    "    print(emerging[['service', 'current_monthly', 'num_resources']].head(5))\n",
    "\n",
    "print(f\"\\nüìâ Services Approaching Saturation (Low growth, High cost):\")\n",
    "mature = growth_df[(growth_df['growth_rate'] < 5) & (growth_df['total_cost'] > growth_df['total_cost'].quantile(0.5))]\n",
    "if len(mature) > 0:\n",
    "    print(mature[['service', 'growth_rate', 'current_monthly', 'market_share']].head(5))\n",
    "\n",
    "# Create high-growth services visualization\n",
    "print(\"\\nCreating high-growth services visualization...\")\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "# Left chart: Top 15 High-Growth Services (sorted by growth rate)\n",
    "top_growth = growth_df.head(15).copy()\n",
    "\n",
    "# Create color gradient based on growth rate\n",
    "colors_growth = ['#2E7D32' if x > 0 else '#D32F2F' for x in top_growth['growth_rate']]\n",
    "\n",
    "y_pos = np.arange(len(top_growth))\n",
    "ax1.barh(y_pos, top_growth['growth_rate'], color=colors_growth, alpha=0.8)\n",
    "ax1.set_yticks(y_pos)\n",
    "ax1.set_yticklabels([s[:35] + '...' if len(s) > 35 else s for s in top_growth['service']], fontsize=9)\n",
    "ax1.set_xlabel('Growth Rate (%)', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Top 15 Services by Growth Rate', fontsize=13, fontweight='bold', pad=15)\n",
    "ax1.axvline(x=0, color='black', linewidth=0.8, linestyle='-', alpha=0.5)\n",
    "ax1.grid(True, alpha=0.3, axis='x')\n",
    "ax1.invert_yaxis()\n",
    "\n",
    "# Add growth rate labels\n",
    "for i, (rate, cost) in enumerate(zip(top_growth['growth_rate'], top_growth['current_monthly'])):\n",
    "    label = f'{rate:+.1f}% (${cost:,.0f}/mo)'\n",
    "    x_pos = rate + (5 if rate > 0 else -5)\n",
    "    ha = 'left' if rate > 0 else 'right'\n",
    "    ax1.text(x_pos, i, label, va='center', fontsize=8, fontweight='bold')\n",
    "\n",
    "# Right chart: Growth vs Market Share Bubble Chart\n",
    "ax2.scatter(growth_df['growth_rate'], growth_df['market_share'], \n",
    "           s=growth_df['num_resources']*2, alpha=0.6, \n",
    "           c=growth_df['current_monthly'], cmap='viridis', edgecolors='black', linewidth=0.5)\n",
    "\n",
    "# Add labels for top services\n",
    "top_to_label = growth_df.nlargest(8, 'market_share')\n",
    "for _, row in top_to_label.iterrows():\n",
    "    ax2.annotate(row['service'][:20], \n",
    "                xy=(row['growth_rate'], row['market_share']),\n",
    "                xytext=(5, 5), textcoords='offset points',\n",
    "                fontsize=8, alpha=0.8, \n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.3))\n",
    "\n",
    "ax2.set_xlabel('Growth Rate (%)', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Market Share (%)', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Growth vs Market Share Analysis\\n(Bubble size = # Resources)', \n",
    "              fontsize=13, fontweight='bold', pad=15)\n",
    "ax2.axvline(x=0, color='red', linewidth=1, linestyle='--', alpha=0.5, label='Zero Growth')\n",
    "ax2.axhline(y=5, color='green', linewidth=1, linestyle='--', alpha=0.5, label='5% Market Share')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.legend(loc='upper right', fontsize=9)\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(ax2.collections[0], ax=ax2)\n",
    "cbar.set_label('Monthly Cost ($)', rotation=270, labelpad=20, fontsize=10, fontweight='bold')\n",
    "\n",
    "# Add summary stats\n",
    "stats_text = f\"\"\"Growth Categories:\n",
    "‚Ä¢ High Growth (>Q3): {len(high_growth)} services\n",
    "‚Ä¢ Moderate Growth: {len(moderate_growth)} services\n",
    "‚Ä¢ Low Growth (<Q1): {len(low_growth)} services\n",
    "‚Ä¢ Emerging (<60d): {len(emerging)} services\n",
    "‚Ä¢ Mature (low Œî, high $): {len(mature)} services\n",
    "\n",
    "Avg Growth Rate: {growth_df['growth_rate'].mean():.1f}%\n",
    "Median Growth: {growth_df['growth_rate'].median():.1f}%\"\"\"\n",
    "\n",
    "ax2.text(1.35, 0.5, stats_text, transform=ax2.transAxes,\n",
    "         fontsize=9, verticalalignment='center', fontfamily='monospace',\n",
    "         bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.3))\n",
    "\n",
    "plt.suptitle('üöÄ HIGH-GROWTH SERVICES ANALYSIS', fontsize=15, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ High-growth services visualization created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e55457f",
   "metadata": {},
   "source": [
    "## 9. Regional and Compartment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f034b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regional analysis\n",
    "regional_analysis = df.groupby('region').agg({\n",
    "    'computedAmount': ['sum', 'mean'],\n",
    "    'resourceId': 'nunique',\n",
    "    'compartmentName': 'nunique',\n",
    "    'service': 'nunique'\n",
    "}).reset_index()\n",
    "regional_analysis.columns = ['region', 'total_cost', 'avg_cost', 'num_resources', 'num_compartments', 'num_services']\n",
    "regional_analysis = regional_analysis.sort_values('total_cost', ascending=False)\n",
    "regional_analysis['market_share'] = (regional_analysis['total_cost'] / regional_analysis['total_cost'].sum() * 100).round(2)\n",
    "\n",
    "# Regional growth trends\n",
    "regional_trends = df.groupby(['year_month', 'region'])['computedAmount'].sum().reset_index()\n",
    "regional_trends = regional_trends.sort_values(['region', 'year_month'])\n",
    "\n",
    "# Compartment analysis\n",
    "compartment_analysis = df.groupby('compartmentName').agg({\n",
    "    'computedAmount': ['sum', 'mean', 'count'],\n",
    "    'service': 'nunique',\n",
    "    'region': 'nunique',\n",
    "    'resourceId': 'nunique'\n",
    "}).reset_index()\n",
    "compartment_analysis.columns = ['compartment', 'total_cost', 'avg_cost', 'num_records', 'num_services', 'num_regions', 'num_resources']\n",
    "compartment_analysis = compartment_analysis.sort_values('total_cost', ascending=False)\n",
    "compartment_analysis['market_share'] = (compartment_analysis['total_cost'] / compartment_analysis['total_cost'].sum() * 100).round(2)\n",
    "\n",
    "print(f\"‚úÖ Regional and Compartment Analysis Completed\")\n",
    "print(f\"\\nüåç Regional Cost Distribution:\")\n",
    "print(regional_analysis[['region', 'total_cost', 'market_share', 'num_services', 'num_resources']].head(10))\n",
    "\n",
    "print(f\"\\nüìä Regional Growth Hotspots:\")\n",
    "regional_growth = []\n",
    "for region in df['region'].unique():\n",
    "    region_data = regional_trends[regional_trends['region'] == region].sort_values('year_month')\n",
    "    if len(region_data) > 1:\n",
    "        first = region_data.iloc[0]['computedAmount']\n",
    "        last = region_data.iloc[-1]['computedAmount']\n",
    "        if first > 0:\n",
    "            growth = ((last / first) - 1) * 100\n",
    "            regional_growth.append({'region': region, 'growth_rate': growth, 'current_cost': last, 'num_months': len(region_data)})\n",
    "\n",
    "if regional_growth:\n",
    "    regional_growth_df = pd.DataFrame(regional_growth).sort_values('growth_rate', ascending=False)\n",
    "    print(regional_growth_df.head(10))\n",
    "else:\n",
    "    print(\"   No multi-month data available for regional growth analysis\")\n",
    "\n",
    "print(f\"\\nüè¢ Top Compartments by Cost:\")\n",
    "print(compartment_analysis[['compartment', 'total_cost', 'market_share', 'num_services']].head(10))\n",
    "\n",
    "print(f\"\\nüéØ Untapped Markets (Regions with low service adoption):\")\n",
    "low_adoption = regional_analysis[regional_analysis['num_services'] < regional_analysis['num_services'].median()].sort_values('total_cost')\n",
    "if len(low_adoption) > 0:\n",
    "    print(low_adoption[['region', 'total_cost', 'num_services', 'num_resources']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98aed1dd",
   "metadata": {},
   "source": [
    "## 10. Forecast Future Consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad85529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series forecasting with comprehensive visualizations and decision insights\n",
    "print(f\"‚úÖ Starting Time Series Forecast Analysis\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Prepare data for forecasting\n",
    "monthly_costs_ts = monthly_costs.set_index('year_month')['total_cost']\n",
    "current_monthly = monthly_costs_ts.iloc[-1]\n",
    "\n",
    "# Build multiple forecast models\n",
    "forecast_results = {}\n",
    "forecast_6m = {}\n",
    "forecast_12m = {}\n",
    "\n",
    "# 1. Linear Regression Forecast (Trend-based)\n",
    "try:\n",
    "    X_train = np.arange(len(monthly_costs_ts)).reshape(-1, 1)\n",
    "    lr_model = LinearRegression()\n",
    "    lr_model.fit(X_train, monthly_costs_ts.values)\n",
    "    \n",
    "    # 6-month forecast\n",
    "    X_forecast_6m = np.arange(len(monthly_costs_ts), len(monthly_costs_ts) + 6).reshape(-1, 1)\n",
    "    forecast_lr_6m = lr_model.predict(X_forecast_6m)\n",
    "    forecast_6m['Linear Trend'] = forecast_lr_6m\n",
    "    \n",
    "    # 12-month forecast\n",
    "    X_forecast_12m = np.arange(len(monthly_costs_ts), len(monthly_costs_ts) + 12).reshape(-1, 1)\n",
    "    forecast_lr_12m = lr_model.predict(X_forecast_12m)\n",
    "    forecast_12m['Linear Trend'] = forecast_lr_12m\n",
    "    \n",
    "    print(\"‚úÖ Linear Regression model trained successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Linear Regression failed: {e}\")\n",
    "\n",
    "# 2. Exponential Smoothing (handles trends)\n",
    "if len(monthly_costs_ts) > 3:\n",
    "    try:\n",
    "        model_exp = ExponentialSmoothing(monthly_costs_ts, trend='add', seasonal=None)\n",
    "        fitted_exp = model_exp.fit()\n",
    "        forecast_6m['Exponential Smoothing'] = fitted_exp.forecast(steps=6)\n",
    "        forecast_12m['Exponential Smoothing'] = fitted_exp.forecast(steps=12)\n",
    "        print(\"‚úÖ Exponential Smoothing model trained successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Exponential Smoothing failed: {e}\")\n",
    "\n",
    "# 3. Moving Average Forecast (Conservative)\n",
    "try:\n",
    "    ma_window = min(3, len(monthly_costs_ts))\n",
    "    ma_value = monthly_costs_ts.tail(ma_window).mean()\n",
    "    forecast_6m['Moving Average'] = np.array([ma_value] * 6)\n",
    "    forecast_12m['Moving Average'] = np.array([ma_value] * 12)\n",
    "    print(\"‚úÖ Moving Average forecast calculated\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Moving Average failed: {e}\")\n",
    "\n",
    "# 4. Growth Rate Scenarios (Business Planning)\n",
    "try:\n",
    "    # Calculate recent growth trend\n",
    "    recent_growth = monthly_costs_ts.pct_change().tail(3).mean()\n",
    "    \n",
    "    # Conservative: 50% of recent growth\n",
    "    conservative_rate = recent_growth * 0.5\n",
    "    conservative_6m = [current_monthly * (1 + conservative_rate) ** i for i in range(1, 7)]\n",
    "    conservative_12m = [current_monthly * (1 + conservative_rate) ** i for i in range(1, 13)]\n",
    "    forecast_6m['Conservative Growth'] = np.array(conservative_6m)\n",
    "    forecast_12m['Conservative Growth'] = np.array(conservative_12m)\n",
    "    \n",
    "    # Aggressive: 150% of recent growth\n",
    "    aggressive_rate = recent_growth * 1.5\n",
    "    aggressive_6m = [current_monthly * (1 + aggressive_rate) ** i for i in range(1, 7)]\n",
    "    aggressive_12m = [current_monthly * (1 + aggressive_rate) ** i for i in range(1, 13)]\n",
    "    forecast_6m['Aggressive Growth'] = np.array(aggressive_6m)\n",
    "    forecast_12m['Aggressive Growth'] = np.array(aggressive_12m)\n",
    "    \n",
    "    print(f\"‚úÖ Growth scenarios calculated (Recent MoM: {recent_growth*100:+.2f}%)\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Growth scenarios failed: {e}\")\n",
    "\n",
    "# Calculate forecast summary statistics\n",
    "print(f\"\\nüìä FORECAST SUMMARY (6-Month Horizon):\")\n",
    "print(\"-\"*80)\n",
    "forecast_summary = []\n",
    "for model_name, values in forecast_6m.items():\n",
    "    avg_monthly = values.mean()\n",
    "    total_6m = values.sum()\n",
    "    month1 = values[0]\n",
    "    month6 = values[-1]\n",
    "    growth_vs_current = ((avg_monthly / current_monthly) - 1) * 100\n",
    "    \n",
    "    forecast_summary.append({\n",
    "        'Model': model_name,\n",
    "        'Avg Monthly': avg_monthly,\n",
    "        'Total 6M': total_6m,\n",
    "        'Month 1': month1,\n",
    "        'Month 6': month6,\n",
    "        'Growth %': growth_vs_current\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(f\"   Avg Monthly: ${avg_monthly:,.2f} ({growth_vs_current:+.1f}% vs current)\")\n",
    "    print(f\"   Total 6M: ${total_6m:,.2f}\")\n",
    "    print(f\"   Month 1: ${month1:,.2f} ‚Üí Month 6: ${month6:,.2f}\")\n",
    "\n",
    "forecast_summary_df = pd.DataFrame(forecast_summary)\n",
    "\n",
    "# Ensemble forecast (average of all models)\n",
    "if forecast_6m:\n",
    "    ensemble_6m = np.mean([v for v in forecast_6m.values()], axis=0)\n",
    "    ensemble_12m = np.mean([v for v in forecast_12m.values()], axis=0)\n",
    "    \n",
    "    print(f\"\\nüéØ ENSEMBLE FORECAST (Average of All Models):\")\n",
    "    print(f\"   6-Month Avg: ${ensemble_6m.mean():,.2f} (Total: ${ensemble_6m.sum():,.2f})\")\n",
    "    print(f\"   12-Month Avg: ${ensemble_12m.mean():,.2f} (Total: ${ensemble_12m.sum():,.2f})\")\n",
    "    print(f\"   Confidence: {'High' if len(forecast_6m) >= 3 else 'Medium' if len(forecast_6m) == 2 else 'Low'}\")\n",
    "\n",
    "# Service-level forecasts for top services\n",
    "print(f\"\\n\\nüìà TOP 5 SERVICES - 6-Month Forecast:\")\n",
    "print(\"-\"*80)\n",
    "top_services_for_forecast = service_summary.head(5)['service'].tolist()\n",
    "service_forecasts = []\n",
    "\n",
    "for service in top_services_for_forecast:\n",
    "    service_monthly = df[df['service'] == service].groupby('year_month')['computedAmount'].sum()\n",
    "    if len(service_monthly) > 2:\n",
    "        try:\n",
    "            # Simple linear forecast for each service\n",
    "            X_svc = np.arange(len(service_monthly)).reshape(-1, 1)\n",
    "            y_svc = service_monthly.values\n",
    "            svc_model = LinearRegression()\n",
    "            svc_model.fit(X_svc, y_svc)\n",
    "            \n",
    "            X_svc_forecast = np.arange(len(service_monthly), len(service_monthly) + 6).reshape(-1, 1)\n",
    "            svc_forecast = svc_model.predict(X_svc_forecast)\n",
    "            \n",
    "            current_svc = service_monthly.iloc[-1]\n",
    "            forecast_avg = svc_forecast.mean()\n",
    "            growth_pct = ((forecast_avg / current_svc) - 1) * 100\n",
    "            \n",
    "            service_forecasts.append({\n",
    "                'service': service,\n",
    "                'current': current_svc,\n",
    "                'forecast_avg': forecast_avg,\n",
    "                'forecast_6m': svc_forecast,\n",
    "                'growth': growth_pct\n",
    "            })\n",
    "            \n",
    "            print(f\"\\n{service[:50]}:\")\n",
    "            print(f\"   Current: ${current_svc:,.2f}/mo ‚Üí Forecast: ${forecast_avg:,.2f}/mo ({growth_pct:+.1f}%)\")\n",
    "            print(f\"   6-Month Total: ${svc_forecast.sum():,.2f}\")\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "# CREATE COMPREHENSIVE FORECAST VISUALIZATION\n",
    "print(\"\\n\\nüìä Creating forecast visualization dashboard...\")\n",
    "\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "gs = plt.GridSpec(3, 3, figure=fig, hspace=0.35, wspace=0.3)\n",
    "\n",
    "# 1. Historical + Forecast Trend (Main Chart - Top Span)\n",
    "ax1 = fig.add_subplot(gs[0, :])\n",
    "months_historical = range(len(monthly_costs_ts))\n",
    "months_forecast = range(len(monthly_costs_ts), len(monthly_costs_ts) + 12)\n",
    "\n",
    "# Plot historical data\n",
    "ax1.plot(months_historical, monthly_costs_ts.values, 'o-', color='navy', linewidth=2.5, \n",
    "         markersize=8, label='Historical Actual', zorder=5)\n",
    "\n",
    "# Plot forecast models\n",
    "colors_forecast = ['green', 'orange', 'red', 'purple', 'brown']\n",
    "for idx, (model_name, values) in enumerate(forecast_12m.items()):\n",
    "    ax1.plot(months_forecast, values, '--', color=colors_forecast[idx % len(colors_forecast)], \n",
    "             linewidth=2, alpha=0.7, label=f'{model_name} Forecast', marker='s', markersize=5)\n",
    "\n",
    "# Plot ensemble\n",
    "if forecast_12m:\n",
    "    ax1.plot(months_forecast, ensemble_12m, color='black', linewidth=3, \n",
    "             alpha=0.8, label='Ensemble Forecast', marker='D', markersize=6, zorder=6)\n",
    "\n",
    "ax1.axvline(x=len(monthly_costs_ts)-0.5, color='red', linestyle=':', linewidth=2, alpha=0.6)\n",
    "ax1.text(len(monthly_costs_ts)-0.5, ax1.get_ylim()[1]*0.95, '‚Üê Historical | Forecast ‚Üí', \n",
    "         ha='center', fontsize=11, fontweight='bold', bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.5))\n",
    "\n",
    "ax1.set_xlabel('Month Index', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Total Cost ($)', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('12-Month Consumption Forecast with Multiple Models', fontsize=14, fontweight='bold', pad=15)\n",
    "ax1.legend(loc='upper left', fontsize=9, framealpha=0.9)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Forecast Comparison (Box Plot)\n",
    "ax2 = fig.add_subplot(gs[1, 0])\n",
    "if forecast_6m:\n",
    "    box_data = [v for v in forecast_6m.values()]\n",
    "    box_labels = [k[:15] for k in forecast_6m.keys()]\n",
    "    bp = ax2.boxplot(box_data, labels=box_labels, patch_artist=True, vert=True)\n",
    "    \n",
    "    for patch, color in zip(bp['boxes'], colors_forecast):\n",
    "        patch.set_facecolor(color)\n",
    "        patch.set_alpha(0.6)\n",
    "    \n",
    "    ax2.axhline(y=current_monthly, color='red', linestyle='--', linewidth=2, label='Current Monthly')\n",
    "    ax2.set_ylabel('Monthly Cost ($)', fontsize=11, fontweight='bold')\n",
    "    ax2.set_title('6M Forecast Distribution by Model', fontsize=12, fontweight='bold')\n",
    "    ax2.tick_params(axis='x', rotation=45, labelsize=9)\n",
    "    ax2.legend(fontsize=9)\n",
    "    ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 3. Scenario Planning (Conservative vs Aggressive)\n",
    "ax3 = fig.add_subplot(gs[1, 1])\n",
    "scenarios = ['Current', 'Conservative', 'Ensemble', 'Aggressive']\n",
    "scenario_values = [\n",
    "    current_monthly * 6,\n",
    "    forecast_6m.get('Conservative Growth', [current_monthly]*6).sum() if 'Conservative Growth' in forecast_6m else current_monthly * 6,\n",
    "    ensemble_6m.sum() if forecast_6m else current_monthly * 6,\n",
    "    forecast_6m.get('Aggressive Growth', [current_monthly]*6).sum() if 'Aggressive Growth' in forecast_6m else current_monthly * 6\n",
    "]\n",
    "scenario_colors = ['gray', 'green', 'blue', 'red']\n",
    "\n",
    "bars_scenario = ax3.bar(scenarios, scenario_values, color=scenario_colors, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "ax3.set_ylabel('Total 6-Month Cost ($)', fontsize=11, fontweight='bold')\n",
    "ax3.set_title('Scenario Planning: 6-Month Total Cost', fontsize=12, fontweight='bold')\n",
    "ax3.tick_params(axis='x', rotation=20)\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels\n",
    "for bar, val in zip(bars_scenario, scenario_values):\n",
    "    height = bar.get_height()\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'${val:,.0f}',\n",
    "            ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "# 4. Top Services Forecast\n",
    "ax4 = fig.add_subplot(gs[1, 2])\n",
    "if service_forecasts:\n",
    "    svc_names = [s['service'][:20] + '...' if len(s['service']) > 20 else s['service'] for s in service_forecasts]\n",
    "    svc_current = [s['current'] for s in service_forecasts]\n",
    "    svc_forecast = [s['forecast_avg'] for s in service_forecasts]\n",
    "    \n",
    "    x_svc = np.arange(len(svc_names))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars1_svc = ax4.barh(x_svc - width/2, svc_current, width, label='Current', color='lightblue', edgecolor='black')\n",
    "    bars2_svc = ax4.barh(x_svc + width/2, svc_forecast, width, label='Forecast Avg', color='orange', edgecolor='black')\n",
    "    \n",
    "    ax4.set_yticks(x_svc)\n",
    "    ax4.set_yticklabels(svc_names, fontsize=9)\n",
    "    ax4.set_xlabel('Monthly Cost ($)', fontsize=11, fontweight='bold')\n",
    "    ax4.set_title('Service-Level Forecast', fontsize=12, fontweight='bold')\n",
    "    ax4.legend(fontsize=9)\n",
    "    ax4.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# 5. Monthly Progression (Stacked Forecast)\n",
    "ax5 = fig.add_subplot(gs[2, :2])\n",
    "if service_forecasts and len(service_forecasts) >= 3:\n",
    "    months_labels = [f'M{i+1}' for i in range(6)]\n",
    "    \n",
    "    # Create stacked area for top 3 services\n",
    "    svc_stack_data = []\n",
    "    svc_stack_labels = []\n",
    "    for svc in service_forecasts[:3]:\n",
    "        svc_stack_data.append(svc['forecast_6m'])\n",
    "        svc_stack_labels.append(svc['service'][:25])\n",
    "    \n",
    "    svc_stack_data = np.array(svc_stack_data)\n",
    "    \n",
    "    ax5.stackplot(range(6), *svc_stack_data, labels=svc_stack_labels, alpha=0.7, \n",
    "                  colors=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
    "    \n",
    "    ax5.set_xticks(range(6))\n",
    "    ax5.set_xticklabels(months_labels)\n",
    "    ax5.set_ylabel('Monthly Cost ($)', fontsize=11, fontweight='bold')\n",
    "    ax5.set_xlabel('Forecast Month', fontsize=11, fontweight='bold')\n",
    "    ax5.set_title('Top 3 Services - Monthly Progression', fontsize=12, fontweight='bold')\n",
    "    ax5.legend(loc='upper left', fontsize=9)\n",
    "    ax5.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 6. Decision Dashboard (Text Summary)\n",
    "ax6 = fig.add_subplot(gs[2, 2])\n",
    "ax6.axis('off')\n",
    "\n",
    "# Calculate key metrics for decision-making\n",
    "if forecast_6m:\n",
    "    ensemble_growth = ((ensemble_6m.mean() / current_monthly) - 1) * 100\n",
    "    ensemble_12m_total = ensemble_12m.sum()\n",
    "    confidence = 'HIGH' if len(forecast_6m) >= 4 else 'MEDIUM' if len(forecast_6m) >= 2 else 'LOW'\n",
    "    \n",
    "    # Determine budget recommendation\n",
    "    if ensemble_growth > 10:\n",
    "        budget_action = \"‚¨ÜÔ∏è  INCREASE BUDGET\"\n",
    "        budget_detail = f\"Expect +{ensemble_growth:.1f}% growth\"\n",
    "    elif ensemble_growth < -10:\n",
    "        budget_action = \"‚¨áÔ∏è  DECREASE BUDGET\"\n",
    "        budget_detail = f\"Expect {ensemble_growth:.1f}% decline\"\n",
    "    else:\n",
    "        budget_action = \"‚û°Ô∏è  MAINTAIN BUDGET\"\n",
    "        budget_detail = f\"Stable growth ({ensemble_growth:+.1f}%)\"\n",
    "    \n",
    "    # Risk assessment\n",
    "    forecast_variance = np.std([v.mean() for v in forecast_6m.values()])\n",
    "    if forecast_variance > current_monthly * 0.2:\n",
    "        risk_level = \"üî¥ HIGH VARIANCE\"\n",
    "        risk_action = \"Multiple scenarios advised\"\n",
    "    elif forecast_variance > current_monthly * 0.1:\n",
    "        risk_level = \"üü° MODERATE VARIANCE\"\n",
    "        risk_action = \"Monitor closely\"\n",
    "    else:\n",
    "        risk_level = \"üü¢ LOW VARIANCE\"\n",
    "        risk_action = \"Predictable trajectory\"\n",
    "    \n",
    "    decision_text = f\"\"\"\n",
    "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "‚ïë  DECISION SUPPORT DASHBOARD       ‚ïë\n",
    "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "\n",
    "üìä FORECAST CONFIDENCE: {confidence}\n",
    "\n",
    "üí∞ BUDGET PLANNING:\n",
    "   {budget_action}\n",
    "   {budget_detail}\n",
    "   \n",
    "   6M Budget: ${ensemble_6m.sum():,.0f}\n",
    "   12M Budget: ${ensemble_12m_total:,.0f}\n",
    "\n",
    "üìà GROWTH TRAJECTORY:\n",
    "   Current: ${current_monthly:,.0f}/mo\n",
    "   6M Avg: ${ensemble_6m.mean():,.0f}/mo\n",
    "   12M Avg: ${ensemble_12m.mean():,.0f}/mo\n",
    "   \n",
    "‚ö†Ô∏è  RISK ASSESSMENT:\n",
    "   {risk_level}\n",
    "   Variance: ${forecast_variance:,.0f}\n",
    "   Action: {risk_action}\n",
    "\n",
    "üéØ KEY RECOMMENDATIONS:\n",
    "   1. Budget for {ensemble_growth:+.1f}% change\n",
    "   2. Review quarterly milestones\n",
    "   3. Monitor top 5 services\n",
    "   4. Plan capacity adjustments\n",
    "   5. {\"Prepare for scale-up\" if ensemble_growth > 0 else \"Optimize for efficiency\"}\n",
    "\"\"\"\n",
    "else:\n",
    "    decision_text = \"\"\"\n",
    "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "‚ïë  DECISION SUPPORT DASHBOARD       ‚ïë\n",
    "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "\n",
    "‚ö†Ô∏è  INSUFFICIENT DATA\n",
    "\n",
    "Please ensure sufficient historical\n",
    "data (minimum 3 months) for \n",
    "accurate forecasting.\n",
    "\"\"\"\n",
    "\n",
    "ax6.text(0.05, 0.95, decision_text, transform=ax6.transAxes,\n",
    "         fontsize=9, verticalalignment='top', fontfamily='monospace',\n",
    "         bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.4, edgecolor='darkgreen', linewidth=2))\n",
    "\n",
    "plt.suptitle('üîÆ FUTURE CONSUMPTION FORECAST & DECISION ANALYSIS', \n",
    "             fontsize=16, fontweight='bold', y=0.98)\n",
    "\n",
    "plt.show()\n",
    "print(\"‚úÖ Forecast visualization dashboard created successfully!\")\n",
    "\n",
    "# Export forecast data\n",
    "print(f\"\\nüìÅ Exporting forecast data...\")\n",
    "if forecast_summary_df is not None and len(forecast_summary_df) > 0:\n",
    "    forecast_export_path = '../output/forecast_analysis.csv'\n",
    "    forecast_summary_df.to_csv(forecast_export_path, index=False)\n",
    "    print(f\"   Saved: {forecast_export_path}\")\n",
    "    \n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ FORECAST ANALYSIS COMPLETE - Ready for Strategic Planning\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ffdd80",
   "metadata": {},
   "source": [
    "## 11. Generate Sales Recommendations and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38acfa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive sales recommendations\n",
    "print(\"=\" * 80)\n",
    "print(\"STRATEGIC SALES RECOMMENDATIONS & ACTION ITEMS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. Upsell Opportunities\n",
    "print(\"\\nüîº UPSELL OPPORTUNITIES\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(\"\\n1. Services Ready for Expansion:\")\n",
    "high_growth_services = growth_df[growth_df['growth_rate'] > 20].sort_values('current_monthly', ascending=False)\n",
    "if len(high_growth_services) > 0:\n",
    "    for idx, (_, service) in enumerate(high_growth_services.head(5).iterrows(), 1):\n",
    "        print(f\"\\n   {idx}. {service['service']}\")\n",
    "        print(f\"      Current Monthly: ${service['current_monthly']:,.2f}\")\n",
    "        print(f\"      Growth Rate: {service['growth_rate']:.1f}%\")\n",
    "        print(f\"      Resources: {int(service['num_resources'])}\")\n",
    "        print(f\"      Action: Offer advanced features, consulting, or managed services\")\n",
    "\n",
    "# 2. Cross-sell Opportunities\n",
    "print(\"\\n\\n‚ùå CROSS-SELL OPPORTUNITIES\")\n",
    "print(\"-\" * 80)\n",
    "print(\"\\n1. Services Adoption Gaps by Region:\")\n",
    "\n",
    "for region in regional_analysis['region'].head(5).values:\n",
    "    region_services = df[df['region'] == region]['service'].nunique()\n",
    "    max_services = df['service'].nunique()\n",
    "    adoption_rate = (region_services / max_services) * 100\n",
    "    \n",
    "    if adoption_rate < 70:\n",
    "        print(f\"\\n   {region}:\")\n",
    "        print(f\"      Service Adoption: {adoption_rate:.1f}% ({region_services}/{max_services})\")\n",
    "        \n",
    "        # Find services in other regions not in this region\n",
    "        all_services = set(df['service'].unique())\n",
    "        region_services_set = set(df[df['region'] == region]['service'].unique())\n",
    "        missing_services = all_services - region_services_set\n",
    "        \n",
    "        if missing_services:\n",
    "            print(f\"      Missing Services: {', '.join(list(missing_services)[:3])}\")\n",
    "            print(f\"      Action: Target with service bundle offers\")\n",
    "\n",
    "# 3. Account Expansion\n",
    "print(\"\\n\\nüìà ACCOUNT EXPANSION (Compartment-level Analysis)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Find compartments with growth potential\n",
    "compartment_growth = []\n",
    "for comp in compartment_analysis['compartment'].head(20).values:\n",
    "    comp_data = df[df['compartmentName'] == comp]\n",
    "    comp_services = comp_data['service'].nunique()\n",
    "    comp_cost = comp_data['computedAmount'].sum()\n",
    "    services_potential = df['service'].nunique() - comp_services\n",
    "    \n",
    "    if services_potential > 3:\n",
    "        compartment_growth.append({\n",
    "            'compartment': comp,\n",
    "            'current_cost': comp_cost,\n",
    "            'service_count': comp_services,\n",
    "            'expansion_potential': services_potential\n",
    "        })\n",
    "\n",
    "if compartment_growth:\n",
    "    comp_growth_df = pd.DataFrame(compartment_growth).sort_values('current_cost', ascending=False)\n",
    "    print(\"\\nCompartments with High Expansion Potential:\")\n",
    "    for idx, (_, comp) in enumerate(comp_growth_df.head(5).iterrows(), 1):\n",
    "        print(f\"\\n   {idx}. {comp['compartment']}\")\n",
    "        print(f\"      Current Cost: ${comp['current_cost']:,.2f}\")\n",
    "        print(f\"      Services Used: {int(comp['service_count'])}\")\n",
    "        print(f\"      Services to Upsell: {int(comp['expansion_potential'])}\")\n",
    "\n",
    "# 4. New Market Opportunities\n",
    "print(\"\\n\\nüåç NEW MARKET OPPORTUNITIES (Geographic Expansion)\")\n",
    "print(\"-\" * 80)\n",
    "print(\"\\nRegions with Growth Potential:\")\n",
    "\n",
    "for idx, (_, region) in enumerate(low_adoption.head(5).iterrows(), 1):\n",
    "    print(f\"\\n   {idx}. {region['region']}\")\n",
    "    print(f\"      Current Spend: ${region['total_cost']:,.2f}\")\n",
    "    print(f\"      Services Available: {int(region['num_services'])}\")\n",
    "    print(f\"      Growth Potential: High (currently underutilized)\")\n",
    "    print(f\"      Action: Targeted sales campaign for region-specific requirements\")\n",
    "\n",
    "# 5. Product Bundle Recommendations\n",
    "print(\"\\n\\nüì¶ RECOMMENDED SERVICE BUNDLES\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Find services often used together\n",
    "service_pairs = {}\n",
    "for comp in df['compartmentName'].unique():\n",
    "    comp_services = df[df['compartmentName'] == comp]['service'].unique()\n",
    "    for i, svc1 in enumerate(comp_services):\n",
    "        for svc2 in comp_services[i+1:]:\n",
    "            pair = tuple(sorted([svc1, svc2]))\n",
    "            service_pairs[pair] = service_pairs.get(pair, 0) + 1\n",
    "\n",
    "if service_pairs:\n",
    "    common_pairs = sorted(service_pairs.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "    print(\"\\nMost Common Service Combinations:\")\n",
    "    for idx, (pair, count) in enumerate(common_pairs, 1):\n",
    "        print(f\"   {idx}. {pair[0]} + {pair[1]} (used together in {count} compartments)\")\n",
    "\n",
    "# 6. Retention Focus\n",
    "print(\"\\n\\n‚ö†Ô∏è  RETENTION FOCUS - Services at Risk\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "declining_services = growth_df[growth_df['growth_rate'] < -10].sort_values('current_monthly', ascending=False)\n",
    "if len(declining_services) > 0:\n",
    "    print(\"\\nServices with Declining Usage (Potential Churn Risk):\")\n",
    "    for idx, (_, service) in enumerate(declining_services.head(5).iterrows(), 1):\n",
    "        print(f\"\\n   {idx}. {service['service']}\")\n",
    "        print(f\"      Current Monthly Cost: ${service['current_monthly']:,.2f}\")\n",
    "        print(f\"      Decline Rate: {service['growth_rate']:.1f}%\")\n",
    "        print(f\"      Action: Proactive support, optimization, feature showcases\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ All tracked services showing stable or positive growth - low churn risk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880ba95f",
   "metadata": {},
   "source": [
    "## 12. Sales Intelligence Dashboard - What to Sell & Where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9df10e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SALES INTELLIGENCE DASHBOARD - Actionable Insights for Revenue Growth\n",
    "print(\"=\"*80)\n",
    "print(\"üéØ SALES INTELLIGENCE DASHBOARD - WHAT TO SELL & WHERE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ========================================\n",
    "# 1. REVENUE CONCENTRATION ANALYSIS\n",
    "# ========================================\n",
    "print(\"\\nüí∞ REVENUE CONCENTRATION ANALYSIS:\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Calculate 80/20 rule - which services drive 80% of revenue\n",
    "service_revenue_sorted = service_summary.sort_values('total_cost', ascending=False).copy()\n",
    "service_revenue_sorted['cumulative_pct'] = (service_revenue_sorted['total_cost'].cumsum() / \n",
    "                                             service_revenue_sorted['total_cost'].sum() * 100)\n",
    "services_for_80pct = len(service_revenue_sorted[service_revenue_sorted['cumulative_pct'] <= 80])\n",
    "\n",
    "print(f\"\\nüéØ PARETO PRINCIPLE (80/20 Rule):\")\n",
    "print(f\"   ‚Ä¢ {services_for_80pct} services generate 80% of revenue (${service_revenue_sorted.head(services_for_80pct)['total_cost'].sum():,.0f})\")\n",
    "print(f\"   ‚Ä¢ {len(service_summary) - services_for_80pct} services generate 20% of revenue\")\n",
    "print(f\"   ‚Üí DECISION: Focus retention efforts on top {services_for_80pct} services\")\n",
    "\n",
    "# Identify high-value services with expansion potential\n",
    "high_value_services = service_revenue_sorted.head(10).copy()\n",
    "high_value_with_penetration = []\n",
    "\n",
    "for _, svc in high_value_services.iterrows():\n",
    "    svc_name = svc['service']\n",
    "    # Calculate penetration (% of compartments using this service)\n",
    "    comps_using = len(df[df['service'] == svc_name]['compartmentName'].unique())\n",
    "    total_comps = len(df['compartmentName'].unique())\n",
    "    penetration = (comps_using / total_comps) * 100\n",
    "    \n",
    "    high_value_with_penetration.append({\n",
    "        'service': svc_name,\n",
    "        'revenue': svc['total_cost'],\n",
    "        'market_share': svc['market_share'],\n",
    "        'penetration': penetration,\n",
    "        'comps_using': comps_using,\n",
    "        'untapped_comps': total_comps - comps_using\n",
    "    })\n",
    "\n",
    "hvwp_df = pd.DataFrame(high_value_with_penetration)\n",
    "print(f\"\\nüíé HIGH-VALUE SERVICES - EXPANSION POTENTIAL:\")\n",
    "print(hvwp_df[['service', 'revenue', 'penetration', 'untapped_comps']].head(5))\n",
    "\n",
    "# ========================================\n",
    "# 2. REGIONAL SALES OPPORTUNITIES\n",
    "# ========================================\n",
    "print(\"\\n\\nüåç REGIONAL SALES OPPORTUNITIES:\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Calculate regional opportunity scores\n",
    "regional_opportunities = []\n",
    "for _, region_data in regional_analysis.head(10).iterrows():\n",
    "    region_name = region_data['region']\n",
    "    region_cost = region_data['total_cost']\n",
    "    region_services = region_data['num_services']\n",
    "    \n",
    "    # Services available but not used in this region\n",
    "    services_in_region = set(df[df['region'] == region_name]['service'].unique())\n",
    "    all_services = set(df['service'].unique())\n",
    "    missing_services = all_services - services_in_region\n",
    "    \n",
    "    # Calculate potential based on other regions' usage\n",
    "    potential = len(missing_services) / len(all_services) * 100\n",
    "    \n",
    "    regional_opportunities.append({\n",
    "        'region': region_name,\n",
    "        'current_revenue': region_cost,\n",
    "        'active_services': region_services,\n",
    "        'missing_services': len(missing_services),\n",
    "        'expansion_potential_pct': potential,\n",
    "        'opportunity_score': potential * (region_cost / 100000)  # Weighted by current spend\n",
    "    })\n",
    "\n",
    "reg_opp_df = pd.DataFrame(regional_opportunities).sort_values('opportunity_score', ascending=False)\n",
    "\n",
    "print(f\"\\nüéØ TOP 5 REGIONS FOR SERVICE EXPANSION:\")\n",
    "for idx, row in reg_opp_df.head(5).iterrows():\n",
    "    print(f\"\\n{idx+1}. {row['region']}\")\n",
    "    print(f\"   Current Revenue: ${row['current_revenue']:,.0f}\")\n",
    "    print(f\"   Active Services: {row['active_services']}\")\n",
    "    print(f\"   Missing Services: {row['missing_services']} ({row['expansion_potential_pct']:.1f}% untapped)\")\n",
    "    print(f\"   ‚Üí ACTION: Introduce {min(5, row['missing_services'])} new services to this region\")\n",
    "\n",
    "# ========================================\n",
    "# 3. CUSTOMER WALLET SHARE ANALYSIS\n",
    "# ========================================\n",
    "print(\"\\n\\nüíº CUSTOMER WALLET SHARE ANALYSIS:\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Identify high-spending compartments with low service diversity (high potential for cross-sell)\n",
    "comp_wallet_analysis = compartment_analysis.copy()\n",
    "comp_wallet_analysis['services_per_dollar'] = comp_wallet_analysis['num_services'] / (comp_wallet_analysis['total_cost'] + 1)\n",
    "\n",
    "# High spend, low diversity = prime cross-sell targets\n",
    "cross_sell_targets = comp_wallet_analysis[\n",
    "    (comp_wallet_analysis['total_cost'] > comp_wallet_analysis['total_cost'].quantile(0.75)) &\n",
    "    (comp_wallet_analysis['num_services'] < comp_wallet_analysis['num_services'].median())\n",
    "].sort_values('total_cost', ascending=False)\n",
    "\n",
    "print(f\"\\nüéØ TOP 10 CROSS-SELL PRIORITY ACCOUNTS:\")\n",
    "print(f\"   (High Revenue + Low Service Diversity = High Expansion Potential)\\n\")\n",
    "\n",
    "for idx, row in cross_sell_targets.head(10).iterrows():\n",
    "    potential_services = len(df['service'].unique()) - row['num_services']\n",
    "    print(f\"{idx+1}. {row['compartment'][:50]}\")\n",
    "    print(f\"   Revenue: ${row['total_cost']:,.0f} | Services: {row['num_services']} | Potential Add: {potential_services}\")\n",
    "\n",
    "total_cross_sell_potential = len(cross_sell_targets) * avg_services_per_comp * (df['computedAmount'].mean() * 30)\n",
    "print(f\"\\nüí∞ TOTAL CROSS-SELL POTENTIAL: ${total_cross_sell_potential:,.0f}\")\n",
    "print(f\"   ‚Üí {len(cross_sell_targets)} high-value accounts √ó avg service revenue\")\n",
    "\n",
    "# ========================================\n",
    "# 4. TRENDING SERVICES - WHAT'S HOT\n",
    "# ========================================\n",
    "print(\"\\n\\nüî• TRENDING SERVICES - WHAT TO PRIORITIZE:\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Identify services with positive growth AND substantial revenue\n",
    "growth_revenue_matrix = growth_df.merge(\n",
    "    service_summary[['service', 'total_cost', 'market_share']], \n",
    "    on='service', \n",
    "    how='left',\n",
    "    suffixes=('', '_svc')\n",
    ")\n",
    "\n",
    "# Hot services: High growth + decent market share\n",
    "hot_services = growth_revenue_matrix[\n",
    "    (growth_revenue_matrix['growth_rate'] > 0) & \n",
    "    (growth_revenue_matrix['market_share'] > 1)\n",
    "].sort_values('growth_rate', ascending=False)\n",
    "\n",
    "if len(hot_services) > 0:\n",
    "    print(f\"\\nüî• HOT SERVICES (Positive Growth + >1% Market Share):\")\n",
    "    for idx, svc in hot_services.head(5).iterrows():\n",
    "        print(f\"\\n{idx+1}. {svc['service']}\")\n",
    "        print(f\"   Growth Rate: +{svc['growth_rate']:.1f}% | Market Share: {svc['market_share']:.1f}%\")\n",
    "        print(f\"   Current Revenue: ${svc['current_monthly']:,.0f}/mo\")\n",
    "        print(f\"   ‚Üí ACTION: Push this service to all regions & high-value accounts\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  No services showing positive growth with >1% market share\")\n",
    "    print(\"   ‚Üí FOCUS: Retention and optimization strategies\")\n",
    "\n",
    "# Cold services: Declining but still generating revenue\n",
    "declining_services = growth_revenue_matrix[\n",
    "    (growth_revenue_matrix['growth_rate'] < -10) & \n",
    "    (growth_revenue_matrix['market_share'] > 2)\n",
    "].sort_values('market_share', ascending=False)\n",
    "\n",
    "if len(declining_services) > 0:\n",
    "    print(f\"\\n‚ùÑÔ∏è  AT-RISK SERVICES (Declining >10% + >2% Market Share):\")\n",
    "    for idx, svc in declining_services.head(3).iterrows():\n",
    "        print(f\"\\n{idx+1}. {svc['service']}\")\n",
    "        print(f\"   Decline Rate: {svc['growth_rate']:.1f}% | Market Share: {svc['market_share']:.1f}%\")\n",
    "        print(f\"   Current Revenue: ${svc['current_monthly']:,.0f}/mo\")\n",
    "        print(f\"   ‚Üí ACTION: Retention campaign + investigate churn reasons\")\n",
    "\n",
    "# ========================================\n",
    "# CREATE SALES INTELLIGENCE VISUALIZATION\n",
    "# ========================================\n",
    "print(\"\\n\\nüìä Creating Sales Intelligence Dashboard...\")\n",
    "\n",
    "fig = plt.figure(figsize=(20, 14))\n",
    "gs = plt.GridSpec(4, 3, figure=fig, hspace=0.4, wspace=0.35)\n",
    "\n",
    "# 1. REVENUE CONCENTRATION (Top Left - Pareto Chart)\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "services_subset = service_revenue_sorted.head(20)\n",
    "ax1.bar(range(len(services_subset)), services_subset['total_cost'], color='steelblue', alpha=0.7, label='Revenue')\n",
    "ax1_twin = ax1.twinx()\n",
    "ax1_twin.plot(range(len(services_subset)), services_subset['cumulative_pct'], \n",
    "              color='red', marker='o', linewidth=2.5, markersize=6, label='Cumulative %')\n",
    "ax1_twin.axhline(y=80, color='orange', linestyle='--', linewidth=2, label='80% Mark')\n",
    "\n",
    "ax1.set_xlabel('Services (Ranked)', fontsize=10, fontweight='bold')\n",
    "ax1.set_ylabel('Revenue ($)', color='steelblue', fontsize=10, fontweight='bold')\n",
    "ax1_twin.set_ylabel('Cumulative %', color='red', fontsize=10, fontweight='bold')\n",
    "ax1.set_title(f'üéØ Revenue Concentration\\n({services_for_80pct} services = 80% revenue)', \n",
    "              fontsize=11, fontweight='bold')\n",
    "ax1.legend(loc='upper left', fontsize=8)\n",
    "ax1_twin.legend(loc='upper right', fontsize=8)\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 2. SERVICE PENETRATION - Expansion Opportunities\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "penetration_data = hvwp_df.head(8).copy()\n",
    "x_pen = np.arange(len(penetration_data))\n",
    "\n",
    "bars_pen = ax2.barh(x_pen, penetration_data['penetration'], color='green', alpha=0.6, label='Current Penetration')\n",
    "bars_gap = ax2.barh(x_pen, 100 - penetration_data['penetration'], left=penetration_data['penetration'],\n",
    "                     color='lightcoral', alpha=0.6, label='Expansion Gap')\n",
    "\n",
    "ax2.set_yticks(x_pen)\n",
    "ax2.set_yticklabels([s[:25] + '...' if len(s) > 25 else s for s in penetration_data['service']], fontsize=9)\n",
    "ax2.set_xlabel('Penetration Rate (%)', fontsize=10, fontweight='bold')\n",
    "ax2.set_title('üíé Service Penetration\\n(% of Compartments Using)', fontsize=11, fontweight='bold')\n",
    "ax2.legend(fontsize=8)\n",
    "ax2.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Add penetration labels\n",
    "for i, (pen, gap) in enumerate(zip(penetration_data['penetration'], 100 - penetration_data['penetration'])):\n",
    "    ax2.text(pen/2, i, f'{pen:.0f}%', ha='center', va='center', fontsize=8, fontweight='bold', color='white')\n",
    "    if gap > 10:\n",
    "        ax2.text(pen + gap/2, i, f'{gap:.0f}% gap', ha='center', va='center', fontsize=8, fontweight='bold')\n",
    "\n",
    "# 3. REGIONAL OPPORTUNITY HEATMAP\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "reg_viz = reg_opp_df.head(8).sort_values('opportunity_score')\n",
    "colors_reg_opp = plt.cm.RdYlGn(reg_viz['opportunity_score'] / reg_viz['opportunity_score'].max())\n",
    "\n",
    "bars_reg = ax3.barh(range(len(reg_viz)), reg_viz['opportunity_score'], color=colors_reg_opp, edgecolor='black')\n",
    "ax3.set_yticks(range(len(reg_viz)))\n",
    "ax3.set_yticklabels(reg_viz['region'], fontsize=9)\n",
    "ax3.set_xlabel('Opportunity Score', fontsize=10, fontweight='bold')\n",
    "ax3.set_title('üåç Regional Expansion Priority\\n(Weighted by Current Revenue)', fontsize=11, fontweight='bold')\n",
    "ax3.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Add missing services count\n",
    "for i, (score, missing) in enumerate(zip(reg_viz['opportunity_score'], reg_viz['missing_services'])):\n",
    "    ax3.text(score * 0.5, i, f'{missing} svcs', ha='center', va='center', \n",
    "             fontsize=8, fontweight='bold', color='white')\n",
    "\n",
    "# 4. CROSS-SELL TARGET MATRIX (Spend vs Services)\n",
    "ax4 = fig.add_subplot(gs[1, :2])\n",
    "scatter_data = compartment_analysis.head(100).copy()\n",
    "\n",
    "# Calculate bubble sizes based on potential\n",
    "scatter_data['potential'] = (len(df['service'].unique()) - scatter_data['num_services']) * (scatter_data['total_cost'] / 10000)\n",
    "\n",
    "scatter = ax4.scatter(scatter_data['num_services'], scatter_data['total_cost'],\n",
    "                      s=scatter_data['potential']*10, alpha=0.6, \n",
    "                      c=scatter_data['num_services'], cmap='viridis', edgecolors='black', linewidth=0.5)\n",
    "\n",
    "# Highlight cross-sell targets\n",
    "if len(cross_sell_targets) > 0:\n",
    "    cs_plot_data = cross_sell_targets.head(10)\n",
    "    ax4.scatter(cs_plot_data['num_services'], cs_plot_data['total_cost'],\n",
    "                s=500, marker='*', color='red', edgecolors='black', linewidth=2,\n",
    "                label='üéØ Priority Targets', zorder=10)\n",
    "\n",
    "# Add quadrant lines\n",
    "median_cost = scatter_data['total_cost'].median()\n",
    "median_svcs = scatter_data['num_services'].median()\n",
    "ax4.axhline(y=median_cost, color='red', linestyle='--', linewidth=1.5, alpha=0.5)\n",
    "ax4.axvline(x=median_svcs, color='red', linestyle='--', linewidth=1.5, alpha=0.5)\n",
    "\n",
    "# Label quadrants\n",
    "ax4.text(scatter_data['num_services'].quantile(0.75), scatter_data['total_cost'].quantile(0.85),\n",
    "         'Enterprise\\n(Retain)', ha='center', fontsize=9, fontweight='bold',\n",
    "         bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.5))\n",
    "ax4.text(scatter_data['num_services'].quantile(0.25), scatter_data['total_cost'].quantile(0.85),\n",
    "         'HIGH CROSS-SELL\\n(Expand Services)', ha='center', fontsize=9, fontweight='bold',\n",
    "         bbox=dict(boxstyle='round', facecolor='orange', alpha=0.6))\n",
    "ax4.text(scatter_data['num_services'].quantile(0.75), scatter_data['total_cost'].quantile(0.15),\n",
    "         'Diverse Small\\n(Optimize)', ha='center', fontsize=9, fontweight='bold',\n",
    "         bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.5))\n",
    "ax4.text(scatter_data['num_services'].quantile(0.25), scatter_data['total_cost'].quantile(0.15),\n",
    "         'Starter\\n(Upsell)', ha='center', fontsize=9, fontweight='bold',\n",
    "         bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.5))\n",
    "\n",
    "ax4.set_xlabel('Number of Services Used', fontsize=11, fontweight='bold')\n",
    "ax4.set_ylabel('Total Revenue ($)', fontsize=11, fontweight='bold')\n",
    "ax4.set_title('üíº Customer Wallet Share Matrix\\n(Bubble size = Cross-sell Potential)', \n",
    "              fontsize=12, fontweight='bold')\n",
    "ax4.legend(loc='upper left', fontsize=9)\n",
    "ax4.grid(True, alpha=0.3)\n",
    "cbar = plt.colorbar(scatter, ax=ax4)\n",
    "cbar.set_label('Service Diversity', fontsize=9)\n",
    "\n",
    "# 5. TRENDING SERVICES - Hot vs Cold\n",
    "ax5 = fig.add_subplot(gs[1, 2])\n",
    "\n",
    "# Combine hot and declining for visualization\n",
    "trending_viz = []\n",
    "if len(hot_services) > 0:\n",
    "    for _, svc in hot_services.head(5).iterrows():\n",
    "        trending_viz.append({'service': svc['service'][:20], 'growth': svc['growth_rate'], 'type': 'Hot'})\n",
    "if len(declining_services) > 0:\n",
    "    for _, svc in declining_services.head(5).iterrows():\n",
    "        trending_viz.append({'service': svc['service'][:20], 'growth': svc['growth_rate'], 'type': 'Cold'})\n",
    "\n",
    "if trending_viz:\n",
    "    trend_df = pd.DataFrame(trending_viz).sort_values('growth')\n",
    "    colors_trend = ['green' if g > 0 else 'red' for g in trend_df['growth']]\n",
    "    \n",
    "    bars_trend = ax5.barh(range(len(trend_df)), trend_df['growth'], color=colors_trend, alpha=0.7, edgecolor='black')\n",
    "    ax5.set_yticks(range(len(trend_df)))\n",
    "    ax5.set_yticklabels(trend_df['service'], fontsize=8)\n",
    "    ax5.set_xlabel('Growth Rate (%)', fontsize=10, fontweight='bold')\n",
    "    ax5.set_title('üî• Trending Services\\n(Green=Push, Red=Retain)', fontsize=11, fontweight='bold')\n",
    "    ax5.axvline(x=0, color='black', linestyle='-', linewidth=2)\n",
    "    ax5.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    # Add labels\n",
    "    for i, (bar, val) in enumerate(zip(bars_trend, trend_df['growth'])):\n",
    "        label_x = val + (5 if val > 0 else -5)\n",
    "        ax5.text(label_x, i, f'{val:+.1f}%', va='center', fontsize=8, fontweight='bold')\n",
    "else:\n",
    "    ax5.text(0.5, 0.5, 'Insufficient growth data', ha='center', va='center', \n",
    "             fontsize=12, transform=ax5.transAxes)\n",
    "    ax5.axis('off')\n",
    "\n",
    "# 6-9. SERVICE-SPECIFIC REVENUE OPPORTUNITIES\n",
    "top_services_for_detail = service_summary.head(4)['service'].values\n",
    "\n",
    "for plot_idx, service_name in enumerate(top_services_for_detail):\n",
    "    ax_detail = fig.add_subplot(gs[2 + (plot_idx // 2), plot_idx % 2])\n",
    "    \n",
    "    # Get service data\n",
    "    svc_data = df[df['service'] == service_name].copy()\n",
    "    svc_regions = svc_data.groupby('region')['computedAmount'].sum().sort_values(ascending=False).head(8)\n",
    "    \n",
    "    # Calculate penetration per region\n",
    "    svc_comps_per_region = svc_data.groupby('region')['compartmentName'].nunique()\n",
    "    total_comps_per_region = df.groupby('region')['compartmentName'].nunique()\n",
    "    penetration_per_region = (svc_comps_per_region / total_comps_per_region * 100).reindex(svc_regions.index, fill_value=0)\n",
    "    \n",
    "    # Plot\n",
    "    x_svc = np.arange(len(svc_regions))\n",
    "    bars_svc = ax_detail.bar(x_svc, svc_regions.values, color='teal', alpha=0.7, edgecolor='black')\n",
    "    \n",
    "    # Color code by penetration\n",
    "    for bar, pen in zip(bars_svc, penetration_per_region):\n",
    "        if pen > 50:\n",
    "            bar.set_color('darkgreen')\n",
    "        elif pen > 25:\n",
    "            bar.set_color('orange')\n",
    "        else:\n",
    "            bar.set_color('red')\n",
    "    \n",
    "    ax_detail.set_xticks(x_svc)\n",
    "    ax_detail.set_xticklabels([r[:12] for r in svc_regions.index], rotation=45, ha='right', fontsize=8)\n",
    "    ax_detail.set_ylabel('Revenue ($)', fontsize=9, fontweight='bold')\n",
    "    ax_detail.set_title(f'{service_name[:30]}\\nRegional Distribution', fontsize=10, fontweight='bold')\n",
    "    ax_detail.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add penetration labels\n",
    "    for i, (bar, rev, pen) in enumerate(zip(bars_svc, svc_regions.values, penetration_per_region)):\n",
    "        ax_detail.text(i, bar.get_height(), f'{pen:.0f}%', ha='center', va='bottom', \n",
    "                      fontsize=7, fontweight='bold')\n",
    "\n",
    "# 10. ACTIONABLE INSIGHTS SUMMARY\n",
    "ax_summary = fig.add_subplot(gs[3, 2])\n",
    "ax_summary.axis('off')\n",
    "\n",
    "summary_text = f\"\"\"\n",
    "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "‚ïë   üéØ ACTIONABLE SALES PRIORITIES      ‚ïë\n",
    "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "\n",
    "1Ô∏è‚É£  RETENTION FOCUS\n",
    "   ‚Ä¢ Protect top {services_for_80pct} services\n",
    "   ‚Ä¢ ${service_revenue_sorted.head(services_for_80pct)['total_cost'].sum():,.0f} at risk\n",
    "\n",
    "2Ô∏è‚É£  CROSS-SELL TARGETS\n",
    "   ‚Ä¢ {len(cross_sell_targets)} high-value accounts\n",
    "   ‚Ä¢ Low service diversity = high potential\n",
    "   ‚Ä¢ Est. Potential: ${total_cross_sell_potential:,.0f}\n",
    "\n",
    "3Ô∏è‚É£  REGIONAL EXPANSION\n",
    "   ‚Ä¢ Top region: {reg_opp_df.iloc[0]['region']}\n",
    "   ‚Ä¢ {reg_opp_df.iloc[0]['missing_services']} services to introduce\n",
    "   ‚Ä¢ Focus on proven services from other regions\n",
    "\n",
    "4Ô∏è‚É£  TRENDING SERVICES\n",
    "   ‚Ä¢ Hot: {len(hot_services)} services growing\n",
    "   ‚Ä¢ Cold: {len(declining_services)} services declining\n",
    "   ‚Ä¢ Push hot services to all regions\n",
    "\n",
    "5Ô∏è‚É£  QUICK WINS\n",
    "   ‚Ä¢ Target compartments: <10 services + high spend\n",
    "   ‚Ä¢ Introduce top 3 bundles\n",
    "   ‚Ä¢ Focus on top 3 regions\n",
    "\n",
    "üí∞ TOTAL OPPORTUNITY:\n",
    "   Cross-sell + Upsell + Regional Expansion\n",
    "   = ${total_cross_sell_potential + (len(reg_opp_df) * 50000):,.0f}\n",
    "\"\"\"\n",
    "\n",
    "ax_summary.text(0.05, 0.95, summary_text, transform=ax_summary.transAxes,\n",
    "                fontsize=8, verticalalignment='top', fontfamily='monospace',\n",
    "                bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.7, \n",
    "                         edgecolor='darkorange', linewidth=3))\n",
    "\n",
    "plt.suptitle('üìä SALES INTELLIGENCE DASHBOARD - ACTIONABLE INSIGHTS FOR REVENUE GROWTH', \n",
    "             fontsize=17, fontweight='bold', y=0.995)\n",
    "\n",
    "plt.show()\n",
    "print(\"\\n‚úÖ Sales Intelligence Dashboard created successfully!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ec5f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional detailed visualizations for specific insights\n",
    "\n",
    "# Visualization 2: Service-level trends for top services\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "fig.suptitle('Top 4 Services - Detailed Trend Analysis', fontsize=14, fontweight='bold')\n",
    "\n",
    "top_4_services = service_summary.head(4)['service'].values\n",
    "\n",
    "for idx, (ax, service) in enumerate(zip(axes.flat, top_4_services)):\n",
    "    service_monthly = df[df['service'] == service].groupby('year_month').agg({\n",
    "        'computedAmount': 'sum',\n",
    "        'resourceId': 'nunique',\n",
    "        'computedQuantity': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    ax2 = ax.twinx()\n",
    "    \n",
    "    # Bar chart for cost\n",
    "    ax.bar(range(len(service_monthly)), service_monthly['computedAmount'].values, \n",
    "           color='skyblue', alpha=0.7, label='Cost')\n",
    "    \n",
    "    # Line chart for resource count\n",
    "    ax2.plot(range(len(service_monthly)), service_monthly['resourceId'].values, \n",
    "            marker='o', color='red', linewidth=2, markersize=6, label='Resources')\n",
    "    \n",
    "    ax.set_xlabel('Month')\n",
    "    ax.set_ylabel('Cost ($)', color='skyblue')\n",
    "    ax2.set_ylabel('Number of Resources', color='red')\n",
    "    ax.set_title(f'{service}', fontweight='bold')\n",
    "    ax.set_xticks(range(len(service_monthly)))\n",
    "    ax.set_xticklabels(service_monthly['year_month'].values, rotation=45, ha='right', fontsize=9)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add legends\n",
    "    ax.legend(loc='upper left')\n",
    "    ax2.legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "print(\"‚úÖ Top Services Trends visualization complete\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b404557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regional growth analysis visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "fig.suptitle('Regional Analysis & Growth Opportunities', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Regional cost and service adoption\n",
    "ax1 = axes[0]\n",
    "top_regions_detail = regional_analysis.head(10)\n",
    "x_pos = np.arange(len(top_regions_detail))\n",
    "width = 0.35\n",
    "\n",
    "ax1_bar = ax1.bar(x_pos - width/2, top_regions_detail['total_cost'].values, width, \n",
    "                   label='Total Cost', color='steelblue', alpha=0.8)\n",
    "ax1_twin = ax1.twinx()\n",
    "ax1_twin.bar(x_pos + width/2, top_regions_detail['num_services'].values, width,\n",
    "             label='Number of Services', color='coral', alpha=0.8)\n",
    "\n",
    "ax1.set_xlabel('Region')\n",
    "ax1.set_ylabel('Total Cost ($)', color='steelblue')\n",
    "ax1_twin.set_ylabel('Services Count', color='coral')\n",
    "ax1.set_title('Regional Cost Distribution & Service Diversity')\n",
    "ax1.set_xticks(x_pos)\n",
    "ax1.set_xticklabels(top_regions_detail['region'].values, rotation=45, ha='right')\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Regional growth rates\n",
    "ax2 = axes[1]\n",
    "# Check if regional_growth_df exists and has data\n",
    "if 'regional_growth_df' in locals() and len(regional_growth_df) > 0:\n",
    "    regional_growth_display = regional_growth_df.head(10).sort_values('growth_rate')\n",
    "    colors_reg = ['green' if x > 0 else 'red' for x in regional_growth_display['growth_rate'].values]\n",
    "    ax2.barh(range(len(regional_growth_display)), regional_growth_display['growth_rate'].values, \n",
    "             color=colors_reg, alpha=0.7)\n",
    "    ax2.set_yticks(range(len(regional_growth_display)))\n",
    "    ax2.set_yticklabels(regional_growth_display['region'].values)\n",
    "    ax2.set_xlabel('Growth Rate (%)')\n",
    "    ax2.set_title('Regional Growth Rates (Period-over-Period)')\n",
    "    ax2.axvline(x=0, color='black', linestyle='-', linewidth=1)\n",
    "    ax2.grid(True, alpha=0.3, axis='x')\n",
    "else:\n",
    "    ax2.text(0.5, 0.5, 'Insufficient multi-month data\\nfor regional growth analysis', \n",
    "             ha='center', va='center', fontsize=12, transform=ax2.transAxes)\n",
    "    ax2.set_title('Regional Growth Rates (Period-over-Period)')\n",
    "    ax2.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "print(\"‚úÖ Regional Analysis visualization complete\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a64645c",
   "metadata": {},
   "source": [
    "## 13. Cross-Selling Opportunity Analysis\n",
    "\n",
    "Identify services that are frequently used together, service adoption gaps, and cross-selling opportunities across compartments and regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdea96f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze service co-occurrence patterns for cross-selling opportunities\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"CROSS-SELLING OPPORTUNITY ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Service Co-occurrence Analysis\n",
    "print(\"\\nüìä Analyzing service usage patterns across compartments...\")\n",
    "\n",
    "# Build service co-occurrence matrix\n",
    "from itertools import combinations\n",
    "\n",
    "service_cooccurrence = {}\n",
    "compartments_with_service = {}\n",
    "\n",
    "# Track which compartments use which services\n",
    "for service in df['service'].unique():\n",
    "    compartments_with_service[service] = set(df[df['service'] == service]['compartmentName'].unique())\n",
    "\n",
    "# Calculate co-occurrence scores\n",
    "for service1, service2 in combinations(df['service'].unique(), 2):\n",
    "    comp1 = compartments_with_service[service1]\n",
    "    comp2 = compartments_with_service[service2]\n",
    "    \n",
    "    # Jaccard similarity (intersection / union)\n",
    "    intersection = len(comp1 & comp2)\n",
    "    union = len(comp1 | comp2)\n",
    "    \n",
    "    if union > 0 and intersection > 0:\n",
    "        jaccard = intersection / union\n",
    "        support = intersection  # How many compartments use both\n",
    "        \n",
    "        service_cooccurrence[(service1, service2)] = {\n",
    "            'jaccard': jaccard,\n",
    "            'support': support,\n",
    "            'comp1_only': len(comp1 - comp2),\n",
    "            'comp2_only': len(comp2 - comp1),\n",
    "            'both': intersection\n",
    "        }\n",
    "\n",
    "# Convert to DataFrame for analysis\n",
    "cooccurrence_list = []\n",
    "for (s1, s2), metrics in service_cooccurrence.items():\n",
    "    cooccurrence_list.append({\n",
    "        'service1': s1,\n",
    "        'service2': s2,\n",
    "        'jaccard_similarity': metrics['jaccard'],\n",
    "        'compartments_both': metrics['both'],\n",
    "        'compartments_s1_only': metrics['comp1_only'],\n",
    "        'compartments_s2_only': metrics['comp2_only'],\n",
    "        'cross_sell_potential': metrics['comp1_only'] + metrics['comp2_only']\n",
    "    })\n",
    "\n",
    "cooccurrence_df = pd.DataFrame(cooccurrence_list)\n",
    "cooccurrence_df = cooccurrence_df.sort_values('compartments_both', ascending=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Analyzed {len(cooccurrence_df)} service pairs\")\n",
    "print(f\"üìä Found {len(cooccurrence_df[cooccurrence_df['compartments_both'] > 5])} strong service associations (5+ compartments)\")\n",
    "\n",
    "# Top service pairs (frequently used together)\n",
    "print(\"\\nüîó TOP 10 SERVICE PAIRS - Frequently Used Together:\")\n",
    "print(\"-\"*80)\n",
    "top_pairs = cooccurrence_df.head(10)\n",
    "for idx, row in top_pairs.iterrows():\n",
    "    print(f\"\\n{row['service1'][:40]} + {row['service2'][:40]}\")\n",
    "    print(f\"   Used together in: {row['compartments_both']} compartments\")\n",
    "    print(f\"   Jaccard Similarity: {row['jaccard_similarity']:.3f}\")\n",
    "    print(f\"   Cross-sell potential: {row['cross_sell_potential']} compartments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a1920e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize service co-occurrence network\n",
    "\n",
    "# Create network visualization of top service relationships\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 14))\n",
    "fig.suptitle('Cross-Selling Opportunity Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Top Service Pairs Heatmap\n",
    "ax1 = axes[0, 0]\n",
    "top_15_services = service_summary.head(15)['service'].values\n",
    "\n",
    "# Build adjacency matrix for top services\n",
    "adjacency = np.zeros((len(top_15_services), len(top_15_services)))\n",
    "for i, s1 in enumerate(top_15_services):\n",
    "    for j, s2 in enumerate(top_15_services):\n",
    "        if i != j:\n",
    "            pair_data = cooccurrence_df[\n",
    "                ((cooccurrence_df['service1'] == s1) & (cooccurrence_df['service2'] == s2)) |\n",
    "                ((cooccurrence_df['service1'] == s2) & (cooccurrence_df['service2'] == s1))\n",
    "            ]\n",
    "            if not pair_data.empty:\n",
    "                adjacency[i, j] = pair_data.iloc[0]['compartments_both']\n",
    "\n",
    "im1 = ax1.imshow(adjacency, cmap='YlOrRd', aspect='auto')\n",
    "ax1.set_xticks(range(len(top_15_services)))\n",
    "ax1.set_yticks(range(len(top_15_services)))\n",
    "ax1.set_xticklabels([s[:20] + '...' if len(s) > 20 else s for s in top_15_services], rotation=45, ha='right', fontsize=8)\n",
    "ax1.set_yticklabels([s[:20] + '...' if len(s) > 20 else s for s in top_15_services], fontsize=8)\n",
    "ax1.set_title('Service Co-occurrence Matrix\\n(Number of shared compartments)', fontweight='bold')\n",
    "plt.colorbar(im1, ax=ax1, label='Compartments')\n",
    "\n",
    "# 2. Cross-sell potential by service\n",
    "ax2 = axes[0, 1]\n",
    "# Calculate cross-sell score for each service\n",
    "cross_sell_scores = {}\n",
    "for service in top_15_services:\n",
    "    # Find all pairs where this service appears\n",
    "    service_pairs = cooccurrence_df[\n",
    "        (cooccurrence_df['service1'] == service) | (cooccurrence_df['service2'] == service)\n",
    "    ]\n",
    "    \n",
    "    # Sum up cross-sell potential\n",
    "    total_potential = 0\n",
    "    for _, row in service_pairs.iterrows():\n",
    "        if row['service1'] == service:\n",
    "            total_potential += row['compartments_s2_only']\n",
    "        else:\n",
    "            total_potential += row['compartments_s1_only']\n",
    "    \n",
    "    cross_sell_scores[service] = total_potential\n",
    "\n",
    "# Sort and plot\n",
    "cross_sell_df = pd.DataFrame(list(cross_sell_scores.items()), columns=['service', 'cross_sell_potential'])\n",
    "cross_sell_df = cross_sell_df.sort_values('cross_sell_potential', ascending=True)\n",
    "\n",
    "ax2.barh(range(len(cross_sell_df)), cross_sell_df['cross_sell_potential'].values, \n",
    "         color=plt.cm.viridis(np.linspace(0, 1, len(cross_sell_df))))\n",
    "ax2.set_yticks(range(len(cross_sell_df)))\n",
    "ax2.set_yticklabels([s[:30] + '...' if len(s) > 30 else s for s in cross_sell_df['service'].values], fontsize=9)\n",
    "ax2.set_xlabel('Cross-Sell Opportunities (Compartments)')\n",
    "ax2.set_title('Service Cross-Sell Potential', fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# 3. Service Adoption Gap Analysis by Region\n",
    "ax3 = axes[1, 0]\n",
    "top_8_services = service_summary.head(8)['service'].values\n",
    "top_8_regions = regional_analysis.head(8)['region'].values\n",
    "\n",
    "# Build adoption matrix (1 if service used in region, 0 otherwise)\n",
    "adoption_matrix = np.zeros((len(top_8_services), len(top_8_regions)))\n",
    "for i, service in enumerate(top_8_services):\n",
    "    for j, region in enumerate(top_8_regions):\n",
    "        count = len(df[(df['service'] == service) & (df['region'] == region)])\n",
    "        adoption_matrix[i, j] = 1 if count > 0 else 0\n",
    "\n",
    "im3 = ax3.imshow(adoption_matrix, cmap='RdYlGn', aspect='auto', vmin=0, vmax=1)\n",
    "ax3.set_xticks(range(len(top_8_regions)))\n",
    "ax3.set_yticks(range(len(top_8_services)))\n",
    "ax3.set_xticklabels(top_8_regions, rotation=45, ha='right', fontsize=9)\n",
    "ax3.set_yticklabels([s[:25] + '...' if len(s) > 25 else s for s in top_8_services], fontsize=9)\n",
    "ax3.set_title('Service Adoption by Region\\n(Red = Gap Opportunity, Green = Adopted)', fontweight='bold')\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(len(top_8_services)):\n",
    "    for j in range(len(top_8_regions)):\n",
    "        text = ax3.text(j, i, '‚úì' if adoption_matrix[i, j] == 1 else '‚úó',\n",
    "                       ha=\"center\", va=\"center\", color=\"white\" if adoption_matrix[i, j] == 1 else \"black\",\n",
    "                       fontsize=10, fontweight='bold')\n",
    "\n",
    "# 4. Top Cross-Sell Opportunities (specific recommendations)\n",
    "ax4 = axes[1, 1]\n",
    "ax4.axis('off')\n",
    "\n",
    "# Find top specific cross-sell opportunities\n",
    "recommendations = []\n",
    "for _, row in cooccurrence_df.head(20).iterrows():\n",
    "    if row['cross_sell_potential'] > 10:  # Significant opportunity\n",
    "        recommendations.append({\n",
    "            'primary': row['service1'][:35],\n",
    "            'cross_sell': row['service2'][:35],\n",
    "            'potential': row['cross_sell_potential'],\n",
    "            'together': row['compartments_both']\n",
    "        })\n",
    "\n",
    "# Display as table\n",
    "table_data = []\n",
    "table_data.append(['Primary Service', 'Cross-Sell To', 'Potential', 'Current'])\n",
    "table_data.append(['-'*35, '-'*35, '-'*10, '-'*10])\n",
    "\n",
    "for rec in recommendations[:10]:\n",
    "    table_data.append([\n",
    "        rec['primary'][:35],\n",
    "        rec['cross_sell'][:35],\n",
    "        f\"{rec['potential']} comps\",\n",
    "        f\"{rec['together']} comps\"\n",
    "    ])\n",
    "\n",
    "ax4.text(0.5, 0.95, 'TOP CROSS-SELL RECOMMENDATIONS', \n",
    "         ha='center', va='top', fontsize=14, fontweight='bold', transform=ax4.transAxes)\n",
    "\n",
    "y_position = 0.88\n",
    "for row in table_data:\n",
    "    if row[0].startswith('-'):\n",
    "        ax4.text(0.05, y_position, row[0], fontsize=8, family='monospace', transform=ax4.transAxes)\n",
    "        ax4.text(0.42, y_position, row[1], fontsize=8, family='monospace', transform=ax4.transAxes)\n",
    "        ax4.text(0.78, y_position, row[2], fontsize=8, family='monospace', transform=ax4.transAxes)\n",
    "        ax4.text(0.90, y_position, row[3], fontsize=8, family='monospace', transform=ax4.transAxes)\n",
    "    else:\n",
    "        ax4.text(0.05, y_position, row[0], fontsize=8, family='monospace', transform=ax4.transAxes)\n",
    "        ax4.text(0.42, y_position, row[1], fontsize=8, family='monospace', transform=ax4.transAxes)\n",
    "        ax4.text(0.78, y_position, row[2], fontsize=8, family='monospace', transform=ax4.transAxes, \n",
    "                color='darkgreen' if 'comps' in row[2] else 'black')\n",
    "        ax4.text(0.90, y_position, row[3], fontsize=8, family='monospace', transform=ax4.transAxes)\n",
    "    y_position -= 0.08\n",
    "\n",
    "plt.tight_layout()\n",
    "print(\"‚úÖ Cross-Selling Analysis visualization complete\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2f6c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Service Bundle Analysis - Identify common service combinations\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SERVICE BUNDLE RECOMMENDATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Find most common 3-service bundles\n",
    "from collections import Counter\n",
    "\n",
    "service_bundles = []\n",
    "for comp in df['compartmentName'].unique():\n",
    "    comp_services = sorted(df[df['compartmentName'] == comp]['service'].unique())\n",
    "    if len(comp_services) >= 3:\n",
    "        # Generate all 3-service combinations\n",
    "        for combo in combinations(comp_services, 3):\n",
    "            service_bundles.append(tuple(sorted(combo)))\n",
    "\n",
    "bundle_counts = Counter(service_bundles)\n",
    "top_bundles = bundle_counts.most_common(15)\n",
    "\n",
    "print(f\"\\nüì¶ TOP 15 THREE-SERVICE BUNDLES:\")\n",
    "print(\"-\"*80)\n",
    "for idx, (bundle, count) in enumerate(top_bundles, 1):\n",
    "    print(f\"\\n{idx}. Bundle used by {count} compartments:\")\n",
    "    for service in bundle:\n",
    "        print(f\"   ‚Ä¢ {service[:70]}\")\n",
    "\n",
    "# Visualize bundle popularity\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "fig.suptitle('Service Bundle Analysis', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Bundle frequency chart\n",
    "ax1 = axes[0]\n",
    "bundle_names = [f\"Bundle {i+1}\" for i in range(min(10, len(top_bundles)))]\n",
    "bundle_freqs = [count for _, count in top_bundles[:10]]\n",
    "\n",
    "bars = ax1.barh(range(len(bundle_names)), bundle_freqs, color=plt.cm.Paired(np.linspace(0, 1, len(bundle_names))))\n",
    "ax1.set_yticks(range(len(bundle_names)))\n",
    "ax1.set_yticklabels(bundle_names)\n",
    "ax1.set_xlabel('Number of Compartments Using Bundle')\n",
    "ax1.set_title('Most Popular 3-Service Bundles', fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Add value labels\n",
    "for i, (bar, freq) in enumerate(zip(bars, bundle_freqs)):\n",
    "    ax1.text(freq + 0.5, i, str(freq), va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Service diversity per compartment\n",
    "ax2 = axes[1]\n",
    "comp_service_counts = df.groupby('compartmentName')['service'].nunique().reset_index()\n",
    "comp_service_counts.columns = ['compartment', 'num_services']\n",
    "\n",
    "# Create histogram\n",
    "bins = [1, 2, 3, 5, 10, 20, 50, 100]\n",
    "hist, bin_edges = np.histogram(comp_service_counts['num_services'], bins=bins)\n",
    "\n",
    "ax2.bar(range(len(hist)), hist, color='teal', alpha=0.7, edgecolor='black')\n",
    "ax2.set_xticks(range(len(hist)))\n",
    "ax2.set_xticklabels([f\"{bins[i]}-{bins[i+1]}\" for i in range(len(bins)-1)], rotation=45)\n",
    "ax2.set_xlabel('Number of Services per Compartment')\n",
    "ax2.set_ylabel('Number of Compartments')\n",
    "ax2.set_title('Service Diversity Distribution', fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add percentage labels\n",
    "total_comps = len(comp_service_counts)\n",
    "for i, count in enumerate(hist):\n",
    "    percentage = (count / total_comps) * 100\n",
    "    ax2.text(i, count + max(hist)*0.02, f'{count}\\n({percentage:.1f}%)', \n",
    "            ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "print(\"\\n‚úÖ Service Bundle visualization complete\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate bundle uplift potential\n",
    "print(f\"\\nüí° BUNDLE UPLIFT ANALYSIS:\")\n",
    "print(\"-\"*80)\n",
    "print(f\"Total Compartments: {len(df['compartmentName'].unique())}\")\n",
    "print(f\"Avg Services per Compartment: {comp_service_counts['num_services'].mean():.1f}\")\n",
    "print(f\"Median Services per Compartment: {comp_service_counts['num_services'].median():.0f}\")\n",
    "print(f\"\\nCompartments with 1-2 services: {len(comp_service_counts[comp_service_counts['num_services'] <= 2])} \"\n",
    "      f\"({len(comp_service_counts[comp_service_counts['num_services'] <= 2])/total_comps*100:.1f}%)\")\n",
    "print(f\"   ‚Üí High potential for bundle upsell\")\n",
    "print(f\"\\nCompartments with 10+ services: {len(comp_service_counts[comp_service_counts['num_services'] >= 10])} \"\n",
    "      f\"({len(comp_service_counts[comp_service_counts['num_services'] >= 10])/total_comps*100:.1f}%)\")\n",
    "print(f\"   ‚Üí Premium customers, focus on optimization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fd35cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compartment Segmentation for Targeted Cross-Selling\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARTMENT SEGMENTATION FOR CROSS-SELLING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Segment compartments by service adoption and spending\n",
    "compartment_profiles = df.groupby('compartmentName').agg({\n",
    "    'computedAmount': 'sum',\n",
    "    'service': 'nunique',\n",
    "    'resourceId': 'nunique',\n",
    "    'region': 'nunique'\n",
    "}).reset_index()\n",
    "compartment_profiles.columns = ['compartment', 'total_spend', 'num_services', 'num_resources', 'num_regions']\n",
    "\n",
    "# Calculate percentiles for segmentation\n",
    "spend_q33 = compartment_profiles['total_spend'].quantile(0.33)\n",
    "spend_q66 = compartment_profiles['total_spend'].quantile(0.66)\n",
    "service_q33 = compartment_profiles['num_services'].quantile(0.33)\n",
    "service_q66 = compartment_profiles['num_services'].quantile(0.66)\n",
    "\n",
    "# Create segments\n",
    "def segment_compartment(row):\n",
    "    if row['total_spend'] >= spend_q66 and row['num_services'] >= service_q66:\n",
    "        return 'Enterprise (High Spend, High Diversity)'\n",
    "    elif row['total_spend'] >= spend_q66 and row['num_services'] < service_q66:\n",
    "        return 'High Value (High Spend, Low Diversity)'\n",
    "    elif row['total_spend'] < spend_q33 and row['num_services'] < service_q33:\n",
    "        return 'Starter (Low Spend, Low Diversity)'\n",
    "    elif row['total_spend'] < spend_q33 and row['num_services'] >= service_q66:\n",
    "        return 'Diverse Small (Low Spend, High Diversity)'\n",
    "    elif row['num_services'] >= service_q66:\n",
    "        return 'Growing (Mid Spend, High Diversity)'\n",
    "    elif row['total_spend'] >= spend_q66:\n",
    "        return 'Focused High Value (High Spend, Mid Diversity)'\n",
    "    else:\n",
    "        return 'Standard (Mid Spend, Mid Diversity)'\n",
    "\n",
    "compartment_profiles['segment'] = compartment_profiles.apply(segment_compartment, axis=1)\n",
    "\n",
    "# Visualize segmentation\n",
    "fig = plt.figure(figsize=(18, 10))\n",
    "\n",
    "# 1. Scatter plot with segments\n",
    "ax1 = plt.subplot(2, 2, 1)\n",
    "segments = compartment_profiles['segment'].unique()\n",
    "colors_seg = plt.cm.Set3(np.linspace(0, 1, len(segments)))\n",
    "color_map = dict(zip(segments, colors_seg))\n",
    "\n",
    "for segment in segments:\n",
    "    seg_data = compartment_profiles[compartment_profiles['segment'] == segment]\n",
    "    ax1.scatter(seg_data['num_services'], seg_data['total_spend'], \n",
    "               label=segment, alpha=0.6, s=100, color=color_map[segment], edgecolors='black', linewidth=0.5)\n",
    "\n",
    "ax1.set_xlabel('Number of Services', fontsize=11, fontweight='bold')\n",
    "ax1.set_ylabel('Total Spend ($)', fontsize=11, fontweight='bold')\n",
    "ax1.set_title('Compartment Segmentation', fontsize=12, fontweight='bold')\n",
    "ax1.legend(loc='best', fontsize=8)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.axhline(y=spend_q66, color='red', linestyle='--', alpha=0.5, linewidth=1)\n",
    "ax1.axhline(y=spend_q33, color='orange', linestyle='--', alpha=0.5, linewidth=1)\n",
    "ax1.axvline(x=service_q66, color='red', linestyle='--', alpha=0.5, linewidth=1)\n",
    "ax1.axvline(x=service_q33, color='orange', linestyle='--', alpha=0.5, linewidth=1)\n",
    "\n",
    "# 2. Segment distribution\n",
    "ax2 = plt.subplot(2, 2, 2)\n",
    "segment_counts = compartment_profiles['segment'].value_counts()\n",
    "colors_pie2 = [color_map[seg] for seg in segment_counts.index]\n",
    "wedges, texts, autotexts = ax2.pie(segment_counts.values, labels=segment_counts.index, \n",
    "                                     autopct='%1.1f%%', colors=colors_pie2, startangle=90)\n",
    "for autotext in autotexts:\n",
    "    autotext.set_color('black')\n",
    "    autotext.set_fontweight('bold')\n",
    "    autotext.set_fontsize(9)\n",
    "ax2.set_title('Compartment Distribution by Segment', fontsize=12, fontweight='bold')\n",
    "\n",
    "# 3. Cross-sell opportunity by segment\n",
    "ax3 = plt.subplot(2, 2, 3)\n",
    "segment_opportunities = []\n",
    "for segment in segments:\n",
    "    seg_comps = compartment_profiles[compartment_profiles['segment'] == segment]['compartment'].values\n",
    "    avg_services = compartment_profiles[compartment_profiles['segment'] == segment]['num_services'].mean()\n",
    "    max_services_available = df['service'].nunique()\n",
    "    opportunity = max_services_available - avg_services\n",
    "    segment_opportunities.append({\n",
    "        'segment': segment,\n",
    "        'avg_services': avg_services,\n",
    "        'opportunity': opportunity,\n",
    "        'count': len(seg_comps)\n",
    "    })\n",
    "\n",
    "seg_opp_df = pd.DataFrame(segment_opportunities).sort_values('opportunity', ascending=True)\n",
    "bars3 = ax3.barh(range(len(seg_opp_df)), seg_opp_df['opportunity'].values,\n",
    "                color=[color_map[s] for s in seg_opp_df['segment'].values], alpha=0.7, edgecolor='black')\n",
    "ax3.set_yticks(range(len(seg_opp_df)))\n",
    "ax3.set_yticklabels([s[:30] for s in seg_opp_df['segment'].values], fontsize=9)\n",
    "ax3.set_xlabel('Avg Services Gap (Cross-sell Potential)', fontsize=10, fontweight='bold')\n",
    "ax3.set_title('Cross-Sell Opportunity by Segment', fontsize=12, fontweight='bold')\n",
    "ax3.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Add value labels\n",
    "for i, (opp, count) in enumerate(zip(seg_opp_df['opportunity'].values, seg_opp_df['count'].values)):\n",
    "    ax3.text(opp + 1, i, f'{opp:.1f} ({count} comps)', va='center', fontsize=8)\n",
    "\n",
    "# 4. Segment recommendations\n",
    "ax4 = plt.subplot(2, 2, 4)\n",
    "ax4.axis('off')\n",
    "\n",
    "recommendations_text = \"\"\"\n",
    "SEGMENT-SPECIFIC RECOMMENDATIONS:\n",
    "\n",
    "üè¢ Enterprise (High Spend, High Diversity)\n",
    "   ‚Ä¢ Focus: Optimization & Advanced Features\n",
    "   ‚Ä¢ Action: Premium support, custom solutions\n",
    "   ‚Ä¢ Cross-sell: Emerging services, add-ons\n",
    "\n",
    "üíé High Value (High Spend, Low Diversity)\n",
    "   ‚Ä¢ Focus: Service Expansion & Diversification\n",
    "   ‚Ä¢ Action: Introduce complementary services\n",
    "   ‚Ä¢ Cross-sell: HIGH PRIORITY - Bundles\n",
    "\n",
    "üå± Starter (Low Spend, Low Diversity)\n",
    "   ‚Ä¢ Focus: Education & Onboarding\n",
    "   ‚Ä¢ Action: Starter bundles, free trials\n",
    "   ‚Ä¢ Cross-sell: Foundational services\n",
    "\n",
    "üìä Diverse Small (Low Spend, High Diversity)\n",
    "   ‚Ä¢ Focus: Usage Optimization\n",
    "   ‚Ä¢ Action: Identify unused services\n",
    "   ‚Ä¢ Cross-sell: Consolidation opportunities\n",
    "\n",
    "üöÄ Growing (Mid Spend, High Diversity)\n",
    "   ‚Ä¢ Focus: Scale & Performance\n",
    "   ‚Ä¢ Action: Growth packages, volume discounts\n",
    "   ‚Ä¢ Cross-sell: Premium tiers\n",
    "\n",
    "‚≠ê Focused High Value (High Spend, Mid Diversity)\n",
    "   ‚Ä¢ Focus: Adjacent Service Adoption\n",
    "   ‚Ä¢ Action: Targeted campaigns\n",
    "   ‚Ä¢ Cross-sell: MEDIUM-HIGH PRIORITY\n",
    "\n",
    "üìà Standard (Mid Spend, Mid Diversity)\n",
    "   ‚Ä¢ Focus: Gradual Expansion\n",
    "   ‚Ä¢ Action: Success stories, use cases\n",
    "   ‚Ä¢ Cross-sell: Popular bundles\n",
    "\"\"\"\n",
    "\n",
    "ax4.text(0.05, 0.95, recommendations_text, transform=ax4.transAxes, \n",
    "        fontsize=9, verticalalignment='top', family='monospace',\n",
    "        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))\n",
    "\n",
    "plt.tight_layout()\n",
    "print(f\"\\n‚úÖ Compartment Segmentation complete\")\n",
    "print(f\"\\nüìä Segment Summary:\")\n",
    "for _, row in seg_opp_df.iterrows():\n",
    "    print(f\"   {row['segment']}: {row['count']} compartments, avg {row['avg_services']:.1f} services, \"\n",
    "          f\"cross-sell gap: {row['opportunity']:.1f} services\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a414e852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-Selling Action Plan Dashboard\n",
    "\n",
    "fig = plt.figure(figsize=(18, 10))\n",
    "fig.suptitle('Cross-Selling Action Plan Dashboard', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Top Priority Cross-Sell Targets (Compartments)\n",
    "ax1 = plt.subplot(2, 3, 1)\n",
    "# Find compartments with high spend but low service diversity\n",
    "high_value_low_div = compartment_profiles[\n",
    "    (compartment_profiles['total_spend'] > compartment_profiles['total_spend'].quantile(0.75)) &\n",
    "    (compartment_profiles['num_services'] < compartment_profiles['num_services'].quantile(0.5))\n",
    "].sort_values('total_spend', ascending=False).head(10)\n",
    "\n",
    "ax1.barh(range(len(high_value_low_div)), high_value_low_div['total_spend'].values,\n",
    "        color='coral', alpha=0.7, edgecolor='black')\n",
    "ax1.set_yticks(range(len(high_value_low_div)))\n",
    "ax1.set_yticklabels([c[:25] + '...' if len(c) > 25 else c for c in high_value_low_div['compartment'].values], fontsize=8)\n",
    "ax1.set_xlabel('Total Spend ($)')\n",
    "ax1.set_title('üéØ Priority Accounts\\n(High Spend, Low Diversity)', fontweight='bold', fontsize=11)\n",
    "ax1.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Add service count annotations\n",
    "for i, (spend, num_svc) in enumerate(zip(high_value_low_div['total_spend'].values, high_value_low_div['num_services'].values)):\n",
    "    ax1.text(spend * 0.5, i, f'{int(num_svc)} svcs', va='center', ha='center', \n",
    "            fontsize=8, fontweight='bold', color='white')\n",
    "\n",
    "# 2. Service Penetration Rate\n",
    "ax2 = plt.subplot(2, 3, 2)\n",
    "# Calculate penetration rate for each service\n",
    "service_penetration = []\n",
    "total_compartments = len(df['compartmentName'].unique())\n",
    "for service in service_summary.head(15)['service'].values:\n",
    "    comps_with_service = len(df[df['service'] == service]['compartmentName'].unique())\n",
    "    penetration = (comps_with_service / total_compartments) * 100\n",
    "    service_penetration.append({\n",
    "        'service': service,\n",
    "        'penetration': penetration,\n",
    "        'comps_count': comps_with_service\n",
    "    })\n",
    "\n",
    "pen_df = pd.DataFrame(service_penetration).sort_values('penetration')\n",
    "colors_pen = ['green' if p > 50 else 'orange' if p > 25 else 'red' for p in pen_df['penetration'].values]\n",
    "\n",
    "ax2.barh(range(len(pen_df)), pen_df['penetration'].values, color=colors_pen, alpha=0.7, edgecolor='black')\n",
    "ax2.set_yticks(range(len(pen_df)))\n",
    "ax2.set_yticklabels([s[:25] + '...' if len(s) > 25 else s for s in pen_df['service'].values], fontsize=8)\n",
    "ax2.set_xlabel('Penetration Rate (%)')\n",
    "ax2.set_title('üìä Service Penetration Rates\\n(Red=Low, Orange=Medium, Green=High)', fontweight='bold', fontsize=11)\n",
    "ax2.axvline(x=50, color='darkgreen', linestyle='--', alpha=0.5, linewidth=2)\n",
    "ax2.axvline(x=25, color='orange', linestyle='--', alpha=0.5, linewidth=2)\n",
    "ax2.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# 3. Regional Service Gap Matrix\n",
    "ax3 = plt.subplot(2, 3, 3)\n",
    "top_5_services = service_summary.head(5)['service'].values\n",
    "top_6_regions = regional_analysis.head(6)['region'].values\n",
    "\n",
    "gap_matrix = np.zeros((len(top_5_services), len(top_6_regions)))\n",
    "for i, service in enumerate(top_5_services):\n",
    "    for j, region in enumerate(top_6_regions):\n",
    "        comps_in_region = len(df[df['region'] == region]['compartmentName'].unique())\n",
    "        comps_with_service = len(df[(df['service'] == service) & (df['region'] == region)]['compartmentName'].unique())\n",
    "        gap_matrix[i, j] = ((comps_in_region - comps_with_service) / comps_in_region * 100) if comps_in_region > 0 else 0\n",
    "\n",
    "im3 = ax3.imshow(gap_matrix, cmap='Reds', aspect='auto')\n",
    "ax3.set_xticks(range(len(top_6_regions)))\n",
    "ax3.set_yticks(range(len(top_5_services)))\n",
    "ax3.set_xticklabels(top_6_regions, rotation=45, ha='right', fontsize=8)\n",
    "ax3.set_yticklabels([s[:20] + '...' if len(s) > 20 else s for s in top_5_services], fontsize=8)\n",
    "ax3.set_title('üó∫Ô∏è Regional Service Gaps (%)\\n(Darker = More Opportunity)', fontweight='bold', fontsize=11)\n",
    "plt.colorbar(im3, ax=ax3, label='Gap %')\n",
    "\n",
    "# 4. Cross-Sell Revenue Potential\n",
    "ax4 = plt.subplot(2, 3, 4)\n",
    "# Estimate revenue potential from cross-selling\n",
    "revenue_potential = []\n",
    "for service in service_summary.head(10)['service'].values:\n",
    "    avg_cost_per_comp = df[df['service'] == service].groupby('compartmentName')['computedAmount'].sum().mean()\n",
    "    comps_with_service = len(df[df['service'] == service]['compartmentName'].unique())\n",
    "    comps_without = total_compartments - comps_with_service\n",
    "    potential_revenue = avg_cost_per_comp * comps_without\n",
    "    \n",
    "    revenue_potential.append({\n",
    "        'service': service,\n",
    "        'potential': potential_revenue,\n",
    "        'targets': comps_without\n",
    "    })\n",
    "\n",
    "rev_df = pd.DataFrame(revenue_potential).sort_values('potential', ascending=False)\n",
    "\n",
    "ax4.bar(range(len(rev_df)), rev_df['potential'].values, \n",
    "       color=plt.cm.plasma(np.linspace(0, 1, len(rev_df))), alpha=0.7, edgecolor='black')\n",
    "ax4.set_xticks(range(len(rev_df)))\n",
    "ax4.set_xticklabels([s[:15] + '...' if len(s) > 15 else s for s in rev_df['service'].values], \n",
    "                    rotation=45, ha='right', fontsize=8)\n",
    "ax4.set_ylabel('Potential Revenue ($)')\n",
    "ax4.set_title('üí∞ Cross-Sell Revenue Potential\\n(If adopted by all compartments)', fontweight='bold', fontsize=11)\n",
    "ax4.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add total potential\n",
    "total_potential = rev_df['potential'].sum()\n",
    "ax4.text(0.5, 0.95, f'Total Potential: ${total_potential:,.0f}', \n",
    "        transform=ax4.transAxes, ha='center', fontsize=10, fontweight='bold',\n",
    "        bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))\n",
    "\n",
    "# 5. Recommended Action Priority Matrix\n",
    "ax5 = plt.subplot(2, 3, 5)\n",
    "# Create action items based on segments\n",
    "action_priorities = []\n",
    "\n",
    "for _, row in seg_opp_df.iterrows():\n",
    "    segment = row['segment']\n",
    "    count = row['count']\n",
    "    opportunity = row['opportunity']\n",
    "    \n",
    "    # Calculate priority score (opportunity * count)\n",
    "    priority_score = opportunity * count\n",
    "    \n",
    "    action_priorities.append({\n",
    "        'segment': segment,\n",
    "        'priority_score': priority_score,\n",
    "        'compartments': count,\n",
    "        'avg_gap': opportunity\n",
    "    })\n",
    "\n",
    "action_df = pd.DataFrame(action_priorities).sort_values('priority_score', ascending=False)\n",
    "\n",
    "# Create bubble chart\n",
    "colors_action = plt.cm.Set2(np.linspace(0, 1, len(action_df)))\n",
    "for i, row in action_df.iterrows():\n",
    "    ax5.scatter(row['avg_gap'], row['compartments'], s=row['priority_score']*20, \n",
    "               alpha=0.6, color=colors_action[i], edgecolors='black', linewidth=1.5)\n",
    "    ax5.text(row['avg_gap'], row['compartments'], action_df.iloc[i].name + 1, \n",
    "            ha='center', va='center', fontweight='bold', fontsize=9)\n",
    "\n",
    "ax5.set_xlabel('Avg Service Gap (Opportunity)', fontweight='bold')\n",
    "ax5.set_ylabel('Number of Compartments', fontweight='bold')\n",
    "ax5.set_title('üéØ Action Priority Matrix\\n(Bubble size = Total Opportunity)', fontweight='bold', fontsize=11)\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Key Metrics Summary\n",
    "ax6 = plt.subplot(2, 3, 6)\n",
    "ax6.axis('off')\n",
    "\n",
    "# Calculate key metrics\n",
    "total_cross_sell_opps = cooccurrence_df['cross_sell_potential'].sum()\n",
    "avg_services_per_comp = compartment_profiles['num_services'].mean()\n",
    "high_priority_comps = len(high_value_low_div)\n",
    "total_rev_potential = rev_df['potential'].sum()\n",
    "\n",
    "metrics_text = f\"\"\"\n",
    "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "‚ïë   CROSS-SELLING KEY METRICS      ‚ïë\n",
    "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "\n",
    "üìä Overall Metrics:\n",
    "   ‚Ä¢ Total Compartments: {total_compartments:,}\n",
    "   ‚Ä¢ Avg Services/Comp: {avg_services_per_comp:.1f}\n",
    "   ‚Ä¢ Total Services: {df['service'].nunique()}\n",
    "\n",
    "üéØ Opportunity Metrics:\n",
    "   ‚Ä¢ Cross-sell Opportunities: {total_cross_sell_opps:,.0f}\n",
    "   ‚Ä¢ High-Priority Accounts: {high_priority_comps}\n",
    "   ‚Ä¢ Revenue Potential: ${total_rev_potential:,.0f}\n",
    "\n",
    "üìà Top Actions:\n",
    "   1. Target High Value/Low Div segment\n",
    "   2. Push top service bundles\n",
    "   3. Fill regional service gaps\n",
    "   4. Upsell to Starter segment\n",
    "\n",
    "üèÜ Focus Areas:\n",
    "   ‚Ä¢ {rev_df.iloc[0]['service'][:35]}\n",
    "     Potential: ${rev_df.iloc[0]['potential']:,.0f}\n",
    "   \n",
    "   ‚Ä¢ {rev_df.iloc[1]['service'][:35]}\n",
    "     Potential: ${rev_df.iloc[1]['potential']:,.0f}\n",
    "   \n",
    "   ‚Ä¢ {rev_df.iloc[2]['service'][:35]}\n",
    "     Potential: ${rev_df.iloc[2]['potential']:,.0f}\n",
    "\n",
    "üí° Next Steps:\n",
    "   ‚Üí Create targeted campaigns\n",
    "   ‚Üí Develop bundle offers\n",
    "   ‚Üí Train sales on co-sell patterns\n",
    "\"\"\"\n",
    "\n",
    "ax6.text(0.05, 0.95, metrics_text, transform=ax6.transAxes, \n",
    "        fontsize=9, verticalalignment='top', family='monospace',\n",
    "        bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.3))\n",
    "\n",
    "plt.tight_layout()\n",
    "print(\"‚úÖ Cross-Selling Action Plan Dashboard complete\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CROSS-SELLING ANALYSIS COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n‚úÖ Total potential cross-sell opportunities identified: {total_cross_sell_opps:,.0f}\")\n",
    "print(f\"üí∞ Estimated revenue potential: ${total_rev_potential:,.0f}\")\n",
    "print(f\"üéØ High-priority accounts for immediate action: {high_priority_comps}\")\n",
    "print(f\"\\nüìä All visualizations embedded in notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb090cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary report as dataframe export\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXECUTIVE SUMMARY - KEY METRICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "summary_metrics = {\n",
    "    'Metric': [\n",
    "        'Total Historical Cost',\n",
    "        'Total Transactions',\n",
    "        'Average Transaction Size',\n",
    "        'Daily Average Cost',\n",
    "        'Monthly Average Cost',\n",
    "        'Current Daily Cost',\n",
    "        'Current Month Cost (partial)',\n",
    "        '',\n",
    "        'Unique Services',\n",
    "        'Unique Regions',\n",
    "        'Unique Compartments',\n",
    "        'Unique Resources',\n",
    "        '',\n",
    "        'Overall Growth Rate (daily)',\n",
    "        'Overall Growth Rate (annualized)',\n",
    "        'Recent MoM Growth',\n",
    "        'Growth Momentum',\n",
    "        '',\n",
    "        'Top Service Market Share',\n",
    "        'Top 3 Services Market Share',\n",
    "        'Top 5 Services Market Share',\n",
    "        '',\n",
    "        'Services with Positive Growth',\n",
    "        'Services with Negative Growth',\n",
    "        'High-Growth Services (>20%)',\n",
    "        'Emerging Services (<60 days)',\n",
    "    ],\n",
    "    'Value': [\n",
    "        f\"${df['computedAmount'].sum():,.2f}\",\n",
    "        f\"{len(df):,}\",\n",
    "        f\"${df['computedAmount'].mean():,.2f}\",\n",
    "        f\"${daily_costs['computedAmount'].mean():,.2f}\",\n",
    "        f\"${monthly_costs['total_cost'].mean():,.2f}\",\n",
    "        f\"${daily_costs['computedAmount'].iloc[-1]:,.2f}\",\n",
    "        f\"${monthly_costs['total_cost'].iloc[-1]:,.2f}\",\n",
    "        '',\n",
    "        f\"{df['service'].nunique()}\",\n",
    "        f\"{df['region'].nunique()}\",\n",
    "        f\"{df['compartmentName'].nunique()}\",\n",
    "        f\"{df['resourceId'].nunique()}\",\n",
    "        '',\n",
    "        f\"{daily_growth_rate:.3f}%\",\n",
    "        f\"{daily_growth_rate * 365:.2f}%\",\n",
    "        f\"{recent_mom:.2f}%\",\n",
    "        f\"{'üöÄ Accelerating' if acceleration > 0 else '‚¨áÔ∏è Decelerating' if acceleration < 0 else '‚û°Ô∏è Stable'}\",\n",
    "        '',\n",
    "        f\"{service_summary.iloc[0]['market_share']:.1f}%\",\n",
    "        f\"{service_summary.head(3)['market_share'].sum():.1f}%\",\n",
    "        f\"{service_summary.head(5)['market_share'].sum():.1f}%\",\n",
    "        '',\n",
    "        f\"{len(growth_df[growth_df['growth_rate'] > 0])}\",\n",
    "        f\"{len(growth_df[growth_df['growth_rate'] < 0])}\",\n",
    "        f\"{len(high_growth)}\",\n",
    "        f\"{len(emerging) if 'emerging' in locals() else 0}\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_metrics)\n",
    "print(\"\\n\" + summary_df.to_string(index=False))\n",
    "\n",
    "# Export key datasets to CSV for further analysis\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXPORTING ANALYSIS RESULTS TO CSV\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Export monthly trends\n",
    "monthly_export = monthly_costs[['year_month', 'total_cost', 'num_services', 'num_regions', 'mom_growth']]\n",
    "monthly_export.to_csv('../output/growth_analysis_monthly_trends.csv', index=False)\n",
    "print(\"‚úÖ Monthly trends exported: growth_analysis_monthly_trends.csv\")\n",
    "\n",
    "# Export service analysis\n",
    "service_export = service_summary[['rank', 'service', 'total_cost', 'market_share', 'num_resources', 'avg_cost_per_row']]\n",
    "service_export.to_csv('../output/growth_analysis_service_breakdown.csv', index=False)\n",
    "print(\"‚úÖ Service breakdown exported: growth_analysis_service_breakdown.csv\")\n",
    "\n",
    "# Export growth analysis\n",
    "growth_export = growth_df[['service', 'total_cost', 'current_monthly', 'growth_rate', 'num_resources', 'market_share']]\n",
    "growth_export.to_csv('../output/growth_analysis_service_growth_rates.csv', index=False)\n",
    "print(\"‚úÖ Service growth rates exported: growth_analysis_service_growth_rates.csv\")\n",
    "\n",
    "# Export regional analysis\n",
    "regional_export = regional_analysis[['region', 'total_cost', 'market_share', 'num_services', 'num_resources']]\n",
    "regional_export.to_csv('../output/growth_analysis_regional_breakdown.csv', index=False)\n",
    "print(\"‚úÖ Regional analysis exported: growth_analysis_regional_breakdown.csv\")\n",
    "\n",
    "# Export compartment analysis\n",
    "compartment_export = compartment_analysis[['compartment', 'total_cost', 'market_share', 'num_services', 'num_resources']]\n",
    "compartment_export.to_csv('../output/growth_analysis_compartment_breakdown.csv', index=False)\n",
    "print(\"‚úÖ Compartment analysis exported: growth_analysis_compartment_breakdown.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n‚úÖ All visualizations and exports have been saved to ../output/\")\n",
    "print(f\"üìä Open the generated CSV files for detailed reporting and further analysis\")\n",
    "print(f\"üìà Share the PNG visualizations with stakeholders for decision-making\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fde926",
   "metadata": {},
   "source": [
    "## 14. Upselling Analysis - Premium Tier Upgrades\n",
    "\n",
    "Identify opportunities to upgrade customers to premium/higher-tier services within existing service categories. Focus on customers already using base-tier services who could benefit from enterprise features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534b4dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upselling Analysis: Identify service tier upgrade opportunities\n",
    "print(\"=== UPSELLING ANALYSIS: PREMIUM TIER UPGRADES ===\\n\")\n",
    "\n",
    "# Define upselling pathways (base service -> premium service mappings)\n",
    "upselling_pathways = {\n",
    "    # Compute upgrades\n",
    "    'Compute': {\n",
    "        'premium': 'Container Engine Service',\n",
    "        'description': 'Upgrade to Container Engine (OKE) for cloud-native workloads',\n",
    "        'value_proposition': 'Enable microservices architecture, improve deployment speed'\n",
    "    },\n",
    "    'Block Storage': {\n",
    "        'premium': 'File Storage',\n",
    "        'description': 'Add File Storage for shared file systems',\n",
    "        'value_proposition': 'Enable multi-instance access, NFS protocol support'\n",
    "    },\n",
    "    \n",
    "    # Database upgrades\n",
    "    'Database': {\n",
    "        'premium': 'Autonomous Data Warehouse',\n",
    "        'description': 'Upgrade to Autonomous Database for self-driving capabilities',\n",
    "        'value_proposition': 'Eliminate manual tuning, 99.995% availability SLA'\n",
    "    },\n",
    "    'MySQL': {\n",
    "        'premium': 'Database Management',\n",
    "        'description': 'Add Database Management for comprehensive database monitoring',\n",
    "        'value_proposition': 'Automated performance insights, diagnostics and fleet management'\n",
    "    },\n",
    "    \n",
    "    # Networking upgrades\n",
    "    'Virtual Cloud Network': {\n",
    "        'premium': 'Load Balancer',\n",
    "        'description': 'Add Load Balancer for high availability',\n",
    "        'value_proposition': 'Ensure application uptime, distribute traffic efficiently'\n",
    "    },\n",
    "    'Load Balancer': {\n",
    "        'premium': 'Web Application Firewall',\n",
    "        'description': 'Upgrade to Web Application Firewall for security',\n",
    "        'value_proposition': 'Protect against OWASP Top 10, DDoS protection'\n",
    "    },\n",
    "    \n",
    "    # Storage upgrades\n",
    "    'Object Storage': {\n",
    "        'premium': 'Archive Storage',\n",
    "        'description': 'Add Archive Storage for long-term data retention',\n",
    "        'value_proposition': 'Reduce storage costs by 90% for infrequently accessed data'\n",
    "    },\n",
    "    \n",
    "    # Observability upgrades\n",
    "    'Telemetry': {\n",
    "        'premium': 'Logging Analytics',\n",
    "        'description': 'Upgrade to Logging Analytics for advanced insights',\n",
    "        'value_proposition': 'ML-powered log analysis, faster troubleshooting'\n",
    "    },\n",
    "    'Logging': {\n",
    "        'premium': 'Application Performance Monitoring',\n",
    "        'description': 'Add APM for application-level monitoring',\n",
    "        'value_proposition': 'End-to-end transaction tracing, performance optimization'\n",
    "    },\n",
    "    \n",
    "    # Security upgrades\n",
    "    'Oracle Cloud Guard Service': {\n",
    "        'premium': 'Vulnerability Scanning Service',\n",
    "        'description': 'Add Vulnerability Scanning for comprehensive security assessment',\n",
    "        'value_proposition': 'Automated vulnerability detection, compliance monitoring'\n",
    "    },\n",
    "    \n",
    "    # Data & AI upgrades\n",
    "    'Data Flow': {\n",
    "        'premium': 'Data Integration',\n",
    "        'description': 'Upgrade to Data Integration for enterprise ETL/ELT',\n",
    "        'value_proposition': 'No-code data pipelines, advanced transformations'\n",
    "    },\n",
    "    'Data Integration': {\n",
    "        'premium': 'Data Science',\n",
    "        'description': 'Add Data Science platform for ML capabilities',\n",
    "        'value_proposition': 'Build and deploy ML models, predictive analytics'\n",
    "    },\n",
    "    'Analytics': {\n",
    "        'premium': 'Oracle AI Data Platform',\n",
    "        'description': 'Upgrade to AI Data Platform for unified data and AI',\n",
    "        'value_proposition': 'Integrated data lakehouse, AI-powered analytics'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Calculate upselling opportunities\n",
    "upselling_opportunities = []\n",
    "\n",
    "for base_service, upgrade_info in upselling_pathways.items():\n",
    "    premium_service = upgrade_info['premium']\n",
    "    \n",
    "    # Find compartments using base service but not premium service\n",
    "    comps_with_base = set(df[df['service'] == base_service]['compartmentName'].unique())\n",
    "    comps_with_premium = set(df[df['service'] == premium_service]['compartmentName'].unique())\n",
    "    \n",
    "    upsell_targets = comps_with_base - comps_with_premium\n",
    "    \n",
    "    if len(upsell_targets) > 0:\n",
    "        # Calculate potential revenue (assume 30% of base service cost)\n",
    "        base_spend = df[df['service'] == base_service]['computedAmount'].sum()\n",
    "        avg_spend_per_comp = base_spend / len(comps_with_base) if len(comps_with_base) > 0 else 0\n",
    "        potential_revenue = len(upsell_targets) * avg_spend_per_comp * 0.30\n",
    "        \n",
    "        upselling_opportunities.append({\n",
    "            'base_service': base_service,\n",
    "            'premium_service': premium_service,\n",
    "            'compartments_with_base': len(comps_with_base),\n",
    "            'compartments_with_premium': len(comps_with_premium),\n",
    "            'upsell_targets': len(upsell_targets),\n",
    "            'conversion_rate': len(comps_with_premium) / len(comps_with_base) if len(comps_with_base) > 0 else 0,\n",
    "            'base_service_revenue': base_spend,\n",
    "            'potential_upsell_revenue': potential_revenue,\n",
    "            'description': upgrade_info['description'],\n",
    "            'value_proposition': upgrade_info['value_proposition']\n",
    "        })\n",
    "\n",
    "upsell_df = pd.DataFrame(upselling_opportunities)\n",
    "upsell_df = upsell_df.sort_values('potential_upsell_revenue', ascending=False)\n",
    "\n",
    "print(f\"Total Upselling Opportunities Found: {len(upsell_df)}\")\n",
    "print(f\"Total Potential Upsell Revenue: ${upsell_df['potential_upsell_revenue'].sum():,.2f}\")\n",
    "print(f\"Total Compartments with Upsell Potential: {upsell_df['upsell_targets'].sum()}\")\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Display top opportunities\n",
    "print(\"TOP 10 UPSELLING OPPORTUNITIES:\\n\")\n",
    "for idx, row in upsell_df.head(10).iterrows():\n",
    "    print(f\"{row['base_service']} ‚Üí {row['premium_service']}\")\n",
    "    print(f\"  Current Users: {row['compartments_with_base']} | Already Upgraded: {row['compartments_with_premium']}\")\n",
    "    print(f\"  Upsell Targets: {row['upsell_targets']} compartments\")\n",
    "    print(f\"  Conversion Rate: {row['conversion_rate']:.1%}\")\n",
    "    print(f\"  Potential Revenue: ${row['potential_upsell_revenue']:,.2f}\")\n",
    "    print(f\"  üìä {row['description']}\")\n",
    "    print(f\"  üí° Value: {row['value_proposition']}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef0a7ba",
   "metadata": {},
   "source": [
    "## 15. Regional Focus Analysis - Top 3 Regions\n",
    "\n",
    "Most customers operate in 2-3 regions. Focus sales efforts on the most active regions where growth potential is highest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8747840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regional Focus: Analyze top 3 regions for concentrated sales efforts\n",
    "print(\"=== REGIONAL FOCUS: TOP 3 REGIONS FOR SALES EXPANSION ===\\n\")\n",
    "\n",
    "# Identify top 3 regions by cost\n",
    "top_3_regions = df.groupby('region').agg({\n",
    "    'computedAmount': 'sum',\n",
    "    'compartmentName': 'nunique',\n",
    "    'service': 'nunique'\n",
    "}).rename(columns={\n",
    "    'computedAmount': 'total_cost',\n",
    "    'compartmentName': 'compartments',\n",
    "    'service': 'services_used'\n",
    "}).sort_values('total_cost', ascending=False).head(3)\n",
    "\n",
    "print(\"TOP 3 REGIONS BY REVENUE:\\n\")\n",
    "for region, data in top_3_regions.iterrows():\n",
    "    pct_of_total = (data['total_cost'] / df['computedAmount'].sum()) * 100\n",
    "    print(f\"üìç {region}\")\n",
    "    print(f\"   Revenue: ${data['total_cost']:,.2f} ({pct_of_total:.1f}% of total)\")\n",
    "    print(f\"   Compartments: {data['compartments']}\")\n",
    "    print(f\"   Services Used: {data['services_used']}\")\n",
    "    print()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Detailed analysis for each top region\n",
    "top_3_region_names = top_3_regions.index.tolist()\n",
    "regional_insights = []\n",
    "\n",
    "for region in top_3_region_names:\n",
    "    region_df = df[df['region'] == region]\n",
    "    \n",
    "    # Service diversity\n",
    "    services_in_region = region_df['service'].nunique()\n",
    "    total_services = df['service'].nunique()\n",
    "    service_coverage = services_in_region / total_services\n",
    "    \n",
    "    # Top services\n",
    "    top_services_region = region_df.groupby('service')['computedAmount'].sum().sort_values(ascending=False).head(5)\n",
    "    \n",
    "    # Compartment analysis\n",
    "    comps_in_region = region_df['compartmentName'].nunique()\n",
    "    avg_cost_per_comp = region_df['computedAmount'].sum() / comps_in_region\n",
    "    \n",
    "    # Cross-sell opportunities (services used in other top regions but not here)\n",
    "    services_in_region_set = set(region_df['service'].unique())\n",
    "    other_regions = [r for r in top_3_region_names if r != region]\n",
    "    services_in_other_top_regions = set()\n",
    "    for other_region in other_regions:\n",
    "        services_in_other_top_regions.update(df[df['region'] == other_region]['service'].unique())\n",
    "    \n",
    "    cross_sell_opps = services_in_other_top_regions - services_in_region_set\n",
    "    cross_sell_count = len(cross_sell_opps)\n",
    "    \n",
    "    # Upselling opportunities in this region\n",
    "    region_upsell_opps = []\n",
    "    for base_service, upgrade_info in upselling_pathways.items():\n",
    "        premium_service = upgrade_info['premium']\n",
    "        comps_with_base = set(region_df[region_df['service'] == base_service]['compartmentName'].unique())\n",
    "        comps_with_premium = set(region_df[region_df['service'] == premium_service]['compartmentName'].unique())\n",
    "        upsell_targets = comps_with_base - comps_with_premium\n",
    "        \n",
    "        if len(upsell_targets) > 0:\n",
    "            region_upsell_opps.append({\n",
    "                'pathway': f\"{base_service} ‚Üí {premium_service}\",\n",
    "                'targets': len(upsell_targets)\n",
    "            })\n",
    "    \n",
    "    regional_insights.append({\n",
    "        'region': region,\n",
    "        'revenue': region_df['computedAmount'].sum(),\n",
    "        'compartments': comps_in_region,\n",
    "        'services_used': services_in_region,\n",
    "        'service_coverage': service_coverage,\n",
    "        'avg_cost_per_comp': avg_cost_per_comp,\n",
    "        'cross_sell_opportunities': cross_sell_count,\n",
    "        'upsell_opportunities': len(region_upsell_opps),\n",
    "        'top_services': top_services_region.to_dict(),\n",
    "        'top_upsell_pathways': sorted(region_upsell_opps, key=lambda x: x['targets'], reverse=True)[:3]\n",
    "    })\n",
    "\n",
    "# Display detailed insights\n",
    "for insight in regional_insights:\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"REGION: {insight['region']}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    print(f\"üí∞ REVENUE METRICS:\")\n",
    "    print(f\"   Total Revenue: ${insight['revenue']:,.2f}\")\n",
    "    print(f\"   Average per Compartment: ${insight['avg_cost_per_comp']:,.2f}\")\n",
    "    print(f\"   Compartments: {insight['compartments']}\")\n",
    "    print()\n",
    "    \n",
    "    print(f\"üìä SERVICE ADOPTION:\")\n",
    "    print(f\"   Services in Use: {insight['services_used']}/{total_services} ({insight['service_coverage']:.1%} coverage)\")\n",
    "    print(f\"   Cross-Sell Opportunities: {insight['cross_sell_opportunities']} services not yet adopted\")\n",
    "    print(f\"   Upsell Opportunities: {insight['upsell_opportunities']} upgrade pathways available\")\n",
    "    print()\n",
    "    \n",
    "    print(f\"üîù TOP 5 SERVICES BY REVENUE:\")\n",
    "    for idx, (service, cost) in enumerate(insight['top_services'].items(), 1):\n",
    "        print(f\"   {idx}. {service}: ${cost:,.2f}\")\n",
    "    print()\n",
    "    \n",
    "    if insight['top_upsell_pathways']:\n",
    "        print(f\"üéØ TOP UPSELLING OPPORTUNITIES:\")\n",
    "        for idx, pathway in enumerate(insight['top_upsell_pathways'], 1):\n",
    "            print(f\"   {idx}. {pathway['pathway']}\")\n",
    "            print(f\"      ‚Üí {pathway['targets']} compartments ready to upgrade\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"\\n‚úÖ FOCUS STRATEGY: Concentrate sales efforts on these 3 regions which represent\")\n",
    "print(f\"   {(top_3_regions['total_cost'].sum() / df['computedAmount'].sum() * 100):.1f}% of total revenue.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2109d178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizations: Upselling and Regional Focus Dashboard\n",
    "print(\"Creating comprehensive upselling and regional focus visualizations...\\n\")\n",
    "\n",
    "fig = plt.figure(figsize=(20, 16))\n",
    "gs = fig.add_gridspec(4, 3, hspace=0.35, wspace=0.3)\n",
    "\n",
    "# 1. Top Upselling Opportunities\n",
    "ax1 = fig.add_subplot(gs[0, :])\n",
    "top_10_upsell = upsell_df.head(10)\n",
    "pathways = [f\"{row['base_service']}\\n‚Üí {row['premium_service']}\" for _, row in top_10_upsell.iterrows()]\n",
    "revenues = top_10_upsell['potential_upsell_revenue'].values\n",
    "targets = top_10_upsell['upsell_targets'].values\n",
    "\n",
    "x = np.arange(len(pathways))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax1.bar(x - width/2, revenues, width, label='Potential Revenue ($)', color='#2E7D32', alpha=0.8)\n",
    "ax1_twin = ax1.twinx()\n",
    "bars2 = ax1_twin.bar(x + width/2, targets, width, label='Target Compartments', color='#1976D2', alpha=0.8)\n",
    "\n",
    "ax1.set_xlabel('Upselling Pathway', fontsize=11, fontweight='bold')\n",
    "ax1.set_ylabel('Potential Revenue ($)', fontsize=10, fontweight='bold', color='#2E7D32')\n",
    "ax1_twin.set_ylabel('Target Compartments', fontsize=10, fontweight='bold', color='#1976D2')\n",
    "ax1.set_title('Top 10 Upselling Opportunities - Premium Tier Upgrades', fontsize=13, fontweight='bold', pad=15)\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(pathways, rotation=45, ha='right', fontsize=9)\n",
    "ax1.tick_params(axis='y', labelcolor='#2E7D32')\n",
    "ax1_twin.tick_params(axis='y', labelcolor='#1976D2')\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, val in zip(bars1, revenues):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'${val:,.0f}', ha='center', va='bottom', fontsize=8, fontweight='bold', color='#2E7D32')\n",
    "\n",
    "# 2. Upselling Conversion Funnel\n",
    "ax2 = fig.add_subplot(gs[1, 0])\n",
    "top_5_funnel = upsell_df.head(5)\n",
    "funnel_data = []\n",
    "for _, row in top_5_funnel.iterrows():\n",
    "    funnel_data.append({\n",
    "        'stage': f\"{row['base_service'][:15]}...\",\n",
    "        'base_users': row['compartments_with_base'],\n",
    "        'converted': row['compartments_with_premium'],\n",
    "        'targets': row['upsell_targets']\n",
    "    })\n",
    "\n",
    "stages = [d['stage'] for d in funnel_data]\n",
    "base = [d['base_users'] for d in funnel_data]\n",
    "converted = [d['converted'] for d in funnel_data]\n",
    "targets_data = [d['targets'] for d in funnel_data]\n",
    "\n",
    "y_pos = np.arange(len(stages))\n",
    "ax2.barh(y_pos, base, color='#E0E0E0', label='Base Users', alpha=0.7)\n",
    "ax2.barh(y_pos, converted, color='#4CAF50', label='Already Upgraded', alpha=0.9)\n",
    "\n",
    "ax2.set_yticks(y_pos)\n",
    "ax2.set_yticklabels(stages, fontsize=9)\n",
    "ax2.set_xlabel('Number of Compartments', fontsize=10, fontweight='bold')\n",
    "ax2.set_title('Upselling Conversion Funnel\\nTop 5 Pathways', fontsize=11, fontweight='bold')\n",
    "ax2.legend(loc='lower right', fontsize=8)\n",
    "ax2.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Add target labels\n",
    "for i, (target, total) in enumerate(zip(targets_data, base)):\n",
    "    conversion = (total - target) / total * 100 if total > 0 else 0\n",
    "    ax2.text(total + 1, i, f'{target} targets\\n({conversion:.0f}% conv.)', \n",
    "             va='center', fontsize=8, fontweight='bold', color='#D32F2F')\n",
    "\n",
    "# 3. Regional Revenue Distribution (Top 3)\n",
    "ax3 = fig.add_subplot(gs[1, 1])\n",
    "region_revenues = top_3_regions['total_cost'].values\n",
    "region_names = [name[:20] for name in top_3_regions.index]\n",
    "colors_region = ['#1976D2', '#388E3C', '#F57C00']\n",
    "\n",
    "wedges, texts, autotexts = ax3.pie(region_revenues, labels=region_names, autopct='%1.1f%%',\n",
    "                                     colors=colors_region, startangle=90, textprops={'fontsize': 9})\n",
    "for autotext in autotexts:\n",
    "    autotext.set_color('white')\n",
    "    autotext.set_fontweight('bold')\n",
    "    autotext.set_fontsize(10)\n",
    "\n",
    "ax3.set_title(f'Top 3 Regions Revenue Distribution\\nTotal: ${top_3_regions[\"total_cost\"].sum():,.0f}',\n",
    "              fontsize=11, fontweight='bold')\n",
    "\n",
    "# 4. Service Coverage by Top 3 Regions\n",
    "ax4 = fig.add_subplot(gs[1, 2])\n",
    "region_names_short = [insight['region'][:15] + '...' if len(insight['region']) > 15 else insight['region'] \n",
    "                       for insight in regional_insights]\n",
    "services_used = [insight['services_used'] for insight in regional_insights]\n",
    "services_available = [total_services] * len(regional_insights)\n",
    "\n",
    "x_pos = np.arange(len(region_names_short))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax4.bar(x_pos - width/2, services_available, width, label='Total Available', \n",
    "                color='#E0E0E0', alpha=0.7)\n",
    "bars2 = ax4.bar(x_pos + width/2, services_used, width, label='Currently Used', \n",
    "                color='#1976D2', alpha=0.9)\n",
    "\n",
    "ax4.set_ylabel('Number of Services', fontsize=10, fontweight='bold')\n",
    "ax4.set_title('Service Adoption Coverage\\nTop 3 Regions', fontsize=11, fontweight='bold')\n",
    "ax4.set_xticks(x_pos)\n",
    "ax4.set_xticklabels(region_names_short, rotation=30, ha='right', fontsize=9)\n",
    "ax4.legend(fontsize=8)\n",
    "ax4.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add coverage percentage\n",
    "for i, (used, available) in enumerate(zip(services_used, services_available)):\n",
    "    coverage = (used / available) * 100\n",
    "    ax4.text(i, used + 2, f'{coverage:.0f}%', ha='center', fontsize=9, fontweight='bold', color='#1976D2')\n",
    "\n",
    "# 5. Cross-Sell vs Upsell Opportunities by Region\n",
    "ax5 = fig.add_subplot(gs[2, 0])\n",
    "regions_short = [insight['region'][:15] for insight in regional_insights]\n",
    "cross_sell = [insight['cross_sell_opportunities'] for insight in regional_insights]\n",
    "upsell = [insight['upsell_opportunities'] for insight in regional_insights]\n",
    "\n",
    "x = np.arange(len(regions_short))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax5.bar(x - width/2, cross_sell, width, label='Cross-Sell Opps', color='#FF9800', alpha=0.8)\n",
    "bars2 = ax5.bar(x + width/2, upsell, width, label='Upsell Opps', color='#9C27B0', alpha=0.8)\n",
    "\n",
    "ax5.set_ylabel('Number of Opportunities', fontsize=10, fontweight='bold')\n",
    "ax5.set_title('Growth Opportunities by Region\\n(Cross-Sell vs Upsell)', fontsize=11, fontweight='bold')\n",
    "ax5.set_xticks(x)\n",
    "ax5.set_xticklabels(regions_short, rotation=30, ha='right', fontsize=9)\n",
    "ax5.legend(fontsize=8)\n",
    "ax5.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax5.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                 f'{int(height)}', ha='center', va='bottom', fontsize=8, fontweight='bold')\n",
    "\n",
    "# 6. Revenue per Compartment (Top 3 Regions)\n",
    "ax6 = fig.add_subplot(gs[2, 1])\n",
    "avg_costs = [insight['avg_cost_per_comp'] for insight in regional_insights]\n",
    "compartments = [insight['compartments'] for insight in regional_insights]\n",
    "\n",
    "colors_bars = ['#1976D2', '#388E3C', '#F57C00']\n",
    "bars = ax6.bar(regions_short, avg_costs, color=colors_bars, alpha=0.8)\n",
    "\n",
    "ax6.set_ylabel('Average Cost per Compartment ($)', fontsize=10, fontweight='bold')\n",
    "ax6.set_title('Revenue Efficiency by Region\\nAvg. Cost per Compartment', fontsize=11, fontweight='bold')\n",
    "ax6.set_xticklabels(regions_short, rotation=30, ha='right', fontsize=9)\n",
    "ax6.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels with compartment count\n",
    "for bar, cost, comp_count in zip(bars, avg_costs, compartments):\n",
    "    height = bar.get_height()\n",
    "    ax6.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'${cost:,.2f}\\n({comp_count} comps)', ha='center', va='bottom', fontsize=8, fontweight='bold')\n",
    "\n",
    "# 7. Upselling Revenue Potential by Category\n",
    "ax7 = fig.add_subplot(gs[2, 2])\n",
    "# Categorize upselling pathways\n",
    "categories = {\n",
    "    'Compute': ['COMPUTE', 'COMPUTE_MANAGEMENT', 'CONTAINER_ENGINE'],\n",
    "    'Database': ['DATABASE', 'DATABASE_TOOLS', 'AUTONOMOUS_DATABASE', 'DATA_SAFE'],\n",
    "    'Networking': ['VIRTUAL_CLOUD_NETWORK', 'LOAD_BALANCER', 'VPN_CONNECT', 'FASTCONNECT', 'WAF'],\n",
    "    'Storage': ['BLOCK_STORAGE', 'FILE_STORAGE', 'OBJECT_STORAGE', 'ARCHIVE_STORAGE'],\n",
    "    'Observability': ['MONITORING', 'LOGGING', 'LOGGING_ANALYTICS', 'APPLICATION_PERFORMANCE_MONITORING'],\n",
    "    'Security': ['IDENTITY', 'CLOUD_GUARD'],\n",
    "    'Data & AI': ['DATA_CATALOG', 'DATA_INTEGRATION', 'DATA_SCIENCE']\n",
    "}\n",
    "\n",
    "category_revenue = {}\n",
    "for category, services in categories.items():\n",
    "    revenue = upsell_df[upsell_df['base_service'].isin(services)]['potential_upsell_revenue'].sum()\n",
    "    if revenue > 0:\n",
    "        category_revenue[category] = revenue\n",
    "\n",
    "sorted_categories = sorted(category_revenue.items(), key=lambda x: x[1], reverse=True)\n",
    "cat_names = [c[0] for c in sorted_categories]\n",
    "cat_revenues = [c[1] for c in sorted_categories]\n",
    "\n",
    "colors_cat = plt.cm.Set3(np.linspace(0, 1, len(cat_names)))\n",
    "bars = ax7.barh(cat_names, cat_revenues, color=colors_cat, alpha=0.8)\n",
    "\n",
    "ax7.set_xlabel('Potential Revenue ($)', fontsize=10, fontweight='bold')\n",
    "ax7.set_title('Upselling Revenue Potential\\nby Service Category', fontsize=11, fontweight='bold')\n",
    "ax7.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Add value labels\n",
    "for bar, revenue in zip(bars, cat_revenues):\n",
    "    width = bar.get_width()\n",
    "    ax7.text(width, bar.get_y() + bar.get_height()/2.,\n",
    "             f' ${revenue:,.0f}', ha='left', va='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "# 8. Regional Service Heatmap (Top 3 Regions, Top Services)\n",
    "ax8 = fig.add_subplot(gs[3, :2])\n",
    "\n",
    "# Create service-region matrix for top services\n",
    "top_services_global = df.groupby('service')['computedAmount'].sum().sort_values(ascending=False).head(12).index\n",
    "region_service_spend = pd.DataFrame(index=top_3_region_names, columns=top_services_global)\n",
    "\n",
    "for region in top_3_region_names:\n",
    "    for service in top_services_global:\n",
    "        spend = df[(df['region'] == region) & (df['service'] == service)]['computedAmount'].sum()\n",
    "        region_service_spend.loc[region, service] = spend\n",
    "\n",
    "region_service_spend = region_service_spend.fillna(0).astype(float)\n",
    "\n",
    "im = ax8.imshow(region_service_spend.values, cmap='YlOrRd', aspect='auto')\n",
    "ax8.set_xticks(np.arange(len(top_services_global)))\n",
    "ax8.set_yticks(np.arange(len(top_3_region_names)))\n",
    "ax8.set_xticklabels(top_services_global, rotation=45, ha='right', fontsize=9)\n",
    "ax8.set_yticklabels([name[:25] for name in top_3_region_names], fontsize=9)\n",
    "ax8.set_title('Service Spending Heatmap: Top 3 Regions √ó Top 12 Services', fontsize=12, fontweight='bold', pad=15)\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(im, ax=ax8)\n",
    "cbar.set_label('Spending ($)', rotation=270, labelpad=20, fontsize=10, fontweight='bold')\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(len(top_3_region_names)):\n",
    "    for j in range(len(top_services_global)):\n",
    "        value = region_service_spend.values[i, j]\n",
    "        if value > 0:\n",
    "            text = ax8.text(j, i, f'${value:.0f}',\n",
    "                           ha=\"center\", va=\"center\", color=\"black\" if value < region_service_spend.values.max()/2 else \"white\",\n",
    "                           fontsize=7, fontweight='bold')\n",
    "\n",
    "# 9. Sales Priority Matrix\n",
    "ax9 = fig.add_subplot(gs[3, 2])\n",
    "\n",
    "# Create priority matrix data\n",
    "priority_data = []\n",
    "for insight in regional_insights:\n",
    "    total_opps = insight['cross_sell_opportunities'] + insight['upsell_opportunities']\n",
    "    revenue_potential = insight['avg_cost_per_comp'] * total_opps * 0.25  # Estimated 25% conversion\n",
    "    priority_data.append({\n",
    "        'region': insight['region'][:15],\n",
    "        'opportunities': total_opps,\n",
    "        'revenue_potential': revenue_potential,\n",
    "        'compartments': insight['compartments']\n",
    "    })\n",
    "\n",
    "regions_plot = [d['region'] for d in priority_data]\n",
    "opps = [d['opportunities'] for d in priority_data]\n",
    "revenues_plot = [d['revenue_potential'] for d in priority_data]\n",
    "sizes = [d['compartments'] * 3 for d in priority_data]\n",
    "\n",
    "scatter = ax9.scatter(opps, revenues_plot, s=sizes, c=colors_region, alpha=0.6, edgecolors='black', linewidth=2)\n",
    "\n",
    "for i, region in enumerate(regions_plot):\n",
    "    ax9.annotate(region, (opps[i], revenues_plot[i]), fontsize=9, fontweight='bold', \n",
    "                 xytext=(5, 5), textcoords='offset points')\n",
    "\n",
    "ax9.set_xlabel('Total Opportunities (Cross-Sell + Upsell)', fontsize=10, fontweight='bold')\n",
    "ax9.set_ylabel('Estimated Revenue Potential ($)', fontsize=10, fontweight='bold')\n",
    "ax9.set_title('Sales Priority Matrix\\nTop 3 Regions\\n(Bubble size = # Compartments)', \n",
    "              fontsize=11, fontweight='bold')\n",
    "ax9.grid(True, alpha=0.3)\n",
    "\n",
    "# Add quadrant lines\n",
    "ax9.axhline(y=np.median(revenues_plot), color='gray', linestyle='--', alpha=0.5, linewidth=1)\n",
    "ax9.axvline(x=np.median(opps), color='gray', linestyle='--', alpha=0.5, linewidth=1)\n",
    "\n",
    "# Add quadrant labels\n",
    "ax9.text(0.95, 0.95, 'HIGH PRIORITY', transform=ax9.transAxes, fontsize=9, \n",
    "         fontweight='bold', color='#D32F2F', ha='right', va='top',\n",
    "         bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.3))\n",
    "\n",
    "plt.suptitle('üéØ UPSELLING & REGIONAL FOCUS DASHBOARD', fontsize=16, fontweight='bold', y=0.995)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Upselling and Regional Focus Dashboard created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc241c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Upselling and Regional Analysis Data\n",
    "print(\"Exporting upselling and regional focus analysis data...\\n\")\n",
    "\n",
    "# Export upselling opportunities\n",
    "upsell_export = upsell_df.copy()\n",
    "upsell_export.to_csv('../output/upselling_opportunities.csv', index=False)\n",
    "print(f\"‚úÖ Exported: upselling_opportunities.csv ({len(upsell_export)} opportunities)\")\n",
    "\n",
    "# Export regional insights\n",
    "regional_export = pd.DataFrame([{\n",
    "    'region': insight['region'],\n",
    "    'revenue': insight['revenue'],\n",
    "    'compartments': insight['compartments'],\n",
    "    'services_used': insight['services_used'],\n",
    "    'service_coverage_pct': insight['service_coverage'] * 100,\n",
    "    'avg_cost_per_compartment': insight['avg_cost_per_comp'],\n",
    "    'cross_sell_opportunities': insight['cross_sell_opportunities'],\n",
    "    'upsell_opportunities': insight['upsell_opportunities'],\n",
    "    'top_service_1': list(insight['top_services'].keys())[0] if insight['top_services'] else '',\n",
    "    'top_service_1_revenue': list(insight['top_services'].values())[0] if insight['top_services'] else 0,\n",
    "    'top_service_2': list(insight['top_services'].keys())[1] if len(insight['top_services']) > 1 else '',\n",
    "    'top_service_2_revenue': list(insight['top_services'].values())[1] if len(insight['top_services']) > 1 else 0,\n",
    "    'top_service_3': list(insight['top_services'].keys())[2] if len(insight['top_services']) > 2 else '',\n",
    "    'top_service_3_revenue': list(insight['top_services'].values())[2] if len(insight['top_services']) > 2 else 0\n",
    "} for insight in regional_insights])\n",
    "\n",
    "regional_export.to_csv('../output/regional_focus_top3.csv', index=False)\n",
    "print(f\"‚úÖ Exported: regional_focus_top3.csv ({len(regional_export)} regions)\")\n",
    "\n",
    "# Create executive summary\n",
    "exec_summary = {\n",
    "    'total_upsell_opportunities': len(upsell_df),\n",
    "    'total_upsell_revenue_potential': upsell_df['potential_upsell_revenue'].sum(),\n",
    "    'total_compartments_with_upsell_potential': upsell_df['upsell_targets'].sum(),\n",
    "    'top_3_regions': top_3_region_names,\n",
    "    'top_3_regions_revenue': top_3_regions['total_cost'].sum(),\n",
    "    'top_3_regions_pct_of_total': (top_3_regions['total_cost'].sum() / df['computedAmount'].sum()) * 100,\n",
    "    'total_cross_sell_opps_in_top_3': sum([i['cross_sell_opportunities'] for i in regional_insights]),\n",
    "    'total_upsell_opps_in_top_3': sum([i['upsell_opportunities'] for i in regional_insights]),\n",
    "    'avg_service_coverage_top_3': np.mean([i['service_coverage'] for i in regional_insights]) * 100\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXECUTIVE SUMMARY - UPSELLING & REGIONAL FOCUS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüí∞ UPSELLING POTENTIAL:\")\n",
    "print(f\"   Total Opportunities: {exec_summary['total_upsell_opportunities']} upgrade pathways\")\n",
    "print(f\"   Revenue Potential: ${exec_summary['total_upsell_revenue_potential']:,.2f}\")\n",
    "print(f\"   Target Compartments: {exec_summary['total_compartments_with_upsell_potential']}\")\n",
    "\n",
    "print(f\"\\nüìç TOP 3 REGIONS:\")\n",
    "print(f\"   Regions: {', '.join(exec_summary['top_3_regions'])}\")\n",
    "print(f\"   Combined Revenue: ${exec_summary['top_3_regions_revenue']:,.2f}\")\n",
    "print(f\"   % of Total: {exec_summary['top_3_regions_pct_of_total']:.1f}%\")\n",
    "print(f\"   Avg Service Coverage: {exec_summary['avg_service_coverage_top_3']:.1f}%\")\n",
    "\n",
    "print(f\"\\nüéØ GROWTH OPPORTUNITIES IN TOP 3 REGIONS:\")\n",
    "print(f\"   Cross-Sell Opportunities: {exec_summary['total_cross_sell_opps_in_top_3']} services\")\n",
    "print(f\"   Upsell Opportunities: {exec_summary['total_upsell_opps_in_top_3']} pathways\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\n‚úÖ All upselling and regional focus analysis completed!\")\n",
    "print(\"üìä Review the dashboard above for visual insights.\")\n",
    "print(\"üìÅ Check output folder for exported CSV files.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e3eb35",
   "metadata": {},
   "source": [
    "## 16. Cost Tracking & Tagging Analysis for Upsell/Cross-Sell\n",
    "\n",
    "Analyze resource tagging patterns to identify opportunities for improved cost governance and targeted sales campaigns. Untagged or poorly tagged resources represent opportunities to sell tagging/governance solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4313ac97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tagging Analysis: Identify cost governance and compliance opportunities\n",
    "print(\"=== COST TRACKING & TAGGING ANALYSIS ===\\n\")\n",
    "\n",
    "# Analyze tagging compliance\n",
    "df['has_cost_center'] = df['cost_center'] != 'Untagged'\n",
    "df['has_environment'] = df['environment'] != 'Untagged'\n",
    "df['has_team'] = df['team'] != 'Untagged'\n",
    "df['has_any_tag'] = df['has_cost_center'] | df['has_environment'] | df['has_team']\n",
    "\n",
    "# Overall tagging statistics\n",
    "total_cost = df['computedAmount'].sum()\n",
    "tagged_cost = df[df['has_any_tag']]['computedAmount'].sum()\n",
    "untagged_cost = df[~df['has_any_tag']]['computedAmount'].sum()\n",
    "tagging_coverage_pct = (tagged_cost / total_cost) * 100\n",
    "\n",
    "print(f\"üìä OVERALL TAGGING COMPLIANCE:\")\n",
    "print(f\"   Total Cost: ${total_cost:,.2f}\")\n",
    "print(f\"   Tagged Resources: ${tagged_cost:,.2f} ({tagging_coverage_pct:.1f}%)\")\n",
    "print(f\"   Untagged Resources: ${untagged_cost:,.2f} ({100-tagging_coverage_pct:.1f}%)\")\n",
    "print()\n",
    "\n",
    "# Tagging by standard keys\n",
    "cost_center_tagged = df[df['has_cost_center']]['computedAmount'].sum()\n",
    "environment_tagged = df[df['has_environment']]['computedAmount'].sum()\n",
    "team_tagged = df[df['has_team']]['computedAmount'].sum()\n",
    "\n",
    "print(f\"üìã TAG KEY COVERAGE:\")\n",
    "print(f\"   CostCenter Tag: ${cost_center_tagged:,.2f} ({cost_center_tagged/total_cost*100:.1f}%)\")\n",
    "print(f\"   Environment Tag: ${environment_tagged:,.2f} ({environment_tagged/total_cost*100:.1f}%)\")\n",
    "print(f\"   Team Tag: ${team_tagged:,.2f} ({team_tagged/total_cost*100:.1f}%)\")\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Tagging compliance by compartment (identify governance opportunities)\n",
    "compartment_tagging = df.groupby('compartmentName').agg({\n",
    "    'computedAmount': 'sum',\n",
    "    'has_any_tag': 'mean',\n",
    "    'has_cost_center': 'mean',\n",
    "    'has_environment': 'mean',\n",
    "    'has_team': 'mean',\n",
    "    'service': 'nunique'\n",
    "}).rename(columns={\n",
    "    'computedAmount': 'total_cost',\n",
    "    'has_any_tag': 'overall_compliance',\n",
    "    'has_cost_center': 'cost_center_compliance',\n",
    "    'has_environment': 'environment_compliance',\n",
    "    'has_team': 'team_compliance',\n",
    "    'service': 'num_services'\n",
    "}).reset_index()\n",
    "\n",
    "compartment_tagging = compartment_tagging.sort_values('total_cost', ascending=False)\n",
    "\n",
    "# Identify governance upsell targets (high spend, low compliance)\n",
    "governance_targets = compartment_tagging[\n",
    "    (compartment_tagging['total_cost'] > compartment_tagging['total_cost'].quantile(0.50)) &\n",
    "    (compartment_tagging['overall_compliance'] < 0.30)\n",
    "].copy()\n",
    "\n",
    "print(f\"üéØ GOVERNANCE UPSELL OPPORTUNITIES:\")\n",
    "print(f\"   High-spend, Low-compliance Compartments: {len(governance_targets)}\")\n",
    "print(f\"   Combined Cost: ${governance_targets['total_cost'].sum():,.2f}\")\n",
    "print(f\"   Average Compliance: {governance_targets['overall_compliance'].mean()*100:.1f}%\")\n",
    "print()\n",
    "\n",
    "if len(governance_targets) > 0:\n",
    "    print(f\"TOP 10 GOVERNANCE TARGETS:\\n\")\n",
    "    for idx, row in governance_targets.head(10).iterrows():\n",
    "        print(f\"üìÅ {row['compartmentName'][:50]}\")\n",
    "        print(f\"   Cost: ${row['total_cost']:,.2f} | Services: {row['num_services']}\")\n",
    "        print(f\"   Compliance: {row['overall_compliance']*100:.0f}% | CostCenter: {row['cost_center_compliance']*100:.0f}% | Environment: {row['environment_compliance']*100:.0f}%\")\n",
    "        print(f\"   üí° Opportunity: Implement tagging policies, cost allocation, showback/chargeback\")\n",
    "        print()\n",
    "\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Tagging patterns by region (identify regional compliance gaps)\n",
    "regional_tagging = df.groupby('region').agg({\n",
    "    'computedAmount': 'sum',\n",
    "    'has_any_tag': 'mean',\n",
    "    'compartmentName': 'nunique'\n",
    "}).rename(columns={\n",
    "    'computedAmount': 'total_cost',\n",
    "    'has_any_tag': 'compliance_rate',\n",
    "    'compartmentName': 'num_compartments'\n",
    "}).sort_values('total_cost', ascending=False).head(10)\n",
    "\n",
    "print(f\"üåç REGIONAL TAGGING COMPLIANCE (Top 10 Regions):\\n\")\n",
    "for region, data in regional_tagging.iterrows():\n",
    "    compliance_status = \"‚úÖ Good\" if data['compliance_rate'] > 0.70 else \"‚ö†Ô∏è Poor\" if data['compliance_rate'] < 0.30 else \"üìä Medium\"\n",
    "    print(f\"{region[:35]:35} | Cost: ${data['total_cost']:>10,.2f} | Compliance: {data['compliance_rate']*100:>5.1f}% {compliance_status}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Service-level tagging analysis (which services are poorly tagged?)\n",
    "service_tagging = df.groupby('service').agg({\n",
    "    'computedAmount': 'sum',\n",
    "    'has_any_tag': 'mean',\n",
    "    'compartmentName': 'nunique'\n",
    "}).rename(columns={\n",
    "    'computedAmount': 'total_cost',\n",
    "    'has_any_tag': 'compliance_rate',\n",
    "    'compartmentName': 'num_compartments'\n",
    "}).sort_values('total_cost', ascending=False)\n",
    "\n",
    "poorly_tagged_services = service_tagging[service_tagging['compliance_rate'] < 0.30].copy()\n",
    "poorly_tagged_services = poorly_tagged_services[poorly_tagged_services['total_cost'] > 10]  # Only significant services\n",
    "\n",
    "print(f\"‚ö†Ô∏è POORLY TAGGED SERVICES (High Cost, Low Compliance):\\n\")\n",
    "if len(poorly_tagged_services) > 0:\n",
    "    for service, data in poorly_tagged_services.head(10).iterrows():\n",
    "        print(f\"{service[:40]:40} | ${data['total_cost']:>10,.2f} | {data['compliance_rate']*100:>5.1f}% tagged\")\n",
    "else:\n",
    "    print(\"   ‚úÖ No major services with poor tagging compliance\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Tag value analysis - identify most common tag values\n",
    "print(f\"üìë TAG VALUE DISTRIBUTION:\\n\")\n",
    "\n",
    "# Cost Center distribution\n",
    "cost_centers = df[df['has_cost_center']].groupby('cost_center')['computedAmount'].sum().sort_values(ascending=False)\n",
    "print(f\"Top 10 Cost Centers:\")\n",
    "for cc, cost in cost_centers.head(10).items():\n",
    "    print(f\"   {cc[:30]:30} | ${cost:>10,.2f}\")\n",
    "print()\n",
    "\n",
    "# Environment distribution\n",
    "environments = df[df['has_environment']].groupby('environment')['computedAmount'].sum().sort_values(ascending=False)\n",
    "print(f\"Environment Breakdown:\")\n",
    "for env, cost in environments.head(10).items():\n",
    "    print(f\"   {env[:30]:30} | ${cost:>10,.2f}\")\n",
    "print()\n",
    "\n",
    "# Team distribution\n",
    "teams = df[df['has_team']].groupby('team')['computedAmount'].sum().sort_values(ascending=False)\n",
    "print(f\"Top 10 Teams:\")\n",
    "for team, cost in teams.head(10).items():\n",
    "    print(f\"   {team[:30]:30} | ${cost:>10,.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Calculate tagging solution revenue opportunity\n",
    "governance_opportunity = {\n",
    "    'untagged_cost': untagged_cost,\n",
    "    'poorly_tagged_compartments': len(governance_targets),\n",
    "    'poorly_tagged_compartment_cost': governance_targets['total_cost'].sum() if len(governance_targets) > 0 else 0,\n",
    "    'estimated_governance_solution_revenue': untagged_cost * 0.02,  # 2% of untagged cost as solution revenue\n",
    "    'showback_chargeback_opportunity': governance_targets['total_cost'].sum() * 0.015 if len(governance_targets) > 0 else 0  # 1.5% for implementation\n",
    "}\n",
    "\n",
    "print(f\"\\nüí∞ GOVERNANCE SOLUTION OPPORTUNITY:\")\n",
    "print(f\"   Untagged Resources: ${governance_opportunity['untagged_cost']:,.2f}\")\n",
    "print(f\"   Governance Solution Revenue Potential: ${governance_opportunity['estimated_governance_solution_revenue']:,.2f}\")\n",
    "print(f\"   Showback/Chargeback Implementation Revenue: ${governance_opportunity['showback_chargeback_opportunity']:,.2f}\")\n",
    "print(f\"   Total Governance Revenue Opportunity: ${governance_opportunity['estimated_governance_solution_revenue'] + governance_opportunity['showback_chargeback_opportunity']:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fa9e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tagging Analysis Visualizations\n",
    "print(\"Creating comprehensive tagging analysis dashboard...\\n\")\n",
    "\n",
    "fig = plt.figure(figsize=(20, 14))\n",
    "gs = fig.add_gridspec(3, 3, hspace=0.35, wspace=0.3)\n",
    "\n",
    "# 1. Overall Tagging Compliance (Pie Chart)\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "tagging_data = [tagged_cost, untagged_cost]\n",
    "tagging_labels = ['Tagged\\nResources', 'Untagged\\nResources']\n",
    "colors_tag = ['#4CAF50', '#F44336']\n",
    "explode = (0.05, 0.1)\n",
    "\n",
    "wedges, texts, autotexts = ax1.pie(tagging_data, labels=tagging_labels, autopct='%1.1f%%',\n",
    "                                     colors=colors_tag, explode=explode, startangle=90,\n",
    "                                     textprops={'fontsize': 10, 'fontweight': 'bold'})\n",
    "for autotext in autotexts:\n",
    "    autotext.set_color('white')\n",
    "    autotext.set_fontsize(11)\n",
    "\n",
    "ax1.set_title(f'Overall Tagging Compliance\\nTotal: ${total_cost:,.0f}', \n",
    "              fontsize=12, fontweight='bold', pad=15)\n",
    "\n",
    "# 2. Tag Key Coverage Breakdown\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "tag_keys = ['CostCenter', 'Environment', 'Team', 'Untagged']\n",
    "tag_costs = [cost_center_tagged, environment_tagged, team_tagged, untagged_cost]\n",
    "colors_keys = ['#2196F3', '#FF9800', '#9C27B0', '#E0E0E0']\n",
    "\n",
    "bars = ax2.barh(tag_keys, tag_costs, color=colors_keys, alpha=0.8)\n",
    "ax2.set_xlabel('Cost ($)', fontsize=10, fontweight='bold')\n",
    "ax2.set_title('Tag Key Coverage by Cost', fontsize=12, fontweight='bold', pad=15)\n",
    "ax2.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Add value labels\n",
    "for bar, cost in zip(bars, tag_costs):\n",
    "    width = bar.get_width()\n",
    "    pct = (cost / total_cost) * 100\n",
    "    ax2.text(width, bar.get_y() + bar.get_height()/2.,\n",
    "             f' ${cost:,.0f} ({pct:.1f}%)', ha='left', va='center', \n",
    "             fontsize=9, fontweight='bold')\n",
    "\n",
    "# 3. Top 10 Governance Targets\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "if len(governance_targets) > 0:\n",
    "    top_gov_targets = governance_targets.head(10).copy()\n",
    "    comp_names_short = [name[:20] + '...' if len(name) > 20 else name \n",
    "                        for name in top_gov_targets['compartmentName']]\n",
    "    costs = top_gov_targets['total_cost'].values\n",
    "    compliance = top_gov_targets['overall_compliance'].values\n",
    "    \n",
    "    y_pos = np.arange(len(comp_names_short))\n",
    "    \n",
    "    # Create horizontal bars colored by compliance\n",
    "    colors_comp = ['#F44336' if c < 0.2 else '#FF9800' if c < 0.3 else '#FFC107' \n",
    "                   for c in compliance]\n",
    "    bars = ax3.barh(y_pos, costs, color=colors_comp, alpha=0.8)\n",
    "    \n",
    "    ax3.set_yticks(y_pos)\n",
    "    ax3.set_yticklabels(comp_names_short, fontsize=8)\n",
    "    ax3.set_xlabel('Cost ($)', fontsize=10, fontweight='bold')\n",
    "    ax3.set_title('Top 10 Governance Targets\\n(High Cost, Low Compliance)', \n",
    "                  fontsize=11, fontweight='bold', pad=15)\n",
    "    ax3.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    # Add compliance percentage labels\n",
    "    for i, (cost, comp) in enumerate(zip(costs, compliance)):\n",
    "        ax3.text(cost + (costs.max() * 0.02), i, f'{comp*100:.0f}%', \n",
    "                va='center', fontsize=8, fontweight='bold', color='#D32F2F')\n",
    "else:\n",
    "    ax3.text(0.5, 0.5, 'No governance targets\\nidentified', \n",
    "             ha='center', va='center', fontsize=12, transform=ax3.transAxes)\n",
    "    ax3.set_xlim(0, 1)\n",
    "    ax3.set_ylim(0, 1)\n",
    "    ax3.axis('off')\n",
    "\n",
    "# 4. Regional Tagging Compliance\n",
    "ax4 = fig.add_subplot(gs[1, 0])\n",
    "top_regions_tag = regional_tagging.head(8)\n",
    "region_names_tag = [r[:20] for r in top_regions_tag.index]\n",
    "compliance_rates = top_regions_tag['compliance_rate'].values * 100\n",
    "region_costs_tag = top_regions_tag['total_cost'].values\n",
    "\n",
    "x_pos = np.arange(len(region_names_tag))\n",
    "width = 0.35\n",
    "\n",
    "# Color bars by compliance level\n",
    "colors_compliance = ['#4CAF50' if c > 70 else '#FFC107' if c > 30 else '#F44336' \n",
    "                     for c in compliance_rates]\n",
    "bars = ax4.bar(x_pos, compliance_rates, color=colors_compliance, alpha=0.8)\n",
    "\n",
    "ax4.set_ylabel('Compliance Rate (%)', fontsize=10, fontweight='bold')\n",
    "ax4.set_title('Regional Tagging Compliance\\nTop 8 Regions', fontsize=11, fontweight='bold')\n",
    "ax4.set_xticks(x_pos)\n",
    "ax4.set_xticklabels(region_names_tag, rotation=45, ha='right', fontsize=8)\n",
    "ax4.axhline(y=70, color='green', linestyle='--', alpha=0.5, linewidth=1, label='Target: 70%')\n",
    "ax4.axhline(y=30, color='red', linestyle='--', alpha=0.5, linewidth=1, label='Critical: 30%')\n",
    "ax4.legend(loc='upper right', fontsize=8)\n",
    "ax4.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels\n",
    "for bar, rate in zip(bars, compliance_rates):\n",
    "    height = bar.get_height()\n",
    "    ax4.text(bar.get_x() + bar.get_width()/2., height + 2,\n",
    "             f'{rate:.0f}%', ha='center', va='bottom', fontsize=8, fontweight='bold')\n",
    "\n",
    "# 5. Tagging Compliance by Service (Top 10 by cost)\n",
    "ax5 = fig.add_subplot(gs[1, 1])\n",
    "top_services_tag = service_tagging.head(10)\n",
    "service_names_short = [s[:25] + '...' if len(s) > 25 else s for s in top_services_tag.index]\n",
    "service_compliance = top_services_tag['compliance_rate'].values * 100\n",
    "service_costs_tag = top_services_tag['total_cost'].values\n",
    "\n",
    "y_pos = np.arange(len(service_names_short))\n",
    "\n",
    "# Base bars for total cost (grey)\n",
    "ax5.barh(y_pos, [100] * len(service_names_short), color='#E0E0E0', alpha=0.3, label='Untagged')\n",
    "\n",
    "# Overlay bars for compliance (colored)\n",
    "colors_svc = ['#4CAF50' if c > 70 else '#FFC107' if c > 30 else '#F44336' \n",
    "              for c in service_compliance]\n",
    "bars = ax5.barh(y_pos, service_compliance, color=colors_svc, alpha=0.8, label='Tagged')\n",
    "\n",
    "ax5.set_yticks(y_pos)\n",
    "ax5.set_yticklabels(service_names_short, fontsize=8)\n",
    "ax5.set_xlabel('Compliance Rate (%)', fontsize=10, fontweight='bold')\n",
    "ax5.set_title('Service Tagging Compliance\\nTop 10 Services by Cost', \n",
    "              fontsize=11, fontweight='bold', pad=15)\n",
    "ax5.set_xlim(0, 100)\n",
    "ax5.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Add compliance labels\n",
    "for i, rate in enumerate(service_compliance):\n",
    "    ax5.text(rate + 2, i, f'{rate:.0f}%', va='center', fontsize=8, fontweight='bold')\n",
    "\n",
    "# 6. Cost Center Distribution (Top 10)\n",
    "ax6 = fig.add_subplot(gs[1, 2])\n",
    "if len(cost_centers) > 0:\n",
    "    top_cc = cost_centers.head(10)\n",
    "    cc_names = [cc[:20] + '...' if len(cc) > 20 else cc for cc in top_cc.index]\n",
    "    cc_costs = top_cc.values\n",
    "    \n",
    "    colors_cc = plt.cm.Set3(np.linspace(0, 1, len(cc_names)))\n",
    "    bars = ax6.barh(cc_names, cc_costs, color=colors_cc, alpha=0.8)\n",
    "    \n",
    "    ax6.set_xlabel('Cost ($)', fontsize=10, fontweight='bold')\n",
    "    ax6.set_title('Top 10 Cost Centers', fontsize=11, fontweight='bold', pad=15)\n",
    "    ax6.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, cost in zip(bars, cc_costs):\n",
    "        width = bar.get_width()\n",
    "        ax6.text(width, bar.get_y() + bar.get_height()/2.,\n",
    "                 f' ${cost:,.0f}', ha='left', va='center', fontsize=8, fontweight='bold')\n",
    "else:\n",
    "    ax6.text(0.5, 0.5, 'No cost center\\ntags found', \n",
    "             ha='center', va='center', fontsize=12, transform=ax6.transAxes)\n",
    "    ax6.axis('off')\n",
    "\n",
    "# 7. Environment Distribution\n",
    "ax7 = fig.add_subplot(gs[2, 0])\n",
    "if len(environments) > 0:\n",
    "    env_data = environments.values\n",
    "    env_labels = environments.index.tolist()\n",
    "    colors_env = ['#1976D2', '#388E3C', '#F57C00', '#C2185B', '#7B1FA2'][:len(env_labels)]\n",
    "    \n",
    "    wedges, texts, autotexts = ax7.pie(env_data, labels=env_labels, autopct='%1.1f%%',\n",
    "                                        colors=colors_env, startangle=90,\n",
    "                                        textprops={'fontsize': 9})\n",
    "    for autotext in autotexts:\n",
    "        autotext.set_color('white')\n",
    "        autotext.set_fontweight('bold')\n",
    "        autotext.set_fontsize(10)\n",
    "    \n",
    "    ax7.set_title(f'Environment Distribution\\nTotal: ${env_data.sum():,.0f}', \n",
    "                  fontsize=11, fontweight='bold')\n",
    "else:\n",
    "    ax7.text(0.5, 0.5, 'No environment\\ntags found', \n",
    "             ha='center', va='center', fontsize=12, transform=ax7.transAxes)\n",
    "    ax7.axis('off')\n",
    "\n",
    "# 8. Governance Opportunity Summary\n",
    "ax8 = fig.add_subplot(gs[2, 1])\n",
    "ax8.axis('off')\n",
    "\n",
    "summary_text = f\"\"\"\n",
    "GOVERNANCE SOLUTION OPPORTUNITIES\n",
    "\n",
    "üìä Tagging Compliance\n",
    "   ‚Ä¢ Overall Coverage: {tagging_coverage_pct:.1f}%\n",
    "   ‚Ä¢ Tagged Cost: ${tagged_cost:,.0f}\n",
    "   ‚Ä¢ Untagged Cost: ${untagged_cost:,.0f}\n",
    "\n",
    "üéØ Target Opportunities\n",
    "   ‚Ä¢ High-Risk Compartments: {len(governance_targets)}\n",
    "   ‚Ä¢ Combined Cost: ${governance_targets['total_cost'].sum() if len(governance_targets) > 0 else 0:,.0f}\n",
    "   ‚Ä¢ Avg. Compliance: {governance_targets['overall_compliance'].mean()*100 if len(governance_targets) > 0 else 0:.1f}%\n",
    "\n",
    "üí∞ Revenue Potential\n",
    "   ‚Ä¢ Tagging Solution: ${governance_opportunity['estimated_governance_solution_revenue']:,.0f}\n",
    "   ‚Ä¢ Showback/Chargeback: ${governance_opportunity['showback_chargeback_opportunity']:,.0f}\n",
    "   ‚Ä¢ Total Opportunity: ${governance_opportunity['estimated_governance_solution_revenue'] + governance_opportunity['showback_chargeback_opportunity']:,.0f}\n",
    "\n",
    "‚úÖ Recommended Actions\n",
    "   1. Implement tag policies for untagged resources\n",
    "   2. Deploy cost allocation/showback for targets\n",
    "   3. Enable automated tagging workflows\n",
    "   4. Establish governance training programs\n",
    "\"\"\"\n",
    "\n",
    "ax8.text(0.05, 0.95, summary_text, transform=ax8.transAxes,\n",
    "         fontsize=10, verticalalignment='top', fontfamily='monospace',\n",
    "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))\n",
    "\n",
    "# 9. Compliance Heatmap: Top Regions vs Tag Keys\n",
    "ax9 = fig.add_subplot(gs[2, 2])\n",
    "\n",
    "# Create compliance matrix\n",
    "top_regions_for_heatmap = regional_tagging.head(6).index\n",
    "tag_key_compliance = pd.DataFrame(index=top_regions_for_heatmap, \n",
    "                                  columns=['CostCenter', 'Environment', 'Team'])\n",
    "\n",
    "for region in top_regions_for_heatmap:\n",
    "    region_data = df[df['region'] == region]\n",
    "    tag_key_compliance.loc[region, 'CostCenter'] = region_data['has_cost_center'].mean() * 100\n",
    "    tag_key_compliance.loc[region, 'Environment'] = region_data['has_environment'].mean() * 100\n",
    "    tag_key_compliance.loc[region, 'Team'] = region_data['has_team'].mean() * 100\n",
    "\n",
    "tag_key_compliance = tag_key_compliance.astype(float)\n",
    "\n",
    "im = ax9.imshow(tag_key_compliance.values, cmap='RdYlGn', aspect='auto', vmin=0, vmax=100)\n",
    "ax9.set_xticks(np.arange(len(tag_key_compliance.columns)))\n",
    "ax9.set_yticks(np.arange(len(tag_key_compliance.index)))\n",
    "ax9.set_xticklabels(tag_key_compliance.columns, fontsize=9, fontweight='bold')\n",
    "ax9.set_yticklabels([r[:20] for r in tag_key_compliance.index], fontsize=8)\n",
    "ax9.set_title('Tag Compliance Heatmap\\nTop 6 Regions √ó Tag Keys', fontsize=11, fontweight='bold', pad=15)\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(im, ax=ax9)\n",
    "cbar.set_label('Compliance %', rotation=270, labelpad=20, fontsize=9, fontweight='bold')\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(len(tag_key_compliance.index)):\n",
    "    for j in range(len(tag_key_compliance.columns)):\n",
    "        value = tag_key_compliance.values[i, j]\n",
    "        color = 'white' if value < 50 else 'black'\n",
    "        text = ax9.text(j, i, f'{value:.0f}%',\n",
    "                       ha=\"center\", va=\"center\", color=color,\n",
    "                       fontsize=9, fontweight='bold')\n",
    "\n",
    "plt.suptitle('üìã COST TRACKING & TAGGING ANALYSIS DASHBOARD', fontsize=16, fontweight='bold', y=0.995)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Tagging analysis dashboard created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4471b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Tagging Analysis Results\n",
    "print(\"Exporting tagging and governance analysis data...\\n\")\n",
    "\n",
    "# Export governance targets\n",
    "if len(governance_targets) > 0:\n",
    "    governance_export = governance_targets.copy()\n",
    "    governance_export['governance_solution_priority'] = governance_export.apply(\n",
    "        lambda x: 'HIGH' if x['total_cost'] > governance_targets['total_cost'].quantile(0.75) else \n",
    "                  'MEDIUM' if x['total_cost'] > governance_targets['total_cost'].quantile(0.50) else 'LOW',\n",
    "        axis=1\n",
    "    )\n",
    "    governance_export.to_csv('../output/tagging_governance_targets.csv', index=False)\n",
    "    print(f\"‚úÖ Exported: tagging_governance_targets.csv ({len(governance_export)} targets)\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No governance targets to export\")\n",
    "\n",
    "# Export regional tagging analysis\n",
    "regional_tag_export = regional_tagging.copy()\n",
    "regional_tag_export.to_csv('../output/regional_tagging_compliance.csv')\n",
    "print(f\"‚úÖ Exported: regional_tagging_compliance.csv ({len(regional_tag_export)} regions)\")\n",
    "\n",
    "# Export service tagging analysis\n",
    "service_tag_export = service_tagging.copy()\n",
    "service_tag_export['compliance_status'] = service_tag_export['compliance_rate'].apply(\n",
    "    lambda x: 'Good' if x > 0.70 else 'Medium' if x > 0.30 else 'Poor'\n",
    ")\n",
    "service_tag_export.to_csv('../output/service_tagging_compliance.csv')\n",
    "print(f\"‚úÖ Exported: service_tagging_compliance.csv ({len(service_tag_export)} services)\")\n",
    "\n",
    "# Export compartment-level tagging for governance teams\n",
    "compartment_tag_export = compartment_tagging.copy()\n",
    "compartment_tag_export['governance_priority'] = compartment_tag_export.apply(\n",
    "    lambda x: 'CRITICAL' if x['total_cost'] > 50 and x['overall_compliance'] < 0.20 else\n",
    "              'HIGH' if x['total_cost'] > 20 and x['overall_compliance'] < 0.40 else\n",
    "              'MEDIUM' if x['overall_compliance'] < 0.60 else 'LOW',\n",
    "    axis=1\n",
    ")\n",
    "compartment_tag_export.to_csv('../output/compartment_tagging_analysis.csv', index=False)\n",
    "print(f\"‚úÖ Exported: compartment_tagging_analysis.csv ({len(compartment_tag_export)} compartments)\")\n",
    "\n",
    "# Create comprehensive tagging summary\n",
    "tagging_summary = {\n",
    "    'overall_compliance': {\n",
    "        'total_cost': total_cost,\n",
    "        'tagged_cost': tagged_cost,\n",
    "        'untagged_cost': untagged_cost,\n",
    "        'tagging_coverage_pct': tagging_coverage_pct\n",
    "    },\n",
    "    'tag_key_coverage': {\n",
    "        'cost_center_tagged': cost_center_tagged,\n",
    "        'cost_center_pct': (cost_center_tagged / total_cost) * 100,\n",
    "        'environment_tagged': environment_tagged,\n",
    "        'environment_pct': (environment_tagged / total_cost) * 100,\n",
    "        'team_tagged': team_tagged,\n",
    "        'team_pct': (team_tagged / total_cost) * 100\n",
    "    },\n",
    "    'governance_targets': {\n",
    "        'num_targets': len(governance_targets),\n",
    "        'target_cost': governance_targets['total_cost'].sum() if len(governance_targets) > 0 else 0,\n",
    "        'avg_compliance': governance_targets['overall_compliance'].mean() if len(governance_targets) > 0 else 0\n",
    "    },\n",
    "    'revenue_opportunity': governance_opportunity\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TAGGING ANALYSIS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüìä OVERALL COMPLIANCE:\")\n",
    "print(f\"   Tagging Coverage: {tagging_coverage_pct:.1f}%\")\n",
    "print(f\"   Tagged Resources: ${tagged_cost:,.2f}\")\n",
    "print(f\"   Untagged Resources: ${untagged_cost:,.2f}\")\n",
    "\n",
    "print(f\"\\nüéØ GOVERNANCE OPPORTUNITIES:\")\n",
    "print(f\"   High-Risk Compartments: {len(governance_targets)}\")\n",
    "print(f\"   Total Cost at Risk: ${governance_targets['total_cost'].sum() if len(governance_targets) > 0 else 0:,.2f}\")\n",
    "\n",
    "print(f\"\\nüí∞ REVENUE POTENTIAL:\")\n",
    "print(f\"   Tagging Solution Revenue: ${governance_opportunity['estimated_governance_solution_revenue']:,.2f}\")\n",
    "print(f\"   Showback/Chargeback Revenue: ${governance_opportunity['showback_chargeback_opportunity']:,.2f}\")\n",
    "print(f\"   Total Governance Opportunity: ${governance_opportunity['estimated_governance_solution_revenue'] + governance_opportunity['showback_chargeback_opportunity']:,.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\n‚úÖ All tagging and governance analysis completed!\")\n",
    "print(\"üìä Review the dashboard above for visual insights.\")\n",
    "print(\"üìÅ Check output folder for exported CSV files.\")\n",
    "print(\"\\nüí° NEXT STEPS:\")\n",
    "print(\"   1. Share governance targets CSV with account teams\")\n",
    "print(\"   2. Develop tagging policy enforcement plan\")\n",
    "print(\"   3. Propose cost allocation/showback implementation\")\n",
    "print(\"   4. Schedule governance training for low-compliance teams\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.9.21)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
